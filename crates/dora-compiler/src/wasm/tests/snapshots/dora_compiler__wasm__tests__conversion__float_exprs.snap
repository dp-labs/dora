---
source: crates/dora-compiler/src/wasm/tests/conversion.rs
expression: op
snapshot_kind: text
---
module {
  func.func public @f32.no_fma(%arg0: !llvm.ptr, %arg1: f32, %arg2: f32, %arg3: f32) -> f32 attributes {llvm.emit_c_interface} {
    %c1_i64 = arith.constant 1 : i64
    %0 = llvm.alloca %c1_i64 x f32 : (i64) -> !llvm.ptr
    llvm.store %arg1, %0 : f32, !llvm.ptr
    %c1_i64_0 = arith.constant 1 : i64
    %1 = llvm.alloca %c1_i64_0 x f32 : (i64) -> !llvm.ptr
    llvm.store %arg2, %1 : f32, !llvm.ptr
    %c1_i64_1 = arith.constant 1 : i64
    %2 = llvm.alloca %c1_i64_1 x f32 : (i64) -> !llvm.ptr
    llvm.store %arg3, %2 : f32, !llvm.ptr
    cf.br ^bb1
  ^bb1:  // pred: ^bb0
    %3 = llvm.load %0 : !llvm.ptr -> f32
    %4 = llvm.load %1 : !llvm.ptr -> f32
    %5 = arith.mulf %3, %4 : f32
    %6 = llvm.load %2 : !llvm.ptr -> f32
    %7 = arith.addf %5, %6 : f32
    cf.br ^bb2(%7 : f32)
  ^bb2(%8: f32):  // pred: ^bb1
    return %8 : f32
  }
  func.func public @f64.no_fma(%arg0: !llvm.ptr, %arg1: f64, %arg2: f64, %arg3: f64) -> f64 attributes {llvm.emit_c_interface} {
    %c1_i64 = arith.constant 1 : i64
    %0 = llvm.alloca %c1_i64 x f64 : (i64) -> !llvm.ptr
    llvm.store %arg1, %0 : f64, !llvm.ptr
    %c1_i64_0 = arith.constant 1 : i64
    %1 = llvm.alloca %c1_i64_0 x f64 : (i64) -> !llvm.ptr
    llvm.store %arg2, %1 : f64, !llvm.ptr
    %c1_i64_1 = arith.constant 1 : i64
    %2 = llvm.alloca %c1_i64_1 x f64 : (i64) -> !llvm.ptr
    llvm.store %arg3, %2 : f64, !llvm.ptr
    cf.br ^bb1
  ^bb1:  // pred: ^bb0
    %3 = llvm.load %0 : !llvm.ptr -> f64
    %4 = llvm.load %1 : !llvm.ptr -> f64
    %5 = arith.mulf %3, %4 : f64
    %6 = llvm.load %2 : !llvm.ptr -> f64
    %7 = arith.addf %5, %6 : f64
    cf.br ^bb2(%7 : f64)
  ^bb2(%8: f64):  // pred: ^bb1
    return %8 : f64
  }
  func.func public @f32.no_fold_add_zero(%arg0: !llvm.ptr, %arg1: f32) -> f32 attributes {llvm.emit_c_interface} {
    %c1_i64 = arith.constant 1 : i64
    %0 = llvm.alloca %c1_i64 x f32 : (i64) -> !llvm.ptr
    llvm.store %arg1, %0 : f32, !llvm.ptr
    cf.br ^bb1
  ^bb1:  // pred: ^bb0
    %1 = llvm.load %0 : !llvm.ptr -> f32
    %c0_i32 = arith.constant 0 : i32
    %2 = arith.bitcast %c0_i32 : i32 to f32
    %3 = arith.addf %1, %2 : f32
    cf.br ^bb2(%3 : f32)
  ^bb2(%4: f32):  // pred: ^bb1
    return %4 : f32
  }
  func.func public @f64.no_fold_add_zero(%arg0: !llvm.ptr, %arg1: f64) -> f64 attributes {llvm.emit_c_interface} {
    %c1_i64 = arith.constant 1 : i64
    %0 = llvm.alloca %c1_i64 x f64 : (i64) -> !llvm.ptr
    llvm.store %arg1, %0 : f64, !llvm.ptr
    cf.br ^bb1
  ^bb1:  // pred: ^bb0
    %1 = llvm.load %0 : !llvm.ptr -> f64
    %c0_i64 = arith.constant 0 : i64
    %2 = arith.bitcast %c0_i64 : i64 to f64
    %3 = arith.addf %1, %2 : f64
    cf.br ^bb2(%3 : f64)
  ^bb2(%4: f64):  // pred: ^bb1
    return %4 : f64
  }
  func.func public @f32.no_fold_zero_sub(%arg0: !llvm.ptr, %arg1: f32) -> f32 attributes {llvm.emit_c_interface} {
    %c1_i64 = arith.constant 1 : i64
    %0 = llvm.alloca %c1_i64 x f32 : (i64) -> !llvm.ptr
    llvm.store %arg1, %0 : f32, !llvm.ptr
    cf.br ^bb1
  ^bb1:  // pred: ^bb0
    %c0_i32 = arith.constant 0 : i32
    %1 = arith.bitcast %c0_i32 : i32 to f32
    %2 = llvm.load %0 : !llvm.ptr -> f32
    %3 = arith.subf %1, %2 : f32
    cf.br ^bb2(%3 : f32)
  ^bb2(%4: f32):  // pred: ^bb1
    return %4 : f32
  }
  func.func public @f64.no_fold_zero_sub(%arg0: !llvm.ptr, %arg1: f64) -> f64 attributes {llvm.emit_c_interface} {
    %c1_i64 = arith.constant 1 : i64
    %0 = llvm.alloca %c1_i64 x f64 : (i64) -> !llvm.ptr
    llvm.store %arg1, %0 : f64, !llvm.ptr
    cf.br ^bb1
  ^bb1:  // pred: ^bb0
    %c0_i64 = arith.constant 0 : i64
    %1 = arith.bitcast %c0_i64 : i64 to f64
    %2 = llvm.load %0 : !llvm.ptr -> f64
    %3 = arith.subf %1, %2 : f64
    cf.br ^bb2(%3 : f64)
  ^bb2(%4: f64):  // pred: ^bb1
    return %4 : f64
  }
  func.func @f6(%arg0: !llvm.ptr, %arg1: f32) -> f32 {
    %c1_i64 = arith.constant 1 : i64
    %0 = llvm.alloca %c1_i64 x f32 : (i64) -> !llvm.ptr
    llvm.store %arg1, %0 : f32, !llvm.ptr
    cf.br ^bb1
  ^bb1:  // pred: ^bb0
    %1 = llvm.load %0 : !llvm.ptr -> f32
    %c0_i32 = arith.constant 0 : i32
    %2 = arith.bitcast %c0_i32 : i32 to f32
    %3 = arith.subf %1, %2 : f32
    cf.br ^bb2(%3 : f32)
  ^bb2(%4: f32):  // pred: ^bb1
    return %4 : f32
  }
  func.func @f7(%arg0: !llvm.ptr, %arg1: f64) -> f64 {
    %c1_i64 = arith.constant 1 : i64
    %0 = llvm.alloca %c1_i64 x f64 : (i64) -> !llvm.ptr
    llvm.store %arg1, %0 : f64, !llvm.ptr
    cf.br ^bb1
  ^bb1:  // pred: ^bb0
    %1 = llvm.load %0 : !llvm.ptr -> f64
    %c0_i64 = arith.constant 0 : i64
    %2 = arith.bitcast %c0_i64 : i64 to f64
    %3 = arith.subf %1, %2 : f64
    cf.br ^bb2(%3 : f64)
  ^bb2(%4: f64):  // pred: ^bb1
    return %4 : f64
  }
  func.func public @f32.no_fold_mul_zero(%arg0: !llvm.ptr, %arg1: f32) -> f32 attributes {llvm.emit_c_interface} {
    %c1_i64 = arith.constant 1 : i64
    %0 = llvm.alloca %c1_i64 x f32 : (i64) -> !llvm.ptr
    llvm.store %arg1, %0 : f32, !llvm.ptr
    cf.br ^bb1
  ^bb1:  // pred: ^bb0
    %1 = llvm.load %0 : !llvm.ptr -> f32
    %c0_i32 = arith.constant 0 : i32
    %2 = arith.bitcast %c0_i32 : i32 to f32
    %3 = arith.mulf %1, %2 : f32
    cf.br ^bb2(%3 : f32)
  ^bb2(%4: f32):  // pred: ^bb1
    return %4 : f32
  }
  func.func public @f64.no_fold_mul_zero(%arg0: !llvm.ptr, %arg1: f64) -> f64 attributes {llvm.emit_c_interface} {
    %c1_i64 = arith.constant 1 : i64
    %0 = llvm.alloca %c1_i64 x f64 : (i64) -> !llvm.ptr
    llvm.store %arg1, %0 : f64, !llvm.ptr
    cf.br ^bb1
  ^bb1:  // pred: ^bb0
    %1 = llvm.load %0 : !llvm.ptr -> f64
    %c0_i64 = arith.constant 0 : i64
    %2 = arith.bitcast %c0_i64 : i64 to f64
    %3 = arith.mulf %1, %2 : f64
    cf.br ^bb2(%3 : f64)
  ^bb2(%4: f64):  // pred: ^bb1
    return %4 : f64
  }
  func.func @f10(%arg0: !llvm.ptr, %arg1: f32) -> f32 {
    %c1_i64 = arith.constant 1 : i64
    %0 = llvm.alloca %c1_i64 x f32 : (i64) -> !llvm.ptr
    llvm.store %arg1, %0 : f32, !llvm.ptr
    cf.br ^bb1
  ^bb1:  // pred: ^bb0
    %1 = llvm.load %0 : !llvm.ptr -> f32
    %c1065353216_i32 = arith.constant 1065353216 : i32
    %2 = arith.bitcast %c1065353216_i32 : i32 to f32
    %3 = arith.mulf %1, %2 : f32
    cf.br ^bb2(%3 : f32)
  ^bb2(%4: f32):  // pred: ^bb1
    return %4 : f32
  }
  func.func @f11(%arg0: !llvm.ptr, %arg1: f64) -> f64 {
    %c1_i64 = arith.constant 1 : i64
    %0 = llvm.alloca %c1_i64 x f64 : (i64) -> !llvm.ptr
    llvm.store %arg1, %0 : f64, !llvm.ptr
    cf.br ^bb1
  ^bb1:  // pred: ^bb0
    %1 = llvm.load %0 : !llvm.ptr -> f64
    %c4607182418800017408_i64 = arith.constant 4607182418800017408 : i64
    %2 = arith.bitcast %c4607182418800017408_i64 : i64 to f64
    %3 = arith.mulf %1, %2 : f64
    cf.br ^bb2(%3 : f64)
  ^bb2(%4: f64):  // pred: ^bb1
    return %4 : f64
  }
  func.func public @f32.no_fold_zero_div(%arg0: !llvm.ptr, %arg1: f32) -> f32 attributes {llvm.emit_c_interface} {
    %c1_i64 = arith.constant 1 : i64
    %0 = llvm.alloca %c1_i64 x f32 : (i64) -> !llvm.ptr
    llvm.store %arg1, %0 : f32, !llvm.ptr
    cf.br ^bb1
  ^bb1:  // pred: ^bb0
    %c0_i32 = arith.constant 0 : i32
    %1 = arith.bitcast %c0_i32 : i32 to f32
    %2 = llvm.load %0 : !llvm.ptr -> f32
    %cst = arith.constant 0.000000e+00 : f32
    %3 = arith.cmpf oeq, %2, %cst : f32
    %4 = scf.if %3 -> (f32) {
      scf.yield %cst : f32
    } else {
      %6 = arith.divf %1, %2 : f32
      scf.yield %6 : f32
    }
    cf.br ^bb2(%4 : f32)
  ^bb2(%5: f32):  // pred: ^bb1
    return %5 : f32
  }
  func.func public @f64.no_fold_zero_div(%arg0: !llvm.ptr, %arg1: f64) -> f64 attributes {llvm.emit_c_interface} {
    %c1_i64 = arith.constant 1 : i64
    %0 = llvm.alloca %c1_i64 x f64 : (i64) -> !llvm.ptr
    llvm.store %arg1, %0 : f64, !llvm.ptr
    cf.br ^bb1
  ^bb1:  // pred: ^bb0
    %c0_i64 = arith.constant 0 : i64
    %1 = arith.bitcast %c0_i64 : i64 to f64
    %2 = llvm.load %0 : !llvm.ptr -> f64
    %cst = arith.constant 0.000000e+00 : f64
    %3 = arith.cmpf oeq, %2, %cst : f64
    %4 = scf.if %3 -> (f64) {
      scf.yield %cst : f64
    } else {
      %6 = arith.divf %1, %2 : f64
      scf.yield %6 : f64
    }
    cf.br ^bb2(%4 : f64)
  ^bb2(%5: f64):  // pred: ^bb1
    return %5 : f64
  }
  func.func @f14(%arg0: !llvm.ptr, %arg1: f32) -> f32 {
    %c1_i64 = arith.constant 1 : i64
    %0 = llvm.alloca %c1_i64 x f32 : (i64) -> !llvm.ptr
    llvm.store %arg1, %0 : f32, !llvm.ptr
    cf.br ^bb1
  ^bb1:  // pred: ^bb0
    %1 = llvm.load %0 : !llvm.ptr -> f32
    %c1065353216_i32 = arith.constant 1065353216 : i32
    %2 = arith.bitcast %c1065353216_i32 : i32 to f32
    %cst = arith.constant 0.000000e+00 : f32
    %3 = arith.cmpf oeq, %2, %cst : f32
    %4 = scf.if %3 -> (f32) {
      scf.yield %cst : f32
    } else {
      %6 = arith.divf %1, %2 : f32
      scf.yield %6 : f32
    }
    cf.br ^bb2(%4 : f32)
  ^bb2(%5: f32):  // pred: ^bb1
    return %5 : f32
  }
  func.func @f15(%arg0: !llvm.ptr, %arg1: f64) -> f64 {
    %c1_i64 = arith.constant 1 : i64
    %0 = llvm.alloca %c1_i64 x f64 : (i64) -> !llvm.ptr
    llvm.store %arg1, %0 : f64, !llvm.ptr
    cf.br ^bb1
  ^bb1:  // pred: ^bb0
    %1 = llvm.load %0 : !llvm.ptr -> f64
    %c4607182418800017408_i64 = arith.constant 4607182418800017408 : i64
    %2 = arith.bitcast %c4607182418800017408_i64 : i64 to f64
    %cst = arith.constant 0.000000e+00 : f64
    %3 = arith.cmpf oeq, %2, %cst : f64
    %4 = scf.if %3 -> (f64) {
      scf.yield %cst : f64
    } else {
      %6 = arith.divf %1, %2 : f64
      scf.yield %6 : f64
    }
    cf.br ^bb2(%4 : f64)
  ^bb2(%5: f64):  // pred: ^bb1
    return %5 : f64
  }
  func.func @f16(%arg0: !llvm.ptr, %arg1: f32) -> f32 {
    %c1_i64 = arith.constant 1 : i64
    %0 = llvm.alloca %c1_i64 x f32 : (i64) -> !llvm.ptr
    llvm.store %arg1, %0 : f32, !llvm.ptr
    cf.br ^bb1
  ^bb1:  // pred: ^bb0
    %1 = llvm.load %0 : !llvm.ptr -> f32
    %c-1082130432_i32 = arith.constant -1082130432 : i32
    %2 = arith.bitcast %c-1082130432_i32 : i32 to f32
    %cst = arith.constant 0.000000e+00 : f32
    %3 = arith.cmpf oeq, %2, %cst : f32
    %4 = scf.if %3 -> (f32) {
      scf.yield %cst : f32
    } else {
      %6 = arith.divf %1, %2 : f32
      scf.yield %6 : f32
    }
    cf.br ^bb2(%4 : f32)
  ^bb2(%5: f32):  // pred: ^bb1
    return %5 : f32
  }
  func.func @f17(%arg0: !llvm.ptr, %arg1: f64) -> f64 {
    %c1_i64 = arith.constant 1 : i64
    %0 = llvm.alloca %c1_i64 x f64 : (i64) -> !llvm.ptr
    llvm.store %arg1, %0 : f64, !llvm.ptr
    cf.br ^bb1
  ^bb1:  // pred: ^bb0
    %1 = llvm.load %0 : !llvm.ptr -> f64
    %c-4616189618054758400_i64 = arith.constant -4616189618054758400 : i64
    %2 = arith.bitcast %c-4616189618054758400_i64 : i64 to f64
    %cst = arith.constant 0.000000e+00 : f64
    %3 = arith.cmpf oeq, %2, %cst : f64
    %4 = scf.if %3 -> (f64) {
      scf.yield %cst : f64
    } else {
      %6 = arith.divf %1, %2 : f64
      scf.yield %6 : f64
    }
    cf.br ^bb2(%4 : f64)
  ^bb2(%5: f64):  // pred: ^bb1
    return %5 : f64
  }
  func.func @f18(%arg0: !llvm.ptr, %arg1: f32) -> f32 {
    %c1_i64 = arith.constant 1 : i64
    %0 = llvm.alloca %c1_i64 x f32 : (i64) -> !llvm.ptr
    llvm.store %arg1, %0 : f32, !llvm.ptr
    cf.br ^bb1
  ^bb1:  // pred: ^bb0
    %c-2147483648_i32 = arith.constant -2147483648 : i32
    %1 = arith.bitcast %c-2147483648_i32 : i32 to f32
    %2 = llvm.load %0 : !llvm.ptr -> f32
    %3 = arith.subf %1, %2 : f32
    cf.br ^bb2(%3 : f32)
  ^bb2(%4: f32):  // pred: ^bb1
    return %4 : f32
  }
  func.func @f19(%arg0: !llvm.ptr, %arg1: f64) -> f64 {
    %c1_i64 = arith.constant 1 : i64
    %0 = llvm.alloca %c1_i64 x f64 : (i64) -> !llvm.ptr
    llvm.store %arg1, %0 : f64, !llvm.ptr
    cf.br ^bb1
  ^bb1:  // pred: ^bb0
    %c-9223372036854775808_i64 = arith.constant -9223372036854775808 : i64
    %1 = arith.bitcast %c-9223372036854775808_i64 : i64 to f64
    %2 = llvm.load %0 : !llvm.ptr -> f64
    %3 = arith.subf %1, %2 : f64
    cf.br ^bb2(%3 : f64)
  ^bb2(%4: f64):  // pred: ^bb1
    return %4 : f64
  }
  func.func @f20(%arg0: !llvm.ptr, %arg1: f32) -> f32 {
    %c1_i64 = arith.constant 1 : i64
    %0 = llvm.alloca %c1_i64 x f32 : (i64) -> !llvm.ptr
    llvm.store %arg1, %0 : f32, !llvm.ptr
    cf.br ^bb1
  ^bb1:  // pred: ^bb0
    %c-1082130432_i32 = arith.constant -1082130432 : i32
    %1 = arith.bitcast %c-1082130432_i32 : i32 to f32
    %2 = llvm.load %0 : !llvm.ptr -> f32
    %3 = arith.mulf %1, %2 : f32
    cf.br ^bb2(%3 : f32)
  ^bb2(%4: f32):  // pred: ^bb1
    return %4 : f32
  }
  func.func @f21(%arg0: !llvm.ptr, %arg1: f64) -> f64 {
    %c1_i64 = arith.constant 1 : i64
    %0 = llvm.alloca %c1_i64 x f64 : (i64) -> !llvm.ptr
    llvm.store %arg1, %0 : f64, !llvm.ptr
    cf.br ^bb1
  ^bb1:  // pred: ^bb0
    %c-4616189618054758400_i64 = arith.constant -4616189618054758400 : i64
    %1 = arith.bitcast %c-4616189618054758400_i64 : i64 to f64
    %2 = llvm.load %0 : !llvm.ptr -> f64
    %3 = arith.mulf %1, %2 : f64
    cf.br ^bb2(%3 : f64)
  ^bb2(%4: f64):  // pred: ^bb1
    return %4 : f64
  }
  func.func public @f32.no_fold_eq_self(%arg0: !llvm.ptr, %arg1: f32) -> i32 attributes {llvm.emit_c_interface} {
    %c1_i64 = arith.constant 1 : i64
    %0 = llvm.alloca %c1_i64 x f32 : (i64) -> !llvm.ptr
    llvm.store %arg1, %0 : f32, !llvm.ptr
    cf.br ^bb1
  ^bb1:  // pred: ^bb0
    %1 = llvm.load %0 : !llvm.ptr -> f32
    %2 = llvm.load %0 : !llvm.ptr -> f32
    %3 = arith.cmpf oeq, %1, %2 : f32
    %4 = arith.extui %3 : i1 to i32
    cf.br ^bb2(%4 : i32)
  ^bb2(%5: i32):  // pred: ^bb1
    return %5 : i32
  }
  func.func public @f64.no_fold_eq_self(%arg0: !llvm.ptr, %arg1: f64) -> i32 attributes {llvm.emit_c_interface} {
    %c1_i64 = arith.constant 1 : i64
    %0 = llvm.alloca %c1_i64 x f64 : (i64) -> !llvm.ptr
    llvm.store %arg1, %0 : f64, !llvm.ptr
    cf.br ^bb1
  ^bb1:  // pred: ^bb0
    %1 = llvm.load %0 : !llvm.ptr -> f64
    %2 = llvm.load %0 : !llvm.ptr -> f64
    %3 = arith.cmpf oeq, %1, %2 : f64
    %4 = arith.extui %3 : i1 to i32
    cf.br ^bb2(%4 : i32)
  ^bb2(%5: i32):  // pred: ^bb1
    return %5 : i32
  }
  func.func public @f32.no_fold_ne_self(%arg0: !llvm.ptr, %arg1: f32) -> i32 attributes {llvm.emit_c_interface} {
    %c1_i64 = arith.constant 1 : i64
    %0 = llvm.alloca %c1_i64 x f32 : (i64) -> !llvm.ptr
    llvm.store %arg1, %0 : f32, !llvm.ptr
    cf.br ^bb1
  ^bb1:  // pred: ^bb0
    %1 = llvm.load %0 : !llvm.ptr -> f32
    %2 = llvm.load %0 : !llvm.ptr -> f32
    %3 = arith.cmpf oeq, %1, %2 : f32
    %4 = arith.extui %3 : i1 to i32
    %c0_i32 = arith.constant 0 : i32
    %5 = arith.cmpi eq, %4, %c0_i32 : i32
    %6 = arith.extui %5 : i1 to i32
    cf.br ^bb2(%6 : i32)
  ^bb2(%7: i32):  // pred: ^bb1
    return %7 : i32
  }
  func.func public @f64.no_fold_ne_self(%arg0: !llvm.ptr, %arg1: f64) -> i32 attributes {llvm.emit_c_interface} {
    %c1_i64 = arith.constant 1 : i64
    %0 = llvm.alloca %c1_i64 x f64 : (i64) -> !llvm.ptr
    llvm.store %arg1, %0 : f64, !llvm.ptr
    cf.br ^bb1
  ^bb1:  // pred: ^bb0
    %1 = llvm.load %0 : !llvm.ptr -> f64
    %2 = llvm.load %0 : !llvm.ptr -> f64
    %3 = arith.cmpf oeq, %1, %2 : f64
    %4 = arith.extui %3 : i1 to i32
    %c0_i32 = arith.constant 0 : i32
    %5 = arith.cmpi eq, %4, %c0_i32 : i32
    %6 = arith.extui %5 : i1 to i32
    cf.br ^bb2(%6 : i32)
  ^bb2(%7: i32):  // pred: ^bb1
    return %7 : i32
  }
  func.func public @f32.no_fold_sub_self(%arg0: !llvm.ptr, %arg1: f32) -> f32 attributes {llvm.emit_c_interface} {
    %c1_i64 = arith.constant 1 : i64
    %0 = llvm.alloca %c1_i64 x f32 : (i64) -> !llvm.ptr
    llvm.store %arg1, %0 : f32, !llvm.ptr
    cf.br ^bb1
  ^bb1:  // pred: ^bb0
    %1 = llvm.load %0 : !llvm.ptr -> f32
    %2 = llvm.load %0 : !llvm.ptr -> f32
    %3 = arith.subf %1, %2 : f32
    cf.br ^bb2(%3 : f32)
  ^bb2(%4: f32):  // pred: ^bb1
    return %4 : f32
  }
  func.func public @f64.no_fold_sub_self(%arg0: !llvm.ptr, %arg1: f64) -> f64 attributes {llvm.emit_c_interface} {
    %c1_i64 = arith.constant 1 : i64
    %0 = llvm.alloca %c1_i64 x f64 : (i64) -> !llvm.ptr
    llvm.store %arg1, %0 : f64, !llvm.ptr
    cf.br ^bb1
  ^bb1:  // pred: ^bb0
    %1 = llvm.load %0 : !llvm.ptr -> f64
    %2 = llvm.load %0 : !llvm.ptr -> f64
    %3 = arith.subf %1, %2 : f64
    cf.br ^bb2(%3 : f64)
  ^bb2(%4: f64):  // pred: ^bb1
    return %4 : f64
  }
  func.func public @f32.no_fold_div_self(%arg0: !llvm.ptr, %arg1: f32) -> f32 attributes {llvm.emit_c_interface} {
    %c1_i64 = arith.constant 1 : i64
    %0 = llvm.alloca %c1_i64 x f32 : (i64) -> !llvm.ptr
    llvm.store %arg1, %0 : f32, !llvm.ptr
    cf.br ^bb1
  ^bb1:  // pred: ^bb0
    %1 = llvm.load %0 : !llvm.ptr -> f32
    %2 = llvm.load %0 : !llvm.ptr -> f32
    %cst = arith.constant 0.000000e+00 : f32
    %3 = arith.cmpf oeq, %2, %cst : f32
    %4 = scf.if %3 -> (f32) {
      scf.yield %cst : f32
    } else {
      %6 = arith.divf %1, %2 : f32
      scf.yield %6 : f32
    }
    cf.br ^bb2(%4 : f32)
  ^bb2(%5: f32):  // pred: ^bb1
    return %5 : f32
  }
  func.func public @f64.no_fold_div_self(%arg0: !llvm.ptr, %arg1: f64) -> f64 attributes {llvm.emit_c_interface} {
    %c1_i64 = arith.constant 1 : i64
    %0 = llvm.alloca %c1_i64 x f64 : (i64) -> !llvm.ptr
    llvm.store %arg1, %0 : f64, !llvm.ptr
    cf.br ^bb1
  ^bb1:  // pred: ^bb0
    %1 = llvm.load %0 : !llvm.ptr -> f64
    %2 = llvm.load %0 : !llvm.ptr -> f64
    %cst = arith.constant 0.000000e+00 : f64
    %3 = arith.cmpf oeq, %2, %cst : f64
    %4 = scf.if %3 -> (f64) {
      scf.yield %cst : f64
    } else {
      %6 = arith.divf %1, %2 : f64
      scf.yield %6 : f64
    }
    cf.br ^bb2(%4 : f64)
  ^bb2(%5: f64):  // pred: ^bb1
    return %5 : f64
  }
  func.func public @f32.no_fold_div_3(%arg0: !llvm.ptr, %arg1: f32) -> f32 attributes {llvm.emit_c_interface} {
    %c1_i64 = arith.constant 1 : i64
    %0 = llvm.alloca %c1_i64 x f32 : (i64) -> !llvm.ptr
    llvm.store %arg1, %0 : f32, !llvm.ptr
    cf.br ^bb1
  ^bb1:  // pred: ^bb0
    %1 = llvm.load %0 : !llvm.ptr -> f32
    %c1077936128_i32 = arith.constant 1077936128 : i32
    %2 = arith.bitcast %c1077936128_i32 : i32 to f32
    %cst = arith.constant 0.000000e+00 : f32
    %3 = arith.cmpf oeq, %2, %cst : f32
    %4 = scf.if %3 -> (f32) {
      scf.yield %cst : f32
    } else {
      %6 = arith.divf %1, %2 : f32
      scf.yield %6 : f32
    }
    cf.br ^bb2(%4 : f32)
  ^bb2(%5: f32):  // pred: ^bb1
    return %5 : f32
  }
  func.func public @f64.no_fold_div_3(%arg0: !llvm.ptr, %arg1: f64) -> f64 attributes {llvm.emit_c_interface} {
    %c1_i64 = arith.constant 1 : i64
    %0 = llvm.alloca %c1_i64 x f64 : (i64) -> !llvm.ptr
    llvm.store %arg1, %0 : f64, !llvm.ptr
    cf.br ^bb1
  ^bb1:  // pred: ^bb0
    %1 = llvm.load %0 : !llvm.ptr -> f64
    %c4613937818241073152_i64 = arith.constant 4613937818241073152 : i64
    %2 = arith.bitcast %c4613937818241073152_i64 : i64 to f64
    %cst = arith.constant 0.000000e+00 : f64
    %3 = arith.cmpf oeq, %2, %cst : f64
    %4 = scf.if %3 -> (f64) {
      scf.yield %cst : f64
    } else {
      %6 = arith.divf %1, %2 : f64
      scf.yield %6 : f64
    }
    cf.br ^bb2(%4 : f64)
  ^bb2(%5: f64):  // pred: ^bb1
    return %5 : f64
  }
  func.func public @f32.no_factor(%arg0: !llvm.ptr, %arg1: f32, %arg2: f32, %arg3: f32) -> f32 attributes {llvm.emit_c_interface} {
    %c1_i64 = arith.constant 1 : i64
    %0 = llvm.alloca %c1_i64 x f32 : (i64) -> !llvm.ptr
    llvm.store %arg1, %0 : f32, !llvm.ptr
    %c1_i64_0 = arith.constant 1 : i64
    %1 = llvm.alloca %c1_i64_0 x f32 : (i64) -> !llvm.ptr
    llvm.store %arg2, %1 : f32, !llvm.ptr
    %c1_i64_1 = arith.constant 1 : i64
    %2 = llvm.alloca %c1_i64_1 x f32 : (i64) -> !llvm.ptr
    llvm.store %arg3, %2 : f32, !llvm.ptr
    cf.br ^bb1
  ^bb1:  // pred: ^bb0
    %3 = llvm.load %0 : !llvm.ptr -> f32
    %4 = llvm.load %2 : !llvm.ptr -> f32
    %5 = arith.mulf %3, %4 : f32
    %6 = llvm.load %1 : !llvm.ptr -> f32
    %7 = llvm.load %2 : !llvm.ptr -> f32
    %8 = arith.mulf %6, %7 : f32
    %9 = arith.addf %5, %8 : f32
    cf.br ^bb2(%9 : f32)
  ^bb2(%10: f32):  // pred: ^bb1
    return %10 : f32
  }
  func.func public @f64.no_factor(%arg0: !llvm.ptr, %arg1: f64, %arg2: f64, %arg3: f64) -> f64 attributes {llvm.emit_c_interface} {
    %c1_i64 = arith.constant 1 : i64
    %0 = llvm.alloca %c1_i64 x f64 : (i64) -> !llvm.ptr
    llvm.store %arg1, %0 : f64, !llvm.ptr
    %c1_i64_0 = arith.constant 1 : i64
    %1 = llvm.alloca %c1_i64_0 x f64 : (i64) -> !llvm.ptr
    llvm.store %arg2, %1 : f64, !llvm.ptr
    %c1_i64_1 = arith.constant 1 : i64
    %2 = llvm.alloca %c1_i64_1 x f64 : (i64) -> !llvm.ptr
    llvm.store %arg3, %2 : f64, !llvm.ptr
    cf.br ^bb1
  ^bb1:  // pred: ^bb0
    %3 = llvm.load %0 : !llvm.ptr -> f64
    %4 = llvm.load %2 : !llvm.ptr -> f64
    %5 = arith.mulf %3, %4 : f64
    %6 = llvm.load %1 : !llvm.ptr -> f64
    %7 = llvm.load %2 : !llvm.ptr -> f64
    %8 = arith.mulf %6, %7 : f64
    %9 = arith.addf %5, %8 : f64
    cf.br ^bb2(%9 : f64)
  ^bb2(%10: f64):  // pred: ^bb1
    return %10 : f64
  }
  func.func public @f32.no_distribute(%arg0: !llvm.ptr, %arg1: f32, %arg2: f32, %arg3: f32) -> f32 attributes {llvm.emit_c_interface} {
    %c1_i64 = arith.constant 1 : i64
    %0 = llvm.alloca %c1_i64 x f32 : (i64) -> !llvm.ptr
    llvm.store %arg1, %0 : f32, !llvm.ptr
    %c1_i64_0 = arith.constant 1 : i64
    %1 = llvm.alloca %c1_i64_0 x f32 : (i64) -> !llvm.ptr
    llvm.store %arg2, %1 : f32, !llvm.ptr
    %c1_i64_1 = arith.constant 1 : i64
    %2 = llvm.alloca %c1_i64_1 x f32 : (i64) -> !llvm.ptr
    llvm.store %arg3, %2 : f32, !llvm.ptr
    cf.br ^bb1
  ^bb1:  // pred: ^bb0
    %3 = llvm.load %0 : !llvm.ptr -> f32
    %4 = llvm.load %1 : !llvm.ptr -> f32
    %5 = arith.addf %3, %4 : f32
    %6 = llvm.load %2 : !llvm.ptr -> f32
    %7 = arith.mulf %5, %6 : f32
    cf.br ^bb2(%7 : f32)
  ^bb2(%8: f32):  // pred: ^bb1
    return %8 : f32
  }
  func.func public @f64.no_distribute(%arg0: !llvm.ptr, %arg1: f64, %arg2: f64, %arg3: f64) -> f64 attributes {llvm.emit_c_interface} {
    %c1_i64 = arith.constant 1 : i64
    %0 = llvm.alloca %c1_i64 x f64 : (i64) -> !llvm.ptr
    llvm.store %arg1, %0 : f64, !llvm.ptr
    %c1_i64_0 = arith.constant 1 : i64
    %1 = llvm.alloca %c1_i64_0 x f64 : (i64) -> !llvm.ptr
    llvm.store %arg2, %1 : f64, !llvm.ptr
    %c1_i64_1 = arith.constant 1 : i64
    %2 = llvm.alloca %c1_i64_1 x f64 : (i64) -> !llvm.ptr
    llvm.store %arg3, %2 : f64, !llvm.ptr
    cf.br ^bb1
  ^bb1:  // pred: ^bb0
    %3 = llvm.load %0 : !llvm.ptr -> f64
    %4 = llvm.load %1 : !llvm.ptr -> f64
    %5 = arith.addf %3, %4 : f64
    %6 = llvm.load %2 : !llvm.ptr -> f64
    %7 = arith.mulf %5, %6 : f64
    cf.br ^bb2(%7 : f64)
  ^bb2(%8: f64):  // pred: ^bb1
    return %8 : f64
  }
  func.func public @f32.no_regroup_div_mul(%arg0: !llvm.ptr, %arg1: f32, %arg2: f32, %arg3: f32) -> f32 attributes {llvm.emit_c_interface} {
    %c1_i64 = arith.constant 1 : i64
    %0 = llvm.alloca %c1_i64 x f32 : (i64) -> !llvm.ptr
    llvm.store %arg1, %0 : f32, !llvm.ptr
    %c1_i64_0 = arith.constant 1 : i64
    %1 = llvm.alloca %c1_i64_0 x f32 : (i64) -> !llvm.ptr
    llvm.store %arg2, %1 : f32, !llvm.ptr
    %c1_i64_1 = arith.constant 1 : i64
    %2 = llvm.alloca %c1_i64_1 x f32 : (i64) -> !llvm.ptr
    llvm.store %arg3, %2 : f32, !llvm.ptr
    cf.br ^bb1
  ^bb1:  // pred: ^bb0
    %3 = llvm.load %0 : !llvm.ptr -> f32
    %4 = llvm.load %1 : !llvm.ptr -> f32
    %5 = llvm.load %2 : !llvm.ptr -> f32
    %cst = arith.constant 0.000000e+00 : f32
    %6 = arith.cmpf oeq, %5, %cst : f32
    %7 = scf.if %6 -> (f32) {
      scf.yield %cst : f32
    } else {
      %10 = arith.divf %4, %5 : f32
      scf.yield %10 : f32
    }
    %8 = arith.mulf %3, %7 : f32
    cf.br ^bb2(%8 : f32)
  ^bb2(%9: f32):  // pred: ^bb1
    return %9 : f32
  }
  func.func public @f64.no_regroup_div_mul(%arg0: !llvm.ptr, %arg1: f64, %arg2: f64, %arg3: f64) -> f64 attributes {llvm.emit_c_interface} {
    %c1_i64 = arith.constant 1 : i64
    %0 = llvm.alloca %c1_i64 x f64 : (i64) -> !llvm.ptr
    llvm.store %arg1, %0 : f64, !llvm.ptr
    %c1_i64_0 = arith.constant 1 : i64
    %1 = llvm.alloca %c1_i64_0 x f64 : (i64) -> !llvm.ptr
    llvm.store %arg2, %1 : f64, !llvm.ptr
    %c1_i64_1 = arith.constant 1 : i64
    %2 = llvm.alloca %c1_i64_1 x f64 : (i64) -> !llvm.ptr
    llvm.store %arg3, %2 : f64, !llvm.ptr
    cf.br ^bb1
  ^bb1:  // pred: ^bb0
    %3 = llvm.load %0 : !llvm.ptr -> f64
    %4 = llvm.load %1 : !llvm.ptr -> f64
    %5 = llvm.load %2 : !llvm.ptr -> f64
    %cst = arith.constant 0.000000e+00 : f64
    %6 = arith.cmpf oeq, %5, %cst : f64
    %7 = scf.if %6 -> (f64) {
      scf.yield %cst : f64
    } else {
      %10 = arith.divf %4, %5 : f64
      scf.yield %10 : f64
    }
    %8 = arith.mulf %3, %7 : f64
    cf.br ^bb2(%8 : f64)
  ^bb2(%9: f64):  // pred: ^bb1
    return %9 : f64
  }
  func.func public @f32.no_regroup_mul_div(%arg0: !llvm.ptr, %arg1: f32, %arg2: f32, %arg3: f32) -> f32 attributes {llvm.emit_c_interface} {
    %c1_i64 = arith.constant 1 : i64
    %0 = llvm.alloca %c1_i64 x f32 : (i64) -> !llvm.ptr
    llvm.store %arg1, %0 : f32, !llvm.ptr
    %c1_i64_0 = arith.constant 1 : i64
    %1 = llvm.alloca %c1_i64_0 x f32 : (i64) -> !llvm.ptr
    llvm.store %arg2, %1 : f32, !llvm.ptr
    %c1_i64_1 = arith.constant 1 : i64
    %2 = llvm.alloca %c1_i64_1 x f32 : (i64) -> !llvm.ptr
    llvm.store %arg3, %2 : f32, !llvm.ptr
    cf.br ^bb1
  ^bb1:  // pred: ^bb0
    %3 = llvm.load %0 : !llvm.ptr -> f32
    %4 = llvm.load %1 : !llvm.ptr -> f32
    %5 = arith.mulf %3, %4 : f32
    %6 = llvm.load %2 : !llvm.ptr -> f32
    %cst = arith.constant 0.000000e+00 : f32
    %7 = arith.cmpf oeq, %6, %cst : f32
    %8 = scf.if %7 -> (f32) {
      scf.yield %cst : f32
    } else {
      %10 = arith.divf %5, %6 : f32
      scf.yield %10 : f32
    }
    cf.br ^bb2(%8 : f32)
  ^bb2(%9: f32):  // pred: ^bb1
    return %9 : f32
  }
  func.func public @f64.no_regroup_mul_div(%arg0: !llvm.ptr, %arg1: f64, %arg2: f64, %arg3: f64) -> f64 attributes {llvm.emit_c_interface} {
    %c1_i64 = arith.constant 1 : i64
    %0 = llvm.alloca %c1_i64 x f64 : (i64) -> !llvm.ptr
    llvm.store %arg1, %0 : f64, !llvm.ptr
    %c1_i64_0 = arith.constant 1 : i64
    %1 = llvm.alloca %c1_i64_0 x f64 : (i64) -> !llvm.ptr
    llvm.store %arg2, %1 : f64, !llvm.ptr
    %c1_i64_1 = arith.constant 1 : i64
    %2 = llvm.alloca %c1_i64_1 x f64 : (i64) -> !llvm.ptr
    llvm.store %arg3, %2 : f64, !llvm.ptr
    cf.br ^bb1
  ^bb1:  // pred: ^bb0
    %3 = llvm.load %0 : !llvm.ptr -> f64
    %4 = llvm.load %1 : !llvm.ptr -> f64
    %5 = arith.mulf %3, %4 : f64
    %6 = llvm.load %2 : !llvm.ptr -> f64
    %cst = arith.constant 0.000000e+00 : f64
    %7 = arith.cmpf oeq, %6, %cst : f64
    %8 = scf.if %7 -> (f64) {
      scf.yield %cst : f64
    } else {
      %10 = arith.divf %5, %6 : f64
      scf.yield %10 : f64
    }
    cf.br ^bb2(%8 : f64)
  ^bb2(%9: f64):  // pred: ^bb1
    return %9 : f64
  }
  func.func public @f32.no_reassociate_add(%arg0: !llvm.ptr, %arg1: f32, %arg2: f32, %arg3: f32, %arg4: f32) -> f32 attributes {llvm.emit_c_interface} {
    %c1_i64 = arith.constant 1 : i64
    %0 = llvm.alloca %c1_i64 x f32 : (i64) -> !llvm.ptr
    llvm.store %arg1, %0 : f32, !llvm.ptr
    %c1_i64_0 = arith.constant 1 : i64
    %1 = llvm.alloca %c1_i64_0 x f32 : (i64) -> !llvm.ptr
    llvm.store %arg2, %1 : f32, !llvm.ptr
    %c1_i64_1 = arith.constant 1 : i64
    %2 = llvm.alloca %c1_i64_1 x f32 : (i64) -> !llvm.ptr
    llvm.store %arg3, %2 : f32, !llvm.ptr
    %c1_i64_2 = arith.constant 1 : i64
    %3 = llvm.alloca %c1_i64_2 x f32 : (i64) -> !llvm.ptr
    llvm.store %arg4, %3 : f32, !llvm.ptr
    cf.br ^bb1
  ^bb1:  // pred: ^bb0
    %4 = llvm.load %0 : !llvm.ptr -> f32
    %5 = llvm.load %1 : !llvm.ptr -> f32
    %6 = arith.addf %4, %5 : f32
    %7 = llvm.load %2 : !llvm.ptr -> f32
    %8 = arith.addf %6, %7 : f32
    %9 = llvm.load %3 : !llvm.ptr -> f32
    %10 = arith.addf %8, %9 : f32
    cf.br ^bb2(%10 : f32)
  ^bb2(%11: f32):  // pred: ^bb1
    return %11 : f32
  }
  func.func public @f64.no_reassociate_add(%arg0: !llvm.ptr, %arg1: f64, %arg2: f64, %arg3: f64, %arg4: f64) -> f64 attributes {llvm.emit_c_interface} {
    %c1_i64 = arith.constant 1 : i64
    %0 = llvm.alloca %c1_i64 x f64 : (i64) -> !llvm.ptr
    llvm.store %arg1, %0 : f64, !llvm.ptr
    %c1_i64_0 = arith.constant 1 : i64
    %1 = llvm.alloca %c1_i64_0 x f64 : (i64) -> !llvm.ptr
    llvm.store %arg2, %1 : f64, !llvm.ptr
    %c1_i64_1 = arith.constant 1 : i64
    %2 = llvm.alloca %c1_i64_1 x f64 : (i64) -> !llvm.ptr
    llvm.store %arg3, %2 : f64, !llvm.ptr
    %c1_i64_2 = arith.constant 1 : i64
    %3 = llvm.alloca %c1_i64_2 x f64 : (i64) -> !llvm.ptr
    llvm.store %arg4, %3 : f64, !llvm.ptr
    cf.br ^bb1
  ^bb1:  // pred: ^bb0
    %4 = llvm.load %0 : !llvm.ptr -> f64
    %5 = llvm.load %1 : !llvm.ptr -> f64
    %6 = arith.addf %4, %5 : f64
    %7 = llvm.load %2 : !llvm.ptr -> f64
    %8 = arith.addf %6, %7 : f64
    %9 = llvm.load %3 : !llvm.ptr -> f64
    %10 = arith.addf %8, %9 : f64
    cf.br ^bb2(%10 : f64)
  ^bb2(%11: f64):  // pred: ^bb1
    return %11 : f64
  }
  func.func public @f32.no_reassociate_mul(%arg0: !llvm.ptr, %arg1: f32, %arg2: f32, %arg3: f32, %arg4: f32) -> f32 attributes {llvm.emit_c_interface} {
    %c1_i64 = arith.constant 1 : i64
    %0 = llvm.alloca %c1_i64 x f32 : (i64) -> !llvm.ptr
    llvm.store %arg1, %0 : f32, !llvm.ptr
    %c1_i64_0 = arith.constant 1 : i64
    %1 = llvm.alloca %c1_i64_0 x f32 : (i64) -> !llvm.ptr
    llvm.store %arg2, %1 : f32, !llvm.ptr
    %c1_i64_1 = arith.constant 1 : i64
    %2 = llvm.alloca %c1_i64_1 x f32 : (i64) -> !llvm.ptr
    llvm.store %arg3, %2 : f32, !llvm.ptr
    %c1_i64_2 = arith.constant 1 : i64
    %3 = llvm.alloca %c1_i64_2 x f32 : (i64) -> !llvm.ptr
    llvm.store %arg4, %3 : f32, !llvm.ptr
    cf.br ^bb1
  ^bb1:  // pred: ^bb0
    %4 = llvm.load %0 : !llvm.ptr -> f32
    %5 = llvm.load %1 : !llvm.ptr -> f32
    %6 = arith.mulf %4, %5 : f32
    %7 = llvm.load %2 : !llvm.ptr -> f32
    %8 = arith.mulf %6, %7 : f32
    %9 = llvm.load %3 : !llvm.ptr -> f32
    %10 = arith.mulf %8, %9 : f32
    cf.br ^bb2(%10 : f32)
  ^bb2(%11: f32):  // pred: ^bb1
    return %11 : f32
  }
  func.func public @f64.no_reassociate_mul(%arg0: !llvm.ptr, %arg1: f64, %arg2: f64, %arg3: f64, %arg4: f64) -> f64 attributes {llvm.emit_c_interface} {
    %c1_i64 = arith.constant 1 : i64
    %0 = llvm.alloca %c1_i64 x f64 : (i64) -> !llvm.ptr
    llvm.store %arg1, %0 : f64, !llvm.ptr
    %c1_i64_0 = arith.constant 1 : i64
    %1 = llvm.alloca %c1_i64_0 x f64 : (i64) -> !llvm.ptr
    llvm.store %arg2, %1 : f64, !llvm.ptr
    %c1_i64_1 = arith.constant 1 : i64
    %2 = llvm.alloca %c1_i64_1 x f64 : (i64) -> !llvm.ptr
    llvm.store %arg3, %2 : f64, !llvm.ptr
    %c1_i64_2 = arith.constant 1 : i64
    %3 = llvm.alloca %c1_i64_2 x f64 : (i64) -> !llvm.ptr
    llvm.store %arg4, %3 : f64, !llvm.ptr
    cf.br ^bb1
  ^bb1:  // pred: ^bb0
    %4 = llvm.load %0 : !llvm.ptr -> f64
    %5 = llvm.load %1 : !llvm.ptr -> f64
    %6 = arith.mulf %4, %5 : f64
    %7 = llvm.load %2 : !llvm.ptr -> f64
    %8 = arith.mulf %6, %7 : f64
    %9 = llvm.load %3 : !llvm.ptr -> f64
    %10 = arith.mulf %8, %9 : f64
    cf.br ^bb2(%10 : f64)
  ^bb2(%11: f64):  // pred: ^bb1
    return %11 : f64
  }
  func.func public @f32.no_fold_div_0(%arg0: !llvm.ptr, %arg1: f32) -> f32 attributes {llvm.emit_c_interface} {
    %c1_i64 = arith.constant 1 : i64
    %0 = llvm.alloca %c1_i64 x f32 : (i64) -> !llvm.ptr
    llvm.store %arg1, %0 : f32, !llvm.ptr
    cf.br ^bb1
  ^bb1:  // pred: ^bb0
    %1 = llvm.load %0 : !llvm.ptr -> f32
    %c0_i32 = arith.constant 0 : i32
    %2 = arith.bitcast %c0_i32 : i32 to f32
    %cst = arith.constant 0.000000e+00 : f32
    %3 = arith.cmpf oeq, %2, %cst : f32
    %4 = scf.if %3 -> (f32) {
      scf.yield %cst : f32
    } else {
      %6 = arith.divf %1, %2 : f32
      scf.yield %6 : f32
    }
    cf.br ^bb2(%4 : f32)
  ^bb2(%5: f32):  // pred: ^bb1
    return %5 : f32
  }
  func.func public @f64.no_fold_div_0(%arg0: !llvm.ptr, %arg1: f64) -> f64 attributes {llvm.emit_c_interface} {
    %c1_i64 = arith.constant 1 : i64
    %0 = llvm.alloca %c1_i64 x f64 : (i64) -> !llvm.ptr
    llvm.store %arg1, %0 : f64, !llvm.ptr
    cf.br ^bb1
  ^bb1:  // pred: ^bb0
    %1 = llvm.load %0 : !llvm.ptr -> f64
    %c0_i64 = arith.constant 0 : i64
    %2 = arith.bitcast %c0_i64 : i64 to f64
    %cst = arith.constant 0.000000e+00 : f64
    %3 = arith.cmpf oeq, %2, %cst : f64
    %4 = scf.if %3 -> (f64) {
      scf.yield %cst : f64
    } else {
      %6 = arith.divf %1, %2 : f64
      scf.yield %6 : f64
    }
    cf.br ^bb2(%4 : f64)
  ^bb2(%5: f64):  // pred: ^bb1
    return %5 : f64
  }
  func.func public @f32.no_fold_div_neg0(%arg0: !llvm.ptr, %arg1: f32) -> f32 attributes {llvm.emit_c_interface} {
    %c1_i64 = arith.constant 1 : i64
    %0 = llvm.alloca %c1_i64 x f32 : (i64) -> !llvm.ptr
    llvm.store %arg1, %0 : f32, !llvm.ptr
    cf.br ^bb1
  ^bb1:  // pred: ^bb0
    %1 = llvm.load %0 : !llvm.ptr -> f32
    %c-2147483648_i32 = arith.constant -2147483648 : i32
    %2 = arith.bitcast %c-2147483648_i32 : i32 to f32
    %cst = arith.constant 0.000000e+00 : f32
    %3 = arith.cmpf oeq, %2, %cst : f32
    %4 = scf.if %3 -> (f32) {
      scf.yield %cst : f32
    } else {
      %6 = arith.divf %1, %2 : f32
      scf.yield %6 : f32
    }
    cf.br ^bb2(%4 : f32)
  ^bb2(%5: f32):  // pred: ^bb1
    return %5 : f32
  }
  func.func public @f64.no_fold_div_neg0(%arg0: !llvm.ptr, %arg1: f64) -> f64 attributes {llvm.emit_c_interface} {
    %c1_i64 = arith.constant 1 : i64
    %0 = llvm.alloca %c1_i64 x f64 : (i64) -> !llvm.ptr
    llvm.store %arg1, %0 : f64, !llvm.ptr
    cf.br ^bb1
  ^bb1:  // pred: ^bb0
    %1 = llvm.load %0 : !llvm.ptr -> f64
    %c-9223372036854775808_i64 = arith.constant -9223372036854775808 : i64
    %2 = arith.bitcast %c-9223372036854775808_i64 : i64 to f64
    %cst = arith.constant 0.000000e+00 : f64
    %3 = arith.cmpf oeq, %2, %cst : f64
    %4 = scf.if %3 -> (f64) {
      scf.yield %cst : f64
    } else {
      %6 = arith.divf %1, %2 : f64
      scf.yield %6 : f64
    }
    cf.br ^bb2(%4 : f64)
  ^bb2(%5: f64):  // pred: ^bb1
    return %5 : f64
  }
  func.func public @f32.no_fold_to_hypot(%arg0: !llvm.ptr, %arg1: f32, %arg2: f32) -> f32 attributes {llvm.emit_c_interface} {
    %c1_i64 = arith.constant 1 : i64
    %0 = llvm.alloca %c1_i64 x f32 : (i64) -> !llvm.ptr
    llvm.store %arg1, %0 : f32, !llvm.ptr
    %c1_i64_0 = arith.constant 1 : i64
    %1 = llvm.alloca %c1_i64_0 x f32 : (i64) -> !llvm.ptr
    llvm.store %arg2, %1 : f32, !llvm.ptr
    cf.br ^bb1
  ^bb1:  // pred: ^bb0
    %2 = llvm.load %0 : !llvm.ptr -> f32
    %3 = llvm.load %0 : !llvm.ptr -> f32
    %4 = arith.mulf %2, %3 : f32
    %5 = llvm.load %1 : !llvm.ptr -> f32
    %6 = llvm.load %1 : !llvm.ptr -> f32
    %7 = arith.mulf %5, %6 : f32
    %8 = arith.addf %4, %7 : f32
    %9 = math.sqrt %8 : f32
    cf.br ^bb2(%9 : f32)
  ^bb2(%10: f32):  // pred: ^bb1
    return %10 : f32
  }
  func.func public @f64.no_fold_to_hypot(%arg0: !llvm.ptr, %arg1: f64, %arg2: f64) -> f64 attributes {llvm.emit_c_interface} {
    %c1_i64 = arith.constant 1 : i64
    %0 = llvm.alloca %c1_i64 x f64 : (i64) -> !llvm.ptr
    llvm.store %arg1, %0 : f64, !llvm.ptr
    %c1_i64_0 = arith.constant 1 : i64
    %1 = llvm.alloca %c1_i64_0 x f64 : (i64) -> !llvm.ptr
    llvm.store %arg2, %1 : f64, !llvm.ptr
    cf.br ^bb1
  ^bb1:  // pred: ^bb0
    %2 = llvm.load %0 : !llvm.ptr -> f64
    %3 = llvm.load %0 : !llvm.ptr -> f64
    %4 = arith.mulf %2, %3 : f64
    %5 = llvm.load %1 : !llvm.ptr -> f64
    %6 = llvm.load %1 : !llvm.ptr -> f64
    %7 = arith.mulf %5, %6 : f64
    %8 = arith.addf %4, %7 : f64
    %9 = math.sqrt %8 : f64
    cf.br ^bb2(%9 : f64)
  ^bb2(%10: f64):  // pred: ^bb1
    return %10 : f64
  }
  func.func public @f32.no_approximate_reciprocal(%arg0: !llvm.ptr, %arg1: f32) -> f32 attributes {llvm.emit_c_interface} {
    %c1_i64 = arith.constant 1 : i64
    %0 = llvm.alloca %c1_i64 x f32 : (i64) -> !llvm.ptr
    llvm.store %arg1, %0 : f32, !llvm.ptr
    cf.br ^bb1
  ^bb1:  // pred: ^bb0
    %c1065353216_i32 = arith.constant 1065353216 : i32
    %1 = arith.bitcast %c1065353216_i32 : i32 to f32
    %2 = llvm.load %0 : !llvm.ptr -> f32
    %cst = arith.constant 0.000000e+00 : f32
    %3 = arith.cmpf oeq, %2, %cst : f32
    %4 = scf.if %3 -> (f32) {
      scf.yield %cst : f32
    } else {
      %6 = arith.divf %1, %2 : f32
      scf.yield %6 : f32
    }
    cf.br ^bb2(%4 : f32)
  ^bb2(%5: f32):  // pred: ^bb1
    return %5 : f32
  }
  func.func public @f32.no_approximate_reciprocal_sqrt(%arg0: !llvm.ptr, %arg1: f32) -> f32 attributes {llvm.emit_c_interface} {
    %c1_i64 = arith.constant 1 : i64
    %0 = llvm.alloca %c1_i64 x f32 : (i64) -> !llvm.ptr
    llvm.store %arg1, %0 : f32, !llvm.ptr
    cf.br ^bb1
  ^bb1:  // pred: ^bb0
    %c1065353216_i32 = arith.constant 1065353216 : i32
    %1 = arith.bitcast %c1065353216_i32 : i32 to f32
    %2 = llvm.load %0 : !llvm.ptr -> f32
    %3 = math.sqrt %2 : f32
    %cst = arith.constant 0.000000e+00 : f32
    %4 = arith.cmpf oeq, %3, %cst : f32
    %5 = scf.if %4 -> (f32) {
      scf.yield %cst : f32
    } else {
      %7 = arith.divf %1, %3 : f32
      scf.yield %7 : f32
    }
    cf.br ^bb2(%5 : f32)
  ^bb2(%6: f32):  // pred: ^bb1
    return %6 : f32
  }
  func.func public @f64.no_fuse_reciprocal_sqrt(%arg0: !llvm.ptr, %arg1: f64) -> f64 attributes {llvm.emit_c_interface} {
    %c1_i64 = arith.constant 1 : i64
    %0 = llvm.alloca %c1_i64 x f64 : (i64) -> !llvm.ptr
    llvm.store %arg1, %0 : f64, !llvm.ptr
    cf.br ^bb1
  ^bb1:  // pred: ^bb0
    %c4607182418800017408_i64 = arith.constant 4607182418800017408 : i64
    %1 = arith.bitcast %c4607182418800017408_i64 : i64 to f64
    %2 = llvm.load %0 : !llvm.ptr -> f64
    %3 = math.sqrt %2 : f64
    %cst = arith.constant 0.000000e+00 : f64
    %4 = arith.cmpf oeq, %3, %cst : f64
    %5 = scf.if %4 -> (f64) {
      scf.yield %cst : f64
    } else {
      %7 = arith.divf %1, %3 : f64
      scf.yield %7 : f64
    }
    cf.br ^bb2(%5 : f64)
  ^bb2(%6: f64):  // pred: ^bb1
    return %6 : f64
  }
  func.func public @f32.no_approximate_sqrt_reciprocal(%arg0: !llvm.ptr, %arg1: f32) -> f32 attributes {llvm.emit_c_interface} {
    %c1_i64 = arith.constant 1 : i64
    %0 = llvm.alloca %c1_i64 x f32 : (i64) -> !llvm.ptr
    llvm.store %arg1, %0 : f32, !llvm.ptr
    cf.br ^bb1
  ^bb1:  // pred: ^bb0
    %c1065353216_i32 = arith.constant 1065353216 : i32
    %1 = arith.bitcast %c1065353216_i32 : i32 to f32
    %2 = llvm.load %0 : !llvm.ptr -> f32
    %cst = arith.constant 0.000000e+00 : f32
    %3 = arith.cmpf oeq, %2, %cst : f32
    %4 = scf.if %3 -> (f32) {
      scf.yield %cst : f32
    } else {
      %7 = arith.divf %1, %2 : f32
      scf.yield %7 : f32
    }
    %5 = math.sqrt %4 : f32
    cf.br ^bb2(%5 : f32)
  ^bb2(%6: f32):  // pred: ^bb1
    return %6 : f32
  }
  func.func public @i32.no_fold_f32_s(%arg0: !llvm.ptr, %arg1: i32) -> i32 attributes {llvm.emit_c_interface} {
    %c1_i64 = arith.constant 1 : i64
    %0 = llvm.alloca %c1_i64 x i32 : (i64) -> !llvm.ptr
    llvm.store %arg1, %0 : i32, !llvm.ptr
    cf.br ^bb1
  ^bb1:  // pred: ^bb0
    %1 = llvm.load %0 : !llvm.ptr -> i32
    %2 = arith.sitofp %1 : i32 to f32
    %3 = arith.fptosi %2 : f32 to i32
    cf.br ^bb2(%3 : i32)
  ^bb2(%4: i32):  // pred: ^bb1
    return %4 : i32
  }
  func.func public @i32.no_fold_f32_u(%arg0: !llvm.ptr, %arg1: i32) -> i32 attributes {llvm.emit_c_interface} {
    %c1_i64 = arith.constant 1 : i64
    %0 = llvm.alloca %c1_i64 x i32 : (i64) -> !llvm.ptr
    llvm.store %arg1, %0 : i32, !llvm.ptr
    cf.br ^bb1
  ^bb1:  // pred: ^bb0
    %1 = llvm.load %0 : !llvm.ptr -> i32
    %2 = arith.uitofp %1 : i32 to f32
    %3 = arith.fptoui %2 : f32 to i32
    cf.br ^bb2(%3 : i32)
  ^bb2(%4: i32):  // pred: ^bb1
    return %4 : i32
  }
  func.func public @i64.no_fold_f64_s(%arg0: !llvm.ptr, %arg1: i64) -> i64 attributes {llvm.emit_c_interface} {
    %c1_i64 = arith.constant 1 : i64
    %0 = llvm.alloca %c1_i64 x i64 : (i64) -> !llvm.ptr
    llvm.store %arg1, %0 : i64, !llvm.ptr
    cf.br ^bb1
  ^bb1:  // pred: ^bb0
    %1 = llvm.load %0 : !llvm.ptr -> i64
    %2 = arith.sitofp %1 : i64 to f64
    %3 = arith.fptosi %2 : f64 to i64
    cf.br ^bb2(%3 : i64)
  ^bb2(%4: i64):  // pred: ^bb1
    return %4 : i64
  }
  func.func public @i64.no_fold_f64_u(%arg0: !llvm.ptr, %arg1: i64) -> i64 attributes {llvm.emit_c_interface} {
    %c1_i64 = arith.constant 1 : i64
    %0 = llvm.alloca %c1_i64 x i64 : (i64) -> !llvm.ptr
    llvm.store %arg1, %0 : i64, !llvm.ptr
    cf.br ^bb1
  ^bb1:  // pred: ^bb0
    %1 = llvm.load %0 : !llvm.ptr -> i64
    %2 = arith.uitofp %1 : i64 to f64
    %3 = arith.fptoui %2 : f64 to i64
    cf.br ^bb2(%3 : i64)
  ^bb2(%4: i64):  // pred: ^bb1
    return %4 : i64
  }
  func.func public @f32.no_fold_add_sub(%arg0: !llvm.ptr, %arg1: f32, %arg2: f32) -> f32 attributes {llvm.emit_c_interface} {
    %c1_i64 = arith.constant 1 : i64
    %0 = llvm.alloca %c1_i64 x f32 : (i64) -> !llvm.ptr
    llvm.store %arg1, %0 : f32, !llvm.ptr
    %c1_i64_0 = arith.constant 1 : i64
    %1 = llvm.alloca %c1_i64_0 x f32 : (i64) -> !llvm.ptr
    llvm.store %arg2, %1 : f32, !llvm.ptr
    cf.br ^bb1
  ^bb1:  // pred: ^bb0
    %2 = llvm.load %0 : !llvm.ptr -> f32
    %3 = llvm.load %1 : !llvm.ptr -> f32
    %4 = arith.addf %2, %3 : f32
    %5 = llvm.load %1 : !llvm.ptr -> f32
    %6 = arith.subf %4, %5 : f32
    cf.br ^bb2(%6 : f32)
  ^bb2(%7: f32):  // pred: ^bb1
    return %7 : f32
  }
  func.func public @f64.no_fold_add_sub(%arg0: !llvm.ptr, %arg1: f64, %arg2: f64) -> f64 attributes {llvm.emit_c_interface} {
    %c1_i64 = arith.constant 1 : i64
    %0 = llvm.alloca %c1_i64 x f64 : (i64) -> !llvm.ptr
    llvm.store %arg1, %0 : f64, !llvm.ptr
    %c1_i64_0 = arith.constant 1 : i64
    %1 = llvm.alloca %c1_i64_0 x f64 : (i64) -> !llvm.ptr
    llvm.store %arg2, %1 : f64, !llvm.ptr
    cf.br ^bb1
  ^bb1:  // pred: ^bb0
    %2 = llvm.load %0 : !llvm.ptr -> f64
    %3 = llvm.load %1 : !llvm.ptr -> f64
    %4 = arith.addf %2, %3 : f64
    %5 = llvm.load %1 : !llvm.ptr -> f64
    %6 = arith.subf %4, %5 : f64
    cf.br ^bb2(%6 : f64)
  ^bb2(%7: f64):  // pred: ^bb1
    return %7 : f64
  }
  func.func public @f32.no_fold_sub_add(%arg0: !llvm.ptr, %arg1: f32, %arg2: f32) -> f32 attributes {llvm.emit_c_interface} {
    %c1_i64 = arith.constant 1 : i64
    %0 = llvm.alloca %c1_i64 x f32 : (i64) -> !llvm.ptr
    llvm.store %arg1, %0 : f32, !llvm.ptr
    %c1_i64_0 = arith.constant 1 : i64
    %1 = llvm.alloca %c1_i64_0 x f32 : (i64) -> !llvm.ptr
    llvm.store %arg2, %1 : f32, !llvm.ptr
    cf.br ^bb1
  ^bb1:  // pred: ^bb0
    %2 = llvm.load %0 : !llvm.ptr -> f32
    %3 = llvm.load %1 : !llvm.ptr -> f32
    %4 = arith.subf %2, %3 : f32
    %5 = llvm.load %1 : !llvm.ptr -> f32
    %6 = arith.addf %4, %5 : f32
    cf.br ^bb2(%6 : f32)
  ^bb2(%7: f32):  // pred: ^bb1
    return %7 : f32
  }
  func.func public @f64.no_fold_sub_add(%arg0: !llvm.ptr, %arg1: f64, %arg2: f64) -> f64 attributes {llvm.emit_c_interface} {
    %c1_i64 = arith.constant 1 : i64
    %0 = llvm.alloca %c1_i64 x f64 : (i64) -> !llvm.ptr
    llvm.store %arg1, %0 : f64, !llvm.ptr
    %c1_i64_0 = arith.constant 1 : i64
    %1 = llvm.alloca %c1_i64_0 x f64 : (i64) -> !llvm.ptr
    llvm.store %arg2, %1 : f64, !llvm.ptr
    cf.br ^bb1
  ^bb1:  // pred: ^bb0
    %2 = llvm.load %0 : !llvm.ptr -> f64
    %3 = llvm.load %1 : !llvm.ptr -> f64
    %4 = arith.subf %2, %3 : f64
    %5 = llvm.load %1 : !llvm.ptr -> f64
    %6 = arith.addf %4, %5 : f64
    cf.br ^bb2(%6 : f64)
  ^bb2(%7: f64):  // pred: ^bb1
    return %7 : f64
  }
  func.func public @f32.no_fold_mul_div(%arg0: !llvm.ptr, %arg1: f32, %arg2: f32) -> f32 attributes {llvm.emit_c_interface} {
    %c1_i64 = arith.constant 1 : i64
    %0 = llvm.alloca %c1_i64 x f32 : (i64) -> !llvm.ptr
    llvm.store %arg1, %0 : f32, !llvm.ptr
    %c1_i64_0 = arith.constant 1 : i64
    %1 = llvm.alloca %c1_i64_0 x f32 : (i64) -> !llvm.ptr
    llvm.store %arg2, %1 : f32, !llvm.ptr
    cf.br ^bb1
  ^bb1:  // pred: ^bb0
    %2 = llvm.load %0 : !llvm.ptr -> f32
    %3 = llvm.load %1 : !llvm.ptr -> f32
    %4 = arith.mulf %2, %3 : f32
    %5 = llvm.load %1 : !llvm.ptr -> f32
    %cst = arith.constant 0.000000e+00 : f32
    %6 = arith.cmpf oeq, %5, %cst : f32
    %7 = scf.if %6 -> (f32) {
      scf.yield %cst : f32
    } else {
      %9 = arith.divf %4, %5 : f32
      scf.yield %9 : f32
    }
    cf.br ^bb2(%7 : f32)
  ^bb2(%8: f32):  // pred: ^bb1
    return %8 : f32
  }
  func.func public @f64.no_fold_mul_div(%arg0: !llvm.ptr, %arg1: f64, %arg2: f64) -> f64 attributes {llvm.emit_c_interface} {
    %c1_i64 = arith.constant 1 : i64
    %0 = llvm.alloca %c1_i64 x f64 : (i64) -> !llvm.ptr
    llvm.store %arg1, %0 : f64, !llvm.ptr
    %c1_i64_0 = arith.constant 1 : i64
    %1 = llvm.alloca %c1_i64_0 x f64 : (i64) -> !llvm.ptr
    llvm.store %arg2, %1 : f64, !llvm.ptr
    cf.br ^bb1
  ^bb1:  // pred: ^bb0
    %2 = llvm.load %0 : !llvm.ptr -> f64
    %3 = llvm.load %1 : !llvm.ptr -> f64
    %4 = arith.mulf %2, %3 : f64
    %5 = llvm.load %1 : !llvm.ptr -> f64
    %cst = arith.constant 0.000000e+00 : f64
    %6 = arith.cmpf oeq, %5, %cst : f64
    %7 = scf.if %6 -> (f64) {
      scf.yield %cst : f64
    } else {
      %9 = arith.divf %4, %5 : f64
      scf.yield %9 : f64
    }
    cf.br ^bb2(%7 : f64)
  ^bb2(%8: f64):  // pred: ^bb1
    return %8 : f64
  }
  func.func public @f32.no_fold_div_mul(%arg0: !llvm.ptr, %arg1: f32, %arg2: f32) -> f32 attributes {llvm.emit_c_interface} {
    %c1_i64 = arith.constant 1 : i64
    %0 = llvm.alloca %c1_i64 x f32 : (i64) -> !llvm.ptr
    llvm.store %arg1, %0 : f32, !llvm.ptr
    %c1_i64_0 = arith.constant 1 : i64
    %1 = llvm.alloca %c1_i64_0 x f32 : (i64) -> !llvm.ptr
    llvm.store %arg2, %1 : f32, !llvm.ptr
    cf.br ^bb1
  ^bb1:  // pred: ^bb0
    %2 = llvm.load %0 : !llvm.ptr -> f32
    %3 = llvm.load %1 : !llvm.ptr -> f32
    %cst = arith.constant 0.000000e+00 : f32
    %4 = arith.cmpf oeq, %3, %cst : f32
    %5 = scf.if %4 -> (f32) {
      scf.yield %cst : f32
    } else {
      %9 = arith.divf %2, %3 : f32
      scf.yield %9 : f32
    }
    %6 = llvm.load %1 : !llvm.ptr -> f32
    %7 = arith.mulf %5, %6 : f32
    cf.br ^bb2(%7 : f32)
  ^bb2(%8: f32):  // pred: ^bb1
    return %8 : f32
  }
  func.func public @f64.no_fold_div_mul(%arg0: !llvm.ptr, %arg1: f64, %arg2: f64) -> f64 attributes {llvm.emit_c_interface} {
    %c1_i64 = arith.constant 1 : i64
    %0 = llvm.alloca %c1_i64 x f64 : (i64) -> !llvm.ptr
    llvm.store %arg1, %0 : f64, !llvm.ptr
    %c1_i64_0 = arith.constant 1 : i64
    %1 = llvm.alloca %c1_i64_0 x f64 : (i64) -> !llvm.ptr
    llvm.store %arg2, %1 : f64, !llvm.ptr
    cf.br ^bb1
  ^bb1:  // pred: ^bb0
    %2 = llvm.load %0 : !llvm.ptr -> f64
    %3 = llvm.load %1 : !llvm.ptr -> f64
    %cst = arith.constant 0.000000e+00 : f64
    %4 = arith.cmpf oeq, %3, %cst : f64
    %5 = scf.if %4 -> (f64) {
      scf.yield %cst : f64
    } else {
      %9 = arith.divf %2, %3 : f64
      scf.yield %9 : f64
    }
    %6 = llvm.load %1 : !llvm.ptr -> f64
    %7 = arith.mulf %5, %6 : f64
    cf.br ^bb2(%7 : f64)
  ^bb2(%8: f64):  // pred: ^bb1
    return %8 : f64
  }
  func.func public @f32.no_fold_div2_mul2(%arg0: !llvm.ptr, %arg1: f32) -> f32 attributes {llvm.emit_c_interface} {
    %c1_i64 = arith.constant 1 : i64
    %0 = llvm.alloca %c1_i64 x f32 : (i64) -> !llvm.ptr
    llvm.store %arg1, %0 : f32, !llvm.ptr
    cf.br ^bb1
  ^bb1:  // pred: ^bb0
    %1 = llvm.load %0 : !llvm.ptr -> f32
    %c1073741824_i32 = arith.constant 1073741824 : i32
    %2 = arith.bitcast %c1073741824_i32 : i32 to f32
    %cst = arith.constant 0.000000e+00 : f32
    %3 = arith.cmpf oeq, %2, %cst : f32
    %4 = scf.if %3 -> (f32) {
      scf.yield %cst : f32
    } else {
      %8 = arith.divf %1, %2 : f32
      scf.yield %8 : f32
    }
    %c1073741824_i32_0 = arith.constant 1073741824 : i32
    %5 = arith.bitcast %c1073741824_i32_0 : i32 to f32
    %6 = arith.mulf %4, %5 : f32
    cf.br ^bb2(%6 : f32)
  ^bb2(%7: f32):  // pred: ^bb1
    return %7 : f32
  }
  func.func public @f64.no_fold_div2_mul2(%arg0: !llvm.ptr, %arg1: f64) -> f64 attributes {llvm.emit_c_interface} {
    %c1_i64 = arith.constant 1 : i64
    %0 = llvm.alloca %c1_i64 x f64 : (i64) -> !llvm.ptr
    llvm.store %arg1, %0 : f64, !llvm.ptr
    cf.br ^bb1
  ^bb1:  // pred: ^bb0
    %1 = llvm.load %0 : !llvm.ptr -> f64
    %c4611686018427387904_i64 = arith.constant 4611686018427387904 : i64
    %2 = arith.bitcast %c4611686018427387904_i64 : i64 to f64
    %cst = arith.constant 0.000000e+00 : f64
    %3 = arith.cmpf oeq, %2, %cst : f64
    %4 = scf.if %3 -> (f64) {
      scf.yield %cst : f64
    } else {
      %8 = arith.divf %1, %2 : f64
      scf.yield %8 : f64
    }
    %c4611686018427387904_i64_0 = arith.constant 4611686018427387904 : i64
    %5 = arith.bitcast %c4611686018427387904_i64_0 : i64 to f64
    %6 = arith.mulf %4, %5 : f64
    cf.br ^bb2(%6 : f64)
  ^bb2(%7: f64):  // pred: ^bb1
    return %7 : f64
  }
  func.func public @no_fold_demote_promote(%arg0: !llvm.ptr, %arg1: f64) -> f64 attributes {llvm.emit_c_interface} {
    %c1_i64 = arith.constant 1 : i64
    %0 = llvm.alloca %c1_i64 x f64 : (i64) -> !llvm.ptr
    llvm.store %arg1, %0 : f64, !llvm.ptr
    cf.br ^bb1
  ^bb1:  // pred: ^bb0
    %1 = llvm.load %0 : !llvm.ptr -> f64
    %2 = arith.truncf %1 : f64 to f32
    %3 = arith.extf %2 : f32 to f64
    cf.br ^bb2(%3 : f64)
  ^bb2(%4: f64):  // pred: ^bb1
    return %4 : f64
  }
  func.func @f69(%arg0: !llvm.ptr, %arg1: f32) -> f32 {
    %c1_i64 = arith.constant 1 : i64
    %0 = llvm.alloca %c1_i64 x f32 : (i64) -> !llvm.ptr
    llvm.store %arg1, %0 : f32, !llvm.ptr
    cf.br ^bb1
  ^bb1:  // pred: ^bb0
    %1 = llvm.load %0 : !llvm.ptr -> f32
    %2 = arith.extf %1 : f32 to f64
    %3 = arith.truncf %2 : f64 to f32
    cf.br ^bb2(%3 : f32)
  ^bb2(%4: f32):  // pred: ^bb1
    return %4 : f32
  }
  func.func public @no_demote_mixed_add(%arg0: !llvm.ptr, %arg1: f64, %arg2: f32) -> f32 attributes {llvm.emit_c_interface} {
    %c1_i64 = arith.constant 1 : i64
    %0 = llvm.alloca %c1_i64 x f64 : (i64) -> !llvm.ptr
    llvm.store %arg1, %0 : f64, !llvm.ptr
    %c1_i64_0 = arith.constant 1 : i64
    %1 = llvm.alloca %c1_i64_0 x f32 : (i64) -> !llvm.ptr
    llvm.store %arg2, %1 : f32, !llvm.ptr
    cf.br ^bb1
  ^bb1:  // pred: ^bb0
    %2 = llvm.load %0 : !llvm.ptr -> f64
    %3 = llvm.load %1 : !llvm.ptr -> f32
    %4 = arith.extf %3 : f32 to f64
    %5 = arith.addf %2, %4 : f64
    %6 = arith.truncf %5 : f64 to f32
    cf.br ^bb2(%6 : f32)
  ^bb2(%7: f32):  // pred: ^bb1
    return %7 : f32
  }
  func.func public @no_demote_mixed_add_commuted(%arg0: !llvm.ptr, %arg1: f32, %arg2: f64) -> f32 attributes {llvm.emit_c_interface} {
    %c1_i64 = arith.constant 1 : i64
    %0 = llvm.alloca %c1_i64 x f32 : (i64) -> !llvm.ptr
    llvm.store %arg1, %0 : f32, !llvm.ptr
    %c1_i64_0 = arith.constant 1 : i64
    %1 = llvm.alloca %c1_i64_0 x f64 : (i64) -> !llvm.ptr
    llvm.store %arg2, %1 : f64, !llvm.ptr
    cf.br ^bb1
  ^bb1:  // pred: ^bb0
    %2 = llvm.load %0 : !llvm.ptr -> f32
    %3 = arith.extf %2 : f32 to f64
    %4 = llvm.load %1 : !llvm.ptr -> f64
    %5 = arith.addf %3, %4 : f64
    %6 = arith.truncf %5 : f64 to f32
    cf.br ^bb2(%6 : f32)
  ^bb2(%7: f32):  // pred: ^bb1
    return %7 : f32
  }
  func.func public @no_demote_mixed_sub(%arg0: !llvm.ptr, %arg1: f64, %arg2: f32) -> f32 attributes {llvm.emit_c_interface} {
    %c1_i64 = arith.constant 1 : i64
    %0 = llvm.alloca %c1_i64 x f64 : (i64) -> !llvm.ptr
    llvm.store %arg1, %0 : f64, !llvm.ptr
    %c1_i64_0 = arith.constant 1 : i64
    %1 = llvm.alloca %c1_i64_0 x f32 : (i64) -> !llvm.ptr
    llvm.store %arg2, %1 : f32, !llvm.ptr
    cf.br ^bb1
  ^bb1:  // pred: ^bb0
    %2 = llvm.load %0 : !llvm.ptr -> f64
    %3 = llvm.load %1 : !llvm.ptr -> f32
    %4 = arith.extf %3 : f32 to f64
    %5 = arith.subf %2, %4 : f64
    %6 = arith.truncf %5 : f64 to f32
    cf.br ^bb2(%6 : f32)
  ^bb2(%7: f32):  // pred: ^bb1
    return %7 : f32
  }
  func.func public @no_demote_mixed_sub_commuted(%arg0: !llvm.ptr, %arg1: f32, %arg2: f64) -> f32 attributes {llvm.emit_c_interface} {
    %c1_i64 = arith.constant 1 : i64
    %0 = llvm.alloca %c1_i64 x f32 : (i64) -> !llvm.ptr
    llvm.store %arg1, %0 : f32, !llvm.ptr
    %c1_i64_0 = arith.constant 1 : i64
    %1 = llvm.alloca %c1_i64_0 x f64 : (i64) -> !llvm.ptr
    llvm.store %arg2, %1 : f64, !llvm.ptr
    cf.br ^bb1
  ^bb1:  // pred: ^bb0
    %2 = llvm.load %0 : !llvm.ptr -> f32
    %3 = arith.extf %2 : f32 to f64
    %4 = llvm.load %1 : !llvm.ptr -> f64
    %5 = arith.subf %3, %4 : f64
    %6 = arith.truncf %5 : f64 to f32
    cf.br ^bb2(%6 : f32)
  ^bb2(%7: f32):  // pred: ^bb1
    return %7 : f32
  }
  func.func public @no_demote_mixed_mul(%arg0: !llvm.ptr, %arg1: f64, %arg2: f32) -> f32 attributes {llvm.emit_c_interface} {
    %c1_i64 = arith.constant 1 : i64
    %0 = llvm.alloca %c1_i64 x f64 : (i64) -> !llvm.ptr
    llvm.store %arg1, %0 : f64, !llvm.ptr
    %c1_i64_0 = arith.constant 1 : i64
    %1 = llvm.alloca %c1_i64_0 x f32 : (i64) -> !llvm.ptr
    llvm.store %arg2, %1 : f32, !llvm.ptr
    cf.br ^bb1
  ^bb1:  // pred: ^bb0
    %2 = llvm.load %0 : !llvm.ptr -> f64
    %3 = llvm.load %1 : !llvm.ptr -> f32
    %4 = arith.extf %3 : f32 to f64
    %5 = arith.mulf %2, %4 : f64
    %6 = arith.truncf %5 : f64 to f32
    cf.br ^bb2(%6 : f32)
  ^bb2(%7: f32):  // pred: ^bb1
    return %7 : f32
  }
  func.func public @no_demote_mixed_mul_commuted(%arg0: !llvm.ptr, %arg1: f32, %arg2: f64) -> f32 attributes {llvm.emit_c_interface} {
    %c1_i64 = arith.constant 1 : i64
    %0 = llvm.alloca %c1_i64 x f32 : (i64) -> !llvm.ptr
    llvm.store %arg1, %0 : f32, !llvm.ptr
    %c1_i64_0 = arith.constant 1 : i64
    %1 = llvm.alloca %c1_i64_0 x f64 : (i64) -> !llvm.ptr
    llvm.store %arg2, %1 : f64, !llvm.ptr
    cf.br ^bb1
  ^bb1:  // pred: ^bb0
    %2 = llvm.load %0 : !llvm.ptr -> f32
    %3 = arith.extf %2 : f32 to f64
    %4 = llvm.load %1 : !llvm.ptr -> f64
    %5 = arith.mulf %3, %4 : f64
    %6 = arith.truncf %5 : f64 to f32
    cf.br ^bb2(%6 : f32)
  ^bb2(%7: f32):  // pred: ^bb1
    return %7 : f32
  }
  func.func public @no_demote_mixed_div(%arg0: !llvm.ptr, %arg1: f64, %arg2: f32) -> f32 attributes {llvm.emit_c_interface} {
    %c1_i64 = arith.constant 1 : i64
    %0 = llvm.alloca %c1_i64 x f64 : (i64) -> !llvm.ptr
    llvm.store %arg1, %0 : f64, !llvm.ptr
    %c1_i64_0 = arith.constant 1 : i64
    %1 = llvm.alloca %c1_i64_0 x f32 : (i64) -> !llvm.ptr
    llvm.store %arg2, %1 : f32, !llvm.ptr
    cf.br ^bb1
  ^bb1:  // pred: ^bb0
    %2 = llvm.load %0 : !llvm.ptr -> f64
    %3 = llvm.load %1 : !llvm.ptr -> f32
    %4 = arith.extf %3 : f32 to f64
    %cst = arith.constant 0.000000e+00 : f64
    %5 = arith.cmpf oeq, %4, %cst : f64
    %6 = scf.if %5 -> (f64) {
      scf.yield %cst : f64
    } else {
      %9 = arith.divf %2, %4 : f64
      scf.yield %9 : f64
    }
    %7 = arith.truncf %6 : f64 to f32
    cf.br ^bb2(%7 : f32)
  ^bb2(%8: f32):  // pred: ^bb1
    return %8 : f32
  }
  func.func public @no_demote_mixed_div_commuted(%arg0: !llvm.ptr, %arg1: f32, %arg2: f64) -> f32 attributes {llvm.emit_c_interface} {
    %c1_i64 = arith.constant 1 : i64
    %0 = llvm.alloca %c1_i64 x f32 : (i64) -> !llvm.ptr
    llvm.store %arg1, %0 : f32, !llvm.ptr
    %c1_i64_0 = arith.constant 1 : i64
    %1 = llvm.alloca %c1_i64_0 x f64 : (i64) -> !llvm.ptr
    llvm.store %arg2, %1 : f64, !llvm.ptr
    cf.br ^bb1
  ^bb1:  // pred: ^bb0
    %2 = llvm.load %0 : !llvm.ptr -> f32
    %3 = arith.extf %2 : f32 to f64
    %4 = llvm.load %1 : !llvm.ptr -> f64
    %cst = arith.constant 0.000000e+00 : f64
    %5 = arith.cmpf oeq, %4, %cst : f64
    %6 = scf.if %5 -> (f64) {
      scf.yield %cst : f64
    } else {
      %9 = arith.divf %3, %4 : f64
      scf.yield %9 : f64
    }
    %7 = arith.truncf %6 : f64 to f32
    cf.br ^bb2(%7 : f32)
  ^bb2(%8: f32):  // pred: ^bb1
    return %8 : f32
  }
  func.func public @f32.i32.no_fold_trunc_s_convert_s(%arg0: !llvm.ptr, %arg1: f32) -> f32 attributes {llvm.emit_c_interface} {
    %c1_i64 = arith.constant 1 : i64
    %0 = llvm.alloca %c1_i64 x f32 : (i64) -> !llvm.ptr
    llvm.store %arg1, %0 : f32, !llvm.ptr
    cf.br ^bb1
  ^bb1:  // pred: ^bb0
    %1 = llvm.load %0 : !llvm.ptr -> f32
    %2 = arith.fptosi %1 : f32 to i32
    %3 = arith.sitofp %2 : i32 to f32
    cf.br ^bb2(%3 : f32)
  ^bb2(%4: f32):  // pred: ^bb1
    return %4 : f32
  }
  func.func public @f32.i32.no_fold_trunc_u_convert_s(%arg0: !llvm.ptr, %arg1: f32) -> f32 attributes {llvm.emit_c_interface} {
    %c1_i64 = arith.constant 1 : i64
    %0 = llvm.alloca %c1_i64 x f32 : (i64) -> !llvm.ptr
    llvm.store %arg1, %0 : f32, !llvm.ptr
    cf.br ^bb1
  ^bb1:  // pred: ^bb0
    %1 = llvm.load %0 : !llvm.ptr -> f32
    %2 = arith.fptoui %1 : f32 to i32
    %3 = arith.sitofp %2 : i32 to f32
    cf.br ^bb2(%3 : f32)
  ^bb2(%4: f32):  // pred: ^bb1
    return %4 : f32
  }
  func.func public @f32.i32.no_fold_trunc_s_convert_u(%arg0: !llvm.ptr, %arg1: f32) -> f32 attributes {llvm.emit_c_interface} {
    %c1_i64 = arith.constant 1 : i64
    %0 = llvm.alloca %c1_i64 x f32 : (i64) -> !llvm.ptr
    llvm.store %arg1, %0 : f32, !llvm.ptr
    cf.br ^bb1
  ^bb1:  // pred: ^bb0
    %1 = llvm.load %0 : !llvm.ptr -> f32
    %2 = arith.fptosi %1 : f32 to i32
    %3 = arith.uitofp %2 : i32 to f32
    cf.br ^bb2(%3 : f32)
  ^bb2(%4: f32):  // pred: ^bb1
    return %4 : f32
  }
  func.func public @f32.i32.no_fold_trunc_u_convert_u(%arg0: !llvm.ptr, %arg1: f32) -> f32 attributes {llvm.emit_c_interface} {
    %c1_i64 = arith.constant 1 : i64
    %0 = llvm.alloca %c1_i64 x f32 : (i64) -> !llvm.ptr
    llvm.store %arg1, %0 : f32, !llvm.ptr
    cf.br ^bb1
  ^bb1:  // pred: ^bb0
    %1 = llvm.load %0 : !llvm.ptr -> f32
    %2 = arith.fptoui %1 : f32 to i32
    %3 = arith.uitofp %2 : i32 to f32
    cf.br ^bb2(%3 : f32)
  ^bb2(%4: f32):  // pred: ^bb1
    return %4 : f32
  }
  func.func public @f64.i32.no_fold_trunc_s_convert_s(%arg0: !llvm.ptr, %arg1: f64) -> f64 attributes {llvm.emit_c_interface} {
    %c1_i64 = arith.constant 1 : i64
    %0 = llvm.alloca %c1_i64 x f64 : (i64) -> !llvm.ptr
    llvm.store %arg1, %0 : f64, !llvm.ptr
    cf.br ^bb1
  ^bb1:  // pred: ^bb0
    %1 = llvm.load %0 : !llvm.ptr -> f64
    %2 = arith.fptosi %1 : f64 to i32
    %3 = arith.sitofp %2 : i32 to f64
    cf.br ^bb2(%3 : f64)
  ^bb2(%4: f64):  // pred: ^bb1
    return %4 : f64
  }
  func.func public @f64.i32.no_fold_trunc_u_convert_s(%arg0: !llvm.ptr, %arg1: f64) -> f64 attributes {llvm.emit_c_interface} {
    %c1_i64 = arith.constant 1 : i64
    %0 = llvm.alloca %c1_i64 x f64 : (i64) -> !llvm.ptr
    llvm.store %arg1, %0 : f64, !llvm.ptr
    cf.br ^bb1
  ^bb1:  // pred: ^bb0
    %1 = llvm.load %0 : !llvm.ptr -> f64
    %2 = arith.fptoui %1 : f64 to i32
    %3 = arith.sitofp %2 : i32 to f64
    cf.br ^bb2(%3 : f64)
  ^bb2(%4: f64):  // pred: ^bb1
    return %4 : f64
  }
  func.func public @f64.i32.no_fold_trunc_s_convert_u(%arg0: !llvm.ptr, %arg1: f64) -> f64 attributes {llvm.emit_c_interface} {
    %c1_i64 = arith.constant 1 : i64
    %0 = llvm.alloca %c1_i64 x f64 : (i64) -> !llvm.ptr
    llvm.store %arg1, %0 : f64, !llvm.ptr
    cf.br ^bb1
  ^bb1:  // pred: ^bb0
    %1 = llvm.load %0 : !llvm.ptr -> f64
    %2 = arith.fptosi %1 : f64 to i32
    %3 = arith.uitofp %2 : i32 to f64
    cf.br ^bb2(%3 : f64)
  ^bb2(%4: f64):  // pred: ^bb1
    return %4 : f64
  }
  func.func public @f64.i32.no_fold_trunc_u_convert_u(%arg0: !llvm.ptr, %arg1: f64) -> f64 attributes {llvm.emit_c_interface} {
    %c1_i64 = arith.constant 1 : i64
    %0 = llvm.alloca %c1_i64 x f64 : (i64) -> !llvm.ptr
    llvm.store %arg1, %0 : f64, !llvm.ptr
    cf.br ^bb1
  ^bb1:  // pred: ^bb0
    %1 = llvm.load %0 : !llvm.ptr -> f64
    %2 = arith.fptoui %1 : f64 to i32
    %3 = arith.uitofp %2 : i32 to f64
    cf.br ^bb2(%3 : f64)
  ^bb2(%4: f64):  // pred: ^bb1
    return %4 : f64
  }
  func.func public @f32.i64.no_fold_trunc_s_convert_s(%arg0: !llvm.ptr, %arg1: f32) -> f32 attributes {llvm.emit_c_interface} {
    %c1_i64 = arith.constant 1 : i64
    %0 = llvm.alloca %c1_i64 x f32 : (i64) -> !llvm.ptr
    llvm.store %arg1, %0 : f32, !llvm.ptr
    cf.br ^bb1
  ^bb1:  // pred: ^bb0
    %1 = llvm.load %0 : !llvm.ptr -> f32
    %2 = arith.fptosi %1 : f32 to i64
    %3 = arith.sitofp %2 : i64 to f32
    cf.br ^bb2(%3 : f32)
  ^bb2(%4: f32):  // pred: ^bb1
    return %4 : f32
  }
  func.func public @f32.i64.no_fold_trunc_u_convert_s(%arg0: !llvm.ptr, %arg1: f32) -> f32 attributes {llvm.emit_c_interface} {
    %c1_i64 = arith.constant 1 : i64
    %0 = llvm.alloca %c1_i64 x f32 : (i64) -> !llvm.ptr
    llvm.store %arg1, %0 : f32, !llvm.ptr
    cf.br ^bb1
  ^bb1:  // pred: ^bb0
    %1 = llvm.load %0 : !llvm.ptr -> f32
    %2 = arith.fptoui %1 : f32 to i64
    %3 = arith.sitofp %2 : i64 to f32
    cf.br ^bb2(%3 : f32)
  ^bb2(%4: f32):  // pred: ^bb1
    return %4 : f32
  }
  func.func public @f32.i64.no_fold_trunc_s_convert_u(%arg0: !llvm.ptr, %arg1: f32) -> f32 attributes {llvm.emit_c_interface} {
    %c1_i64 = arith.constant 1 : i64
    %0 = llvm.alloca %c1_i64 x f32 : (i64) -> !llvm.ptr
    llvm.store %arg1, %0 : f32, !llvm.ptr
    cf.br ^bb1
  ^bb1:  // pred: ^bb0
    %1 = llvm.load %0 : !llvm.ptr -> f32
    %2 = arith.fptosi %1 : f32 to i64
    %3 = arith.uitofp %2 : i64 to f32
    cf.br ^bb2(%3 : f32)
  ^bb2(%4: f32):  // pred: ^bb1
    return %4 : f32
  }
  func.func public @f32.i64.no_fold_trunc_u_convert_u(%arg0: !llvm.ptr, %arg1: f32) -> f32 attributes {llvm.emit_c_interface} {
    %c1_i64 = arith.constant 1 : i64
    %0 = llvm.alloca %c1_i64 x f32 : (i64) -> !llvm.ptr
    llvm.store %arg1, %0 : f32, !llvm.ptr
    cf.br ^bb1
  ^bb1:  // pred: ^bb0
    %1 = llvm.load %0 : !llvm.ptr -> f32
    %2 = arith.fptoui %1 : f32 to i64
    %3 = arith.uitofp %2 : i64 to f32
    cf.br ^bb2(%3 : f32)
  ^bb2(%4: f32):  // pred: ^bb1
    return %4 : f32
  }
  func.func public @f64.i64.no_fold_trunc_s_convert_s(%arg0: !llvm.ptr, %arg1: f64) -> f64 attributes {llvm.emit_c_interface} {
    %c1_i64 = arith.constant 1 : i64
    %0 = llvm.alloca %c1_i64 x f64 : (i64) -> !llvm.ptr
    llvm.store %arg1, %0 : f64, !llvm.ptr
    cf.br ^bb1
  ^bb1:  // pred: ^bb0
    %1 = llvm.load %0 : !llvm.ptr -> f64
    %2 = arith.fptosi %1 : f64 to i64
    %3 = arith.sitofp %2 : i64 to f64
    cf.br ^bb2(%3 : f64)
  ^bb2(%4: f64):  // pred: ^bb1
    return %4 : f64
  }
  func.func public @f64.i64.no_fold_trunc_u_convert_s(%arg0: !llvm.ptr, %arg1: f64) -> f64 attributes {llvm.emit_c_interface} {
    %c1_i64 = arith.constant 1 : i64
    %0 = llvm.alloca %c1_i64 x f64 : (i64) -> !llvm.ptr
    llvm.store %arg1, %0 : f64, !llvm.ptr
    cf.br ^bb1
  ^bb1:  // pred: ^bb0
    %1 = llvm.load %0 : !llvm.ptr -> f64
    %2 = arith.fptoui %1 : f64 to i64
    %3 = arith.sitofp %2 : i64 to f64
    cf.br ^bb2(%3 : f64)
  ^bb2(%4: f64):  // pred: ^bb1
    return %4 : f64
  }
  func.func public @f64.i64.no_fold_trunc_s_convert_u(%arg0: !llvm.ptr, %arg1: f64) -> f64 attributes {llvm.emit_c_interface} {
    %c1_i64 = arith.constant 1 : i64
    %0 = llvm.alloca %c1_i64 x f64 : (i64) -> !llvm.ptr
    llvm.store %arg1, %0 : f64, !llvm.ptr
    cf.br ^bb1
  ^bb1:  // pred: ^bb0
    %1 = llvm.load %0 : !llvm.ptr -> f64
    %2 = arith.fptosi %1 : f64 to i64
    %3 = arith.uitofp %2 : i64 to f64
    cf.br ^bb2(%3 : f64)
  ^bb2(%4: f64):  // pred: ^bb1
    return %4 : f64
  }
  func.func public @f64.i64.no_fold_trunc_u_convert_u(%arg0: !llvm.ptr, %arg1: f64) -> f64 attributes {llvm.emit_c_interface} {
    %c1_i64 = arith.constant 1 : i64
    %0 = llvm.alloca %c1_i64 x f64 : (i64) -> !llvm.ptr
    llvm.store %arg1, %0 : f64, !llvm.ptr
    cf.br ^bb1
  ^bb1:  // pred: ^bb0
    %1 = llvm.load %0 : !llvm.ptr -> f64
    %2 = arith.fptoui %1 : f64 to i64
    %3 = arith.uitofp %2 : i64 to f64
    cf.br ^bb2(%3 : f64)
  ^bb2(%4: f64):  // pred: ^bb1
    return %4 : f64
  }
  func.func public @f32.ult(%arg0: !llvm.ptr, %arg1: f32, %arg2: f32) -> i32 attributes {llvm.emit_c_interface} {
    %c1_i64 = arith.constant 1 : i64
    %0 = llvm.alloca %c1_i64 x f32 : (i64) -> !llvm.ptr
    llvm.store %arg1, %0 : f32, !llvm.ptr
    %c1_i64_0 = arith.constant 1 : i64
    %1 = llvm.alloca %c1_i64_0 x f32 : (i64) -> !llvm.ptr
    llvm.store %arg2, %1 : f32, !llvm.ptr
    cf.br ^bb1
  ^bb1:  // pred: ^bb0
    %2 = llvm.load %0 : !llvm.ptr -> f32
    %3 = llvm.load %1 : !llvm.ptr -> f32
    %4 = arith.cmpf oge, %2, %3 : f32
    %5 = arith.extui %4 : i1 to i32
    %c0_i32 = arith.constant 0 : i32
    %6 = arith.cmpi eq, %5, %c0_i32 : i32
    %7 = arith.extui %6 : i1 to i32
    cf.br ^bb2(%7 : i32)
  ^bb2(%8: i32):  // pred: ^bb1
    return %8 : i32
  }
  func.func public @f32.ule(%arg0: !llvm.ptr, %arg1: f32, %arg2: f32) -> i32 attributes {llvm.emit_c_interface} {
    %c1_i64 = arith.constant 1 : i64
    %0 = llvm.alloca %c1_i64 x f32 : (i64) -> !llvm.ptr
    llvm.store %arg1, %0 : f32, !llvm.ptr
    %c1_i64_0 = arith.constant 1 : i64
    %1 = llvm.alloca %c1_i64_0 x f32 : (i64) -> !llvm.ptr
    llvm.store %arg2, %1 : f32, !llvm.ptr
    cf.br ^bb1
  ^bb1:  // pred: ^bb0
    %2 = llvm.load %0 : !llvm.ptr -> f32
    %3 = llvm.load %1 : !llvm.ptr -> f32
    %4 = arith.cmpf ogt, %2, %3 : f32
    %5 = arith.extui %4 : i1 to i32
    %c0_i32 = arith.constant 0 : i32
    %6 = arith.cmpi eq, %5, %c0_i32 : i32
    %7 = arith.extui %6 : i1 to i32
    cf.br ^bb2(%7 : i32)
  ^bb2(%8: i32):  // pred: ^bb1
    return %8 : i32
  }
  func.func public @f32.ugt(%arg0: !llvm.ptr, %arg1: f32, %arg2: f32) -> i32 attributes {llvm.emit_c_interface} {
    %c1_i64 = arith.constant 1 : i64
    %0 = llvm.alloca %c1_i64 x f32 : (i64) -> !llvm.ptr
    llvm.store %arg1, %0 : f32, !llvm.ptr
    %c1_i64_0 = arith.constant 1 : i64
    %1 = llvm.alloca %c1_i64_0 x f32 : (i64) -> !llvm.ptr
    llvm.store %arg2, %1 : f32, !llvm.ptr
    cf.br ^bb1
  ^bb1:  // pred: ^bb0
    %2 = llvm.load %0 : !llvm.ptr -> f32
    %3 = llvm.load %1 : !llvm.ptr -> f32
    %4 = arith.cmpf ole, %2, %3 : f32
    %5 = arith.extui %4 : i1 to i32
    %c0_i32 = arith.constant 0 : i32
    %6 = arith.cmpi eq, %5, %c0_i32 : i32
    %7 = arith.extui %6 : i1 to i32
    cf.br ^bb2(%7 : i32)
  ^bb2(%8: i32):  // pred: ^bb1
    return %8 : i32
  }
  func.func public @f32.uge(%arg0: !llvm.ptr, %arg1: f32, %arg2: f32) -> i32 attributes {llvm.emit_c_interface} {
    %c1_i64 = arith.constant 1 : i64
    %0 = llvm.alloca %c1_i64 x f32 : (i64) -> !llvm.ptr
    llvm.store %arg1, %0 : f32, !llvm.ptr
    %c1_i64_0 = arith.constant 1 : i64
    %1 = llvm.alloca %c1_i64_0 x f32 : (i64) -> !llvm.ptr
    llvm.store %arg2, %1 : f32, !llvm.ptr
    cf.br ^bb1
  ^bb1:  // pred: ^bb0
    %2 = llvm.load %0 : !llvm.ptr -> f32
    %3 = llvm.load %1 : !llvm.ptr -> f32
    %4 = arith.cmpf olt, %2, %3 : f32
    %5 = arith.extui %4 : i1 to i32
    %c0_i32 = arith.constant 0 : i32
    %6 = arith.cmpi eq, %5, %c0_i32 : i32
    %7 = arith.extui %6 : i1 to i32
    cf.br ^bb2(%7 : i32)
  ^bb2(%8: i32):  // pred: ^bb1
    return %8 : i32
  }
  func.func public @f64.ult(%arg0: !llvm.ptr, %arg1: f64, %arg2: f64) -> i32 attributes {llvm.emit_c_interface} {
    %c1_i64 = arith.constant 1 : i64
    %0 = llvm.alloca %c1_i64 x f64 : (i64) -> !llvm.ptr
    llvm.store %arg1, %0 : f64, !llvm.ptr
    %c1_i64_0 = arith.constant 1 : i64
    %1 = llvm.alloca %c1_i64_0 x f64 : (i64) -> !llvm.ptr
    llvm.store %arg2, %1 : f64, !llvm.ptr
    cf.br ^bb1
  ^bb1:  // pred: ^bb0
    %2 = llvm.load %0 : !llvm.ptr -> f64
    %3 = llvm.load %1 : !llvm.ptr -> f64
    %4 = arith.cmpf oge, %2, %3 : f64
    %5 = arith.extui %4 : i1 to i32
    %c0_i32 = arith.constant 0 : i32
    %6 = arith.cmpi eq, %5, %c0_i32 : i32
    %7 = arith.extui %6 : i1 to i32
    cf.br ^bb2(%7 : i32)
  ^bb2(%8: i32):  // pred: ^bb1
    return %8 : i32
  }
  func.func public @f64.ule(%arg0: !llvm.ptr, %arg1: f64, %arg2: f64) -> i32 attributes {llvm.emit_c_interface} {
    %c1_i64 = arith.constant 1 : i64
    %0 = llvm.alloca %c1_i64 x f64 : (i64) -> !llvm.ptr
    llvm.store %arg1, %0 : f64, !llvm.ptr
    %c1_i64_0 = arith.constant 1 : i64
    %1 = llvm.alloca %c1_i64_0 x f64 : (i64) -> !llvm.ptr
    llvm.store %arg2, %1 : f64, !llvm.ptr
    cf.br ^bb1
  ^bb1:  // pred: ^bb0
    %2 = llvm.load %0 : !llvm.ptr -> f64
    %3 = llvm.load %1 : !llvm.ptr -> f64
    %4 = arith.cmpf ogt, %2, %3 : f64
    %5 = arith.extui %4 : i1 to i32
    %c0_i32 = arith.constant 0 : i32
    %6 = arith.cmpi eq, %5, %c0_i32 : i32
    %7 = arith.extui %6 : i1 to i32
    cf.br ^bb2(%7 : i32)
  ^bb2(%8: i32):  // pred: ^bb1
    return %8 : i32
  }
  func.func public @f64.ugt(%arg0: !llvm.ptr, %arg1: f64, %arg2: f64) -> i32 attributes {llvm.emit_c_interface} {
    %c1_i64 = arith.constant 1 : i64
    %0 = llvm.alloca %c1_i64 x f64 : (i64) -> !llvm.ptr
    llvm.store %arg1, %0 : f64, !llvm.ptr
    %c1_i64_0 = arith.constant 1 : i64
    %1 = llvm.alloca %c1_i64_0 x f64 : (i64) -> !llvm.ptr
    llvm.store %arg2, %1 : f64, !llvm.ptr
    cf.br ^bb1
  ^bb1:  // pred: ^bb0
    %2 = llvm.load %0 : !llvm.ptr -> f64
    %3 = llvm.load %1 : !llvm.ptr -> f64
    %4 = arith.cmpf ole, %2, %3 : f64
    %5 = arith.extui %4 : i1 to i32
    %c0_i32 = arith.constant 0 : i32
    %6 = arith.cmpi eq, %5, %c0_i32 : i32
    %7 = arith.extui %6 : i1 to i32
    cf.br ^bb2(%7 : i32)
  ^bb2(%8: i32):  // pred: ^bb1
    return %8 : i32
  }
  func.func public @f64.uge(%arg0: !llvm.ptr, %arg1: f64, %arg2: f64) -> i32 attributes {llvm.emit_c_interface} {
    %c1_i64 = arith.constant 1 : i64
    %0 = llvm.alloca %c1_i64 x f64 : (i64) -> !llvm.ptr
    llvm.store %arg1, %0 : f64, !llvm.ptr
    %c1_i64_0 = arith.constant 1 : i64
    %1 = llvm.alloca %c1_i64_0 x f64 : (i64) -> !llvm.ptr
    llvm.store %arg2, %1 : f64, !llvm.ptr
    cf.br ^bb1
  ^bb1:  // pred: ^bb0
    %2 = llvm.load %0 : !llvm.ptr -> f64
    %3 = llvm.load %1 : !llvm.ptr -> f64
    %4 = arith.cmpf olt, %2, %3 : f64
    %5 = arith.extui %4 : i1 to i32
    %c0_i32 = arith.constant 0 : i32
    %6 = arith.cmpi eq, %5, %c0_i32 : i32
    %7 = arith.extui %6 : i1 to i32
    cf.br ^bb2(%7 : i32)
  ^bb2(%8: i32):  // pred: ^bb1
    return %8 : i32
  }
  func.func public @f32.no_fold_lt_select(%arg0: !llvm.ptr, %arg1: f32, %arg2: f32) -> f32 attributes {llvm.emit_c_interface} {
    %c1_i64 = arith.constant 1 : i64
    %0 = llvm.alloca %c1_i64 x f32 : (i64) -> !llvm.ptr
    llvm.store %arg1, %0 : f32, !llvm.ptr
    %c1_i64_0 = arith.constant 1 : i64
    %1 = llvm.alloca %c1_i64_0 x f32 : (i64) -> !llvm.ptr
    llvm.store %arg2, %1 : f32, !llvm.ptr
    cf.br ^bb1
  ^bb1:  // pred: ^bb0
    %2 = llvm.load %0 : !llvm.ptr -> f32
    %3 = llvm.load %1 : !llvm.ptr -> f32
    %4 = llvm.load %0 : !llvm.ptr -> f32
    %5 = llvm.load %1 : !llvm.ptr -> f32
    %6 = arith.cmpf olt, %4, %5 : f32
    %7 = arith.extui %6 : i1 to i32
    %c0_i32 = arith.constant 0 : i32
    %8 = arith.cmpi ne, %7, %c0_i32 : i32
    %9 = arith.select %8, %2, %3 : f32
    cf.br ^bb2(%9 : f32)
  ^bb2(%10: f32):  // pred: ^bb1
    return %10 : f32
  }
  func.func public @f32.no_fold_le_select(%arg0: !llvm.ptr, %arg1: f32, %arg2: f32) -> f32 attributes {llvm.emit_c_interface} {
    %c1_i64 = arith.constant 1 : i64
    %0 = llvm.alloca %c1_i64 x f32 : (i64) -> !llvm.ptr
    llvm.store %arg1, %0 : f32, !llvm.ptr
    %c1_i64_0 = arith.constant 1 : i64
    %1 = llvm.alloca %c1_i64_0 x f32 : (i64) -> !llvm.ptr
    llvm.store %arg2, %1 : f32, !llvm.ptr
    cf.br ^bb1
  ^bb1:  // pred: ^bb0
    %2 = llvm.load %0 : !llvm.ptr -> f32
    %3 = llvm.load %1 : !llvm.ptr -> f32
    %4 = llvm.load %0 : !llvm.ptr -> f32
    %5 = llvm.load %1 : !llvm.ptr -> f32
    %6 = arith.cmpf ole, %4, %5 : f32
    %7 = arith.extui %6 : i1 to i32
    %c0_i32 = arith.constant 0 : i32
    %8 = arith.cmpi ne, %7, %c0_i32 : i32
    %9 = arith.select %8, %2, %3 : f32
    cf.br ^bb2(%9 : f32)
  ^bb2(%10: f32):  // pred: ^bb1
    return %10 : f32
  }
  func.func public @f32.no_fold_gt_select(%arg0: !llvm.ptr, %arg1: f32, %arg2: f32) -> f32 attributes {llvm.emit_c_interface} {
    %c1_i64 = arith.constant 1 : i64
    %0 = llvm.alloca %c1_i64 x f32 : (i64) -> !llvm.ptr
    llvm.store %arg1, %0 : f32, !llvm.ptr
    %c1_i64_0 = arith.constant 1 : i64
    %1 = llvm.alloca %c1_i64_0 x f32 : (i64) -> !llvm.ptr
    llvm.store %arg2, %1 : f32, !llvm.ptr
    cf.br ^bb1
  ^bb1:  // pred: ^bb0
    %2 = llvm.load %0 : !llvm.ptr -> f32
    %3 = llvm.load %1 : !llvm.ptr -> f32
    %4 = llvm.load %0 : !llvm.ptr -> f32
    %5 = llvm.load %1 : !llvm.ptr -> f32
    %6 = arith.cmpf ogt, %4, %5 : f32
    %7 = arith.extui %6 : i1 to i32
    %c0_i32 = arith.constant 0 : i32
    %8 = arith.cmpi ne, %7, %c0_i32 : i32
    %9 = arith.select %8, %2, %3 : f32
    cf.br ^bb2(%9 : f32)
  ^bb2(%10: f32):  // pred: ^bb1
    return %10 : f32
  }
  func.func public @f32.no_fold_ge_select(%arg0: !llvm.ptr, %arg1: f32, %arg2: f32) -> f32 attributes {llvm.emit_c_interface} {
    %c1_i64 = arith.constant 1 : i64
    %0 = llvm.alloca %c1_i64 x f32 : (i64) -> !llvm.ptr
    llvm.store %arg1, %0 : f32, !llvm.ptr
    %c1_i64_0 = arith.constant 1 : i64
    %1 = llvm.alloca %c1_i64_0 x f32 : (i64) -> !llvm.ptr
    llvm.store %arg2, %1 : f32, !llvm.ptr
    cf.br ^bb1
  ^bb1:  // pred: ^bb0
    %2 = llvm.load %0 : !llvm.ptr -> f32
    %3 = llvm.load %1 : !llvm.ptr -> f32
    %4 = llvm.load %0 : !llvm.ptr -> f32
    %5 = llvm.load %1 : !llvm.ptr -> f32
    %6 = arith.cmpf oge, %4, %5 : f32
    %7 = arith.extui %6 : i1 to i32
    %c0_i32 = arith.constant 0 : i32
    %8 = arith.cmpi ne, %7, %c0_i32 : i32
    %9 = arith.select %8, %2, %3 : f32
    cf.br ^bb2(%9 : f32)
  ^bb2(%10: f32):  // pred: ^bb1
    return %10 : f32
  }
  func.func public @f64.no_fold_lt_select(%arg0: !llvm.ptr, %arg1: f64, %arg2: f64) -> f64 attributes {llvm.emit_c_interface} {
    %c1_i64 = arith.constant 1 : i64
    %0 = llvm.alloca %c1_i64 x f64 : (i64) -> !llvm.ptr
    llvm.store %arg1, %0 : f64, !llvm.ptr
    %c1_i64_0 = arith.constant 1 : i64
    %1 = llvm.alloca %c1_i64_0 x f64 : (i64) -> !llvm.ptr
    llvm.store %arg2, %1 : f64, !llvm.ptr
    cf.br ^bb1
  ^bb1:  // pred: ^bb0
    %2 = llvm.load %0 : !llvm.ptr -> f64
    %3 = llvm.load %1 : !llvm.ptr -> f64
    %4 = llvm.load %0 : !llvm.ptr -> f64
    %5 = llvm.load %1 : !llvm.ptr -> f64
    %6 = arith.cmpf olt, %4, %5 : f64
    %7 = arith.extui %6 : i1 to i32
    %c0_i32 = arith.constant 0 : i32
    %8 = arith.cmpi ne, %7, %c0_i32 : i32
    %9 = arith.select %8, %2, %3 : f64
    cf.br ^bb2(%9 : f64)
  ^bb2(%10: f64):  // pred: ^bb1
    return %10 : f64
  }
  func.func public @f64.no_fold_le_select(%arg0: !llvm.ptr, %arg1: f64, %arg2: f64) -> f64 attributes {llvm.emit_c_interface} {
    %c1_i64 = arith.constant 1 : i64
    %0 = llvm.alloca %c1_i64 x f64 : (i64) -> !llvm.ptr
    llvm.store %arg1, %0 : f64, !llvm.ptr
    %c1_i64_0 = arith.constant 1 : i64
    %1 = llvm.alloca %c1_i64_0 x f64 : (i64) -> !llvm.ptr
    llvm.store %arg2, %1 : f64, !llvm.ptr
    cf.br ^bb1
  ^bb1:  // pred: ^bb0
    %2 = llvm.load %0 : !llvm.ptr -> f64
    %3 = llvm.load %1 : !llvm.ptr -> f64
    %4 = llvm.load %0 : !llvm.ptr -> f64
    %5 = llvm.load %1 : !llvm.ptr -> f64
    %6 = arith.cmpf ole, %4, %5 : f64
    %7 = arith.extui %6 : i1 to i32
    %c0_i32 = arith.constant 0 : i32
    %8 = arith.cmpi ne, %7, %c0_i32 : i32
    %9 = arith.select %8, %2, %3 : f64
    cf.br ^bb2(%9 : f64)
  ^bb2(%10: f64):  // pred: ^bb1
    return %10 : f64
  }
  func.func public @f64.no_fold_gt_select(%arg0: !llvm.ptr, %arg1: f64, %arg2: f64) -> f64 attributes {llvm.emit_c_interface} {
    %c1_i64 = arith.constant 1 : i64
    %0 = llvm.alloca %c1_i64 x f64 : (i64) -> !llvm.ptr
    llvm.store %arg1, %0 : f64, !llvm.ptr
    %c1_i64_0 = arith.constant 1 : i64
    %1 = llvm.alloca %c1_i64_0 x f64 : (i64) -> !llvm.ptr
    llvm.store %arg2, %1 : f64, !llvm.ptr
    cf.br ^bb1
  ^bb1:  // pred: ^bb0
    %2 = llvm.load %0 : !llvm.ptr -> f64
    %3 = llvm.load %1 : !llvm.ptr -> f64
    %4 = llvm.load %0 : !llvm.ptr -> f64
    %5 = llvm.load %1 : !llvm.ptr -> f64
    %6 = arith.cmpf ogt, %4, %5 : f64
    %7 = arith.extui %6 : i1 to i32
    %c0_i32 = arith.constant 0 : i32
    %8 = arith.cmpi ne, %7, %c0_i32 : i32
    %9 = arith.select %8, %2, %3 : f64
    cf.br ^bb2(%9 : f64)
  ^bb2(%10: f64):  // pred: ^bb1
    return %10 : f64
  }
  func.func public @f64.no_fold_ge_select(%arg0: !llvm.ptr, %arg1: f64, %arg2: f64) -> f64 attributes {llvm.emit_c_interface} {
    %c1_i64 = arith.constant 1 : i64
    %0 = llvm.alloca %c1_i64 x f64 : (i64) -> !llvm.ptr
    llvm.store %arg1, %0 : f64, !llvm.ptr
    %c1_i64_0 = arith.constant 1 : i64
    %1 = llvm.alloca %c1_i64_0 x f64 : (i64) -> !llvm.ptr
    llvm.store %arg2, %1 : f64, !llvm.ptr
    cf.br ^bb1
  ^bb1:  // pred: ^bb0
    %2 = llvm.load %0 : !llvm.ptr -> f64
    %3 = llvm.load %1 : !llvm.ptr -> f64
    %4 = llvm.load %0 : !llvm.ptr -> f64
    %5 = llvm.load %1 : !llvm.ptr -> f64
    %6 = arith.cmpf oge, %4, %5 : f64
    %7 = arith.extui %6 : i1 to i32
    %c0_i32 = arith.constant 0 : i32
    %8 = arith.cmpi ne, %7, %c0_i32 : i32
    %9 = arith.select %8, %2, %3 : f64
    cf.br ^bb2(%9 : f64)
  ^bb2(%10: f64):  // pred: ^bb1
    return %10 : f64
  }
  func.func public @f32.no_fold_lt_if(%arg0: !llvm.ptr, %arg1: f32, %arg2: f32) -> f32 attributes {llvm.emit_c_interface} {
    %c1_i64 = arith.constant 1 : i64
    %0 = llvm.alloca %c1_i64 x f32 : (i64) -> !llvm.ptr
    llvm.store %arg1, %0 : f32, !llvm.ptr
    %c1_i64_0 = arith.constant 1 : i64
    %1 = llvm.alloca %c1_i64_0 x f32 : (i64) -> !llvm.ptr
    llvm.store %arg2, %1 : f32, !llvm.ptr
    cf.br ^bb1
  ^bb1:  // pred: ^bb0
    %2 = llvm.load %0 : !llvm.ptr -> f32
    %3 = llvm.load %1 : !llvm.ptr -> f32
    %4 = arith.cmpf olt, %2, %3 : f32
    %5 = arith.extui %4 : i1 to i32
    %c0_i32 = arith.constant 0 : i32
    %6 = arith.cmpi ne, %5, %c0_i32 : i32
    cf.cond_br %6, ^bb3, ^bb4
  ^bb2(%7: f32):  // pred: ^bb5
    return %7 : f32
  ^bb3:  // pred: ^bb1
    %8 = llvm.load %0 : !llvm.ptr -> f32
    cf.br ^bb5(%8 : f32)
  ^bb4:  // pred: ^bb1
    %9 = llvm.load %1 : !llvm.ptr -> f32
    cf.br ^bb5(%9 : f32)
  ^bb5(%10: f32):  // 2 preds: ^bb3, ^bb4
    cf.br ^bb2(%10 : f32)
  }
  func.func public @f32.no_fold_le_if(%arg0: !llvm.ptr, %arg1: f32, %arg2: f32) -> f32 attributes {llvm.emit_c_interface} {
    %c1_i64 = arith.constant 1 : i64
    %0 = llvm.alloca %c1_i64 x f32 : (i64) -> !llvm.ptr
    llvm.store %arg1, %0 : f32, !llvm.ptr
    %c1_i64_0 = arith.constant 1 : i64
    %1 = llvm.alloca %c1_i64_0 x f32 : (i64) -> !llvm.ptr
    llvm.store %arg2, %1 : f32, !llvm.ptr
    cf.br ^bb1
  ^bb1:  // pred: ^bb0
    %2 = llvm.load %0 : !llvm.ptr -> f32
    %3 = llvm.load %1 : !llvm.ptr -> f32
    %4 = arith.cmpf ole, %2, %3 : f32
    %5 = arith.extui %4 : i1 to i32
    %c0_i32 = arith.constant 0 : i32
    %6 = arith.cmpi ne, %5, %c0_i32 : i32
    cf.cond_br %6, ^bb3, ^bb4
  ^bb2(%7: f32):  // pred: ^bb5
    return %7 : f32
  ^bb3:  // pred: ^bb1
    %8 = llvm.load %0 : !llvm.ptr -> f32
    cf.br ^bb5(%8 : f32)
  ^bb4:  // pred: ^bb1
    %9 = llvm.load %1 : !llvm.ptr -> f32
    cf.br ^bb5(%9 : f32)
  ^bb5(%10: f32):  // 2 preds: ^bb3, ^bb4
    cf.br ^bb2(%10 : f32)
  }
  func.func public @f32.no_fold_gt_if(%arg0: !llvm.ptr, %arg1: f32, %arg2: f32) -> f32 attributes {llvm.emit_c_interface} {
    %c1_i64 = arith.constant 1 : i64
    %0 = llvm.alloca %c1_i64 x f32 : (i64) -> !llvm.ptr
    llvm.store %arg1, %0 : f32, !llvm.ptr
    %c1_i64_0 = arith.constant 1 : i64
    %1 = llvm.alloca %c1_i64_0 x f32 : (i64) -> !llvm.ptr
    llvm.store %arg2, %1 : f32, !llvm.ptr
    cf.br ^bb1
  ^bb1:  // pred: ^bb0
    %2 = llvm.load %0 : !llvm.ptr -> f32
    %3 = llvm.load %1 : !llvm.ptr -> f32
    %4 = arith.cmpf ogt, %2, %3 : f32
    %5 = arith.extui %4 : i1 to i32
    %c0_i32 = arith.constant 0 : i32
    %6 = arith.cmpi ne, %5, %c0_i32 : i32
    cf.cond_br %6, ^bb3, ^bb4
  ^bb2(%7: f32):  // pred: ^bb5
    return %7 : f32
  ^bb3:  // pred: ^bb1
    %8 = llvm.load %0 : !llvm.ptr -> f32
    cf.br ^bb5(%8 : f32)
  ^bb4:  // pred: ^bb1
    %9 = llvm.load %1 : !llvm.ptr -> f32
    cf.br ^bb5(%9 : f32)
  ^bb5(%10: f32):  // 2 preds: ^bb3, ^bb4
    cf.br ^bb2(%10 : f32)
  }
  func.func public @f32.no_fold_ge_if(%arg0: !llvm.ptr, %arg1: f32, %arg2: f32) -> f32 attributes {llvm.emit_c_interface} {
    %c1_i64 = arith.constant 1 : i64
    %0 = llvm.alloca %c1_i64 x f32 : (i64) -> !llvm.ptr
    llvm.store %arg1, %0 : f32, !llvm.ptr
    %c1_i64_0 = arith.constant 1 : i64
    %1 = llvm.alloca %c1_i64_0 x f32 : (i64) -> !llvm.ptr
    llvm.store %arg2, %1 : f32, !llvm.ptr
    cf.br ^bb1
  ^bb1:  // pred: ^bb0
    %2 = llvm.load %0 : !llvm.ptr -> f32
    %3 = llvm.load %1 : !llvm.ptr -> f32
    %4 = arith.cmpf oge, %2, %3 : f32
    %5 = arith.extui %4 : i1 to i32
    %c0_i32 = arith.constant 0 : i32
    %6 = arith.cmpi ne, %5, %c0_i32 : i32
    cf.cond_br %6, ^bb3, ^bb4
  ^bb2(%7: f32):  // pred: ^bb5
    return %7 : f32
  ^bb3:  // pred: ^bb1
    %8 = llvm.load %0 : !llvm.ptr -> f32
    cf.br ^bb5(%8 : f32)
  ^bb4:  // pred: ^bb1
    %9 = llvm.load %1 : !llvm.ptr -> f32
    cf.br ^bb5(%9 : f32)
  ^bb5(%10: f32):  // 2 preds: ^bb3, ^bb4
    cf.br ^bb2(%10 : f32)
  }
  func.func public @f64.no_fold_lt_if(%arg0: !llvm.ptr, %arg1: f64, %arg2: f64) -> f64 attributes {llvm.emit_c_interface} {
    %c1_i64 = arith.constant 1 : i64
    %0 = llvm.alloca %c1_i64 x f64 : (i64) -> !llvm.ptr
    llvm.store %arg1, %0 : f64, !llvm.ptr
    %c1_i64_0 = arith.constant 1 : i64
    %1 = llvm.alloca %c1_i64_0 x f64 : (i64) -> !llvm.ptr
    llvm.store %arg2, %1 : f64, !llvm.ptr
    cf.br ^bb1
  ^bb1:  // pred: ^bb0
    %2 = llvm.load %0 : !llvm.ptr -> f64
    %3 = llvm.load %1 : !llvm.ptr -> f64
    %4 = arith.cmpf olt, %2, %3 : f64
    %5 = arith.extui %4 : i1 to i32
    %c0_i32 = arith.constant 0 : i32
    %6 = arith.cmpi ne, %5, %c0_i32 : i32
    cf.cond_br %6, ^bb3, ^bb4
  ^bb2(%7: f64):  // pred: ^bb5
    return %7 : f64
  ^bb3:  // pred: ^bb1
    %8 = llvm.load %0 : !llvm.ptr -> f64
    cf.br ^bb5(%8 : f64)
  ^bb4:  // pred: ^bb1
    %9 = llvm.load %1 : !llvm.ptr -> f64
    cf.br ^bb5(%9 : f64)
  ^bb5(%10: f64):  // 2 preds: ^bb3, ^bb4
    cf.br ^bb2(%10 : f64)
  }
  func.func public @f64.no_fold_le_if(%arg0: !llvm.ptr, %arg1: f64, %arg2: f64) -> f64 attributes {llvm.emit_c_interface} {
    %c1_i64 = arith.constant 1 : i64
    %0 = llvm.alloca %c1_i64 x f64 : (i64) -> !llvm.ptr
    llvm.store %arg1, %0 : f64, !llvm.ptr
    %c1_i64_0 = arith.constant 1 : i64
    %1 = llvm.alloca %c1_i64_0 x f64 : (i64) -> !llvm.ptr
    llvm.store %arg2, %1 : f64, !llvm.ptr
    cf.br ^bb1
  ^bb1:  // pred: ^bb0
    %2 = llvm.load %0 : !llvm.ptr -> f64
    %3 = llvm.load %1 : !llvm.ptr -> f64
    %4 = arith.cmpf ole, %2, %3 : f64
    %5 = arith.extui %4 : i1 to i32
    %c0_i32 = arith.constant 0 : i32
    %6 = arith.cmpi ne, %5, %c0_i32 : i32
    cf.cond_br %6, ^bb3, ^bb4
  ^bb2(%7: f64):  // pred: ^bb5
    return %7 : f64
  ^bb3:  // pred: ^bb1
    %8 = llvm.load %0 : !llvm.ptr -> f64
    cf.br ^bb5(%8 : f64)
  ^bb4:  // pred: ^bb1
    %9 = llvm.load %1 : !llvm.ptr -> f64
    cf.br ^bb5(%9 : f64)
  ^bb5(%10: f64):  // 2 preds: ^bb3, ^bb4
    cf.br ^bb2(%10 : f64)
  }
  func.func public @f64.no_fold_gt_if(%arg0: !llvm.ptr, %arg1: f64, %arg2: f64) -> f64 attributes {llvm.emit_c_interface} {
    %c1_i64 = arith.constant 1 : i64
    %0 = llvm.alloca %c1_i64 x f64 : (i64) -> !llvm.ptr
    llvm.store %arg1, %0 : f64, !llvm.ptr
    %c1_i64_0 = arith.constant 1 : i64
    %1 = llvm.alloca %c1_i64_0 x f64 : (i64) -> !llvm.ptr
    llvm.store %arg2, %1 : f64, !llvm.ptr
    cf.br ^bb1
  ^bb1:  // pred: ^bb0
    %2 = llvm.load %0 : !llvm.ptr -> f64
    %3 = llvm.load %1 : !llvm.ptr -> f64
    %4 = arith.cmpf ogt, %2, %3 : f64
    %5 = arith.extui %4 : i1 to i32
    %c0_i32 = arith.constant 0 : i32
    %6 = arith.cmpi ne, %5, %c0_i32 : i32
    cf.cond_br %6, ^bb3, ^bb4
  ^bb2(%7: f64):  // pred: ^bb5
    return %7 : f64
  ^bb3:  // pred: ^bb1
    %8 = llvm.load %0 : !llvm.ptr -> f64
    cf.br ^bb5(%8 : f64)
  ^bb4:  // pred: ^bb1
    %9 = llvm.load %1 : !llvm.ptr -> f64
    cf.br ^bb5(%9 : f64)
  ^bb5(%10: f64):  // 2 preds: ^bb3, ^bb4
    cf.br ^bb2(%10 : f64)
  }
  func.func public @f64.no_fold_ge_if(%arg0: !llvm.ptr, %arg1: f64, %arg2: f64) -> f64 attributes {llvm.emit_c_interface} {
    %c1_i64 = arith.constant 1 : i64
    %0 = llvm.alloca %c1_i64 x f64 : (i64) -> !llvm.ptr
    llvm.store %arg1, %0 : f64, !llvm.ptr
    %c1_i64_0 = arith.constant 1 : i64
    %1 = llvm.alloca %c1_i64_0 x f64 : (i64) -> !llvm.ptr
    llvm.store %arg2, %1 : f64, !llvm.ptr
    cf.br ^bb1
  ^bb1:  // pred: ^bb0
    %2 = llvm.load %0 : !llvm.ptr -> f64
    %3 = llvm.load %1 : !llvm.ptr -> f64
    %4 = arith.cmpf oge, %2, %3 : f64
    %5 = arith.extui %4 : i1 to i32
    %c0_i32 = arith.constant 0 : i32
    %6 = arith.cmpi ne, %5, %c0_i32 : i32
    cf.cond_br %6, ^bb3, ^bb4
  ^bb2(%7: f64):  // pred: ^bb5
    return %7 : f64
  ^bb3:  // pred: ^bb1
    %8 = llvm.load %0 : !llvm.ptr -> f64
    cf.br ^bb5(%8 : f64)
  ^bb4:  // pred: ^bb1
    %9 = llvm.load %1 : !llvm.ptr -> f64
    cf.br ^bb5(%9 : f64)
  ^bb5(%10: f64):  // 2 preds: ^bb3, ^bb4
    cf.br ^bb2(%10 : f64)
  }
  func.func public @f32.no_fold_lt_select_to_abs(%arg0: !llvm.ptr, %arg1: f32) -> f32 attributes {llvm.emit_c_interface} {
    %c1_i64 = arith.constant 1 : i64
    %0 = llvm.alloca %c1_i64 x f32 : (i64) -> !llvm.ptr
    llvm.store %arg1, %0 : f32, !llvm.ptr
    cf.br ^bb1
  ^bb1:  // pred: ^bb0
    %1 = llvm.load %0 : !llvm.ptr -> f32
    %2 = arith.negf %1 : f32
    %3 = llvm.load %0 : !llvm.ptr -> f32
    %4 = llvm.load %0 : !llvm.ptr -> f32
    %c0_i32 = arith.constant 0 : i32
    %5 = arith.bitcast %c0_i32 : i32 to f32
    %6 = arith.cmpf olt, %4, %5 : f32
    %7 = arith.extui %6 : i1 to i32
    %c0_i32_0 = arith.constant 0 : i32
    %8 = arith.cmpi ne, %7, %c0_i32_0 : i32
    %9 = arith.select %8, %2, %3 : f32
    cf.br ^bb2(%9 : f32)
  ^bb2(%10: f32):  // pred: ^bb1
    return %10 : f32
  }
  func.func public @f32.no_fold_le_select_to_abs(%arg0: !llvm.ptr, %arg1: f32) -> f32 attributes {llvm.emit_c_interface} {
    %c1_i64 = arith.constant 1 : i64
    %0 = llvm.alloca %c1_i64 x f32 : (i64) -> !llvm.ptr
    llvm.store %arg1, %0 : f32, !llvm.ptr
    cf.br ^bb1
  ^bb1:  // pred: ^bb0
    %1 = llvm.load %0 : !llvm.ptr -> f32
    %2 = arith.negf %1 : f32
    %3 = llvm.load %0 : !llvm.ptr -> f32
    %4 = llvm.load %0 : !llvm.ptr -> f32
    %c-2147483648_i32 = arith.constant -2147483648 : i32
    %5 = arith.bitcast %c-2147483648_i32 : i32 to f32
    %6 = arith.cmpf ole, %4, %5 : f32
    %7 = arith.extui %6 : i1 to i32
    %c0_i32 = arith.constant 0 : i32
    %8 = arith.cmpi ne, %7, %c0_i32 : i32
    %9 = arith.select %8, %2, %3 : f32
    cf.br ^bb2(%9 : f32)
  ^bb2(%10: f32):  // pred: ^bb1
    return %10 : f32
  }
  func.func public @f32.no_fold_gt_select_to_abs(%arg0: !llvm.ptr, %arg1: f32) -> f32 attributes {llvm.emit_c_interface} {
    %c1_i64 = arith.constant 1 : i64
    %0 = llvm.alloca %c1_i64 x f32 : (i64) -> !llvm.ptr
    llvm.store %arg1, %0 : f32, !llvm.ptr
    cf.br ^bb1
  ^bb1:  // pred: ^bb0
    %1 = llvm.load %0 : !llvm.ptr -> f32
    %2 = llvm.load %0 : !llvm.ptr -> f32
    %3 = arith.negf %2 : f32
    %4 = llvm.load %0 : !llvm.ptr -> f32
    %c-2147483648_i32 = arith.constant -2147483648 : i32
    %5 = arith.bitcast %c-2147483648_i32 : i32 to f32
    %6 = arith.cmpf ogt, %4, %5 : f32
    %7 = arith.extui %6 : i1 to i32
    %c0_i32 = arith.constant 0 : i32
    %8 = arith.cmpi ne, %7, %c0_i32 : i32
    %9 = arith.select %8, %1, %3 : f32
    cf.br ^bb2(%9 : f32)
  ^bb2(%10: f32):  // pred: ^bb1
    return %10 : f32
  }
  func.func public @f32.no_fold_ge_select_to_abs(%arg0: !llvm.ptr, %arg1: f32) -> f32 attributes {llvm.emit_c_interface} {
    %c1_i64 = arith.constant 1 : i64
    %0 = llvm.alloca %c1_i64 x f32 : (i64) -> !llvm.ptr
    llvm.store %arg1, %0 : f32, !llvm.ptr
    cf.br ^bb1
  ^bb1:  // pred: ^bb0
    %1 = llvm.load %0 : !llvm.ptr -> f32
    %2 = llvm.load %0 : !llvm.ptr -> f32
    %3 = arith.negf %2 : f32
    %4 = llvm.load %0 : !llvm.ptr -> f32
    %c0_i32 = arith.constant 0 : i32
    %5 = arith.bitcast %c0_i32 : i32 to f32
    %6 = arith.cmpf oge, %4, %5 : f32
    %7 = arith.extui %6 : i1 to i32
    %c0_i32_0 = arith.constant 0 : i32
    %8 = arith.cmpi ne, %7, %c0_i32_0 : i32
    %9 = arith.select %8, %1, %3 : f32
    cf.br ^bb2(%9 : f32)
  ^bb2(%10: f32):  // pred: ^bb1
    return %10 : f32
  }
  func.func public @f64.no_fold_lt_select_to_abs(%arg0: !llvm.ptr, %arg1: f64) -> f64 attributes {llvm.emit_c_interface} {
    %c1_i64 = arith.constant 1 : i64
    %0 = llvm.alloca %c1_i64 x f64 : (i64) -> !llvm.ptr
    llvm.store %arg1, %0 : f64, !llvm.ptr
    cf.br ^bb1
  ^bb1:  // pred: ^bb0
    %1 = llvm.load %0 : !llvm.ptr -> f64
    %2 = arith.negf %1 : f64
    %3 = llvm.load %0 : !llvm.ptr -> f64
    %4 = llvm.load %0 : !llvm.ptr -> f64
    %c0_i64 = arith.constant 0 : i64
    %5 = arith.bitcast %c0_i64 : i64 to f64
    %6 = arith.cmpf olt, %4, %5 : f64
    %7 = arith.extui %6 : i1 to i32
    %c0_i32 = arith.constant 0 : i32
    %8 = arith.cmpi ne, %7, %c0_i32 : i32
    %9 = arith.select %8, %2, %3 : f64
    cf.br ^bb2(%9 : f64)
  ^bb2(%10: f64):  // pred: ^bb1
    return %10 : f64
  }
  func.func public @f64.no_fold_le_select_to_abs(%arg0: !llvm.ptr, %arg1: f64) -> f64 attributes {llvm.emit_c_interface} {
    %c1_i64 = arith.constant 1 : i64
    %0 = llvm.alloca %c1_i64 x f64 : (i64) -> !llvm.ptr
    llvm.store %arg1, %0 : f64, !llvm.ptr
    cf.br ^bb1
  ^bb1:  // pred: ^bb0
    %1 = llvm.load %0 : !llvm.ptr -> f64
    %2 = arith.negf %1 : f64
    %3 = llvm.load %0 : !llvm.ptr -> f64
    %4 = llvm.load %0 : !llvm.ptr -> f64
    %c-9223372036854775808_i64 = arith.constant -9223372036854775808 : i64
    %5 = arith.bitcast %c-9223372036854775808_i64 : i64 to f64
    %6 = arith.cmpf ole, %4, %5 : f64
    %7 = arith.extui %6 : i1 to i32
    %c0_i32 = arith.constant 0 : i32
    %8 = arith.cmpi ne, %7, %c0_i32 : i32
    %9 = arith.select %8, %2, %3 : f64
    cf.br ^bb2(%9 : f64)
  ^bb2(%10: f64):  // pred: ^bb1
    return %10 : f64
  }
  func.func public @f64.no_fold_gt_select_to_abs(%arg0: !llvm.ptr, %arg1: f64) -> f64 attributes {llvm.emit_c_interface} {
    %c1_i64 = arith.constant 1 : i64
    %0 = llvm.alloca %c1_i64 x f64 : (i64) -> !llvm.ptr
    llvm.store %arg1, %0 : f64, !llvm.ptr
    cf.br ^bb1
  ^bb1:  // pred: ^bb0
    %1 = llvm.load %0 : !llvm.ptr -> f64
    %2 = llvm.load %0 : !llvm.ptr -> f64
    %3 = arith.negf %2 : f64
    %4 = llvm.load %0 : !llvm.ptr -> f64
    %c-9223372036854775808_i64 = arith.constant -9223372036854775808 : i64
    %5 = arith.bitcast %c-9223372036854775808_i64 : i64 to f64
    %6 = arith.cmpf ogt, %4, %5 : f64
    %7 = arith.extui %6 : i1 to i32
    %c0_i32 = arith.constant 0 : i32
    %8 = arith.cmpi ne, %7, %c0_i32 : i32
    %9 = arith.select %8, %1, %3 : f64
    cf.br ^bb2(%9 : f64)
  ^bb2(%10: f64):  // pred: ^bb1
    return %10 : f64
  }
  func.func public @f64.no_fold_ge_select_to_abs(%arg0: !llvm.ptr, %arg1: f64) -> f64 attributes {llvm.emit_c_interface} {
    %c1_i64 = arith.constant 1 : i64
    %0 = llvm.alloca %c1_i64 x f64 : (i64) -> !llvm.ptr
    llvm.store %arg1, %0 : f64, !llvm.ptr
    cf.br ^bb1
  ^bb1:  // pred: ^bb0
    %1 = llvm.load %0 : !llvm.ptr -> f64
    %2 = llvm.load %0 : !llvm.ptr -> f64
    %3 = arith.negf %2 : f64
    %4 = llvm.load %0 : !llvm.ptr -> f64
    %c0_i64 = arith.constant 0 : i64
    %5 = arith.bitcast %c0_i64 : i64 to f64
    %6 = arith.cmpf oge, %4, %5 : f64
    %7 = arith.extui %6 : i1 to i32
    %c0_i32 = arith.constant 0 : i32
    %8 = arith.cmpi ne, %7, %c0_i32 : i32
    %9 = arith.select %8, %1, %3 : f64
    cf.br ^bb2(%9 : f64)
  ^bb2(%10: f64):  // pred: ^bb1
    return %10 : f64
  }
  func.func public @f32.no_fold_lt_if_to_abs(%arg0: !llvm.ptr, %arg1: f32) -> f32 attributes {llvm.emit_c_interface} {
    %c1_i64 = arith.constant 1 : i64
    %0 = llvm.alloca %c1_i64 x f32 : (i64) -> !llvm.ptr
    llvm.store %arg1, %0 : f32, !llvm.ptr
    cf.br ^bb1
  ^bb1:  // pred: ^bb0
    %1 = llvm.load %0 : !llvm.ptr -> f32
    %c0_i32 = arith.constant 0 : i32
    %2 = arith.bitcast %c0_i32 : i32 to f32
    %3 = arith.cmpf olt, %1, %2 : f32
    %4 = arith.extui %3 : i1 to i32
    %c0_i32_0 = arith.constant 0 : i32
    %5 = arith.cmpi ne, %4, %c0_i32_0 : i32
    cf.cond_br %5, ^bb3, ^bb4
  ^bb2(%6: f32):  // pred: ^bb5
    return %6 : f32
  ^bb3:  // pred: ^bb1
    %7 = llvm.load %0 : !llvm.ptr -> f32
    %8 = arith.negf %7 : f32
    cf.br ^bb5(%8 : f32)
  ^bb4:  // pred: ^bb1
    %9 = llvm.load %0 : !llvm.ptr -> f32
    cf.br ^bb5(%9 : f32)
  ^bb5(%10: f32):  // 2 preds: ^bb3, ^bb4
    cf.br ^bb2(%10 : f32)
  }
  func.func public @f32.no_fold_le_if_to_abs(%arg0: !llvm.ptr, %arg1: f32) -> f32 attributes {llvm.emit_c_interface} {
    %c1_i64 = arith.constant 1 : i64
    %0 = llvm.alloca %c1_i64 x f32 : (i64) -> !llvm.ptr
    llvm.store %arg1, %0 : f32, !llvm.ptr
    cf.br ^bb1
  ^bb1:  // pred: ^bb0
    %1 = llvm.load %0 : !llvm.ptr -> f32
    %c-2147483648_i32 = arith.constant -2147483648 : i32
    %2 = arith.bitcast %c-2147483648_i32 : i32 to f32
    %3 = arith.cmpf ole, %1, %2 : f32
    %4 = arith.extui %3 : i1 to i32
    %c0_i32 = arith.constant 0 : i32
    %5 = arith.cmpi ne, %4, %c0_i32 : i32
    cf.cond_br %5, ^bb3, ^bb4
  ^bb2(%6: f32):  // pred: ^bb5
    return %6 : f32
  ^bb3:  // pred: ^bb1
    %7 = llvm.load %0 : !llvm.ptr -> f32
    %8 = arith.negf %7 : f32
    cf.br ^bb5(%8 : f32)
  ^bb4:  // pred: ^bb1
    %9 = llvm.load %0 : !llvm.ptr -> f32
    cf.br ^bb5(%9 : f32)
  ^bb5(%10: f32):  // 2 preds: ^bb3, ^bb4
    cf.br ^bb2(%10 : f32)
  }
  func.func public @f32.no_fold_gt_if_to_abs(%arg0: !llvm.ptr, %arg1: f32) -> f32 attributes {llvm.emit_c_interface} {
    %c1_i64 = arith.constant 1 : i64
    %0 = llvm.alloca %c1_i64 x f32 : (i64) -> !llvm.ptr
    llvm.store %arg1, %0 : f32, !llvm.ptr
    cf.br ^bb1
  ^bb1:  // pred: ^bb0
    %1 = llvm.load %0 : !llvm.ptr -> f32
    %c-2147483648_i32 = arith.constant -2147483648 : i32
    %2 = arith.bitcast %c-2147483648_i32 : i32 to f32
    %3 = arith.cmpf ogt, %1, %2 : f32
    %4 = arith.extui %3 : i1 to i32
    %c0_i32 = arith.constant 0 : i32
    %5 = arith.cmpi ne, %4, %c0_i32 : i32
    cf.cond_br %5, ^bb3, ^bb4
  ^bb2(%6: f32):  // pred: ^bb5
    return %6 : f32
  ^bb3:  // pred: ^bb1
    %7 = llvm.load %0 : !llvm.ptr -> f32
    cf.br ^bb5(%7 : f32)
  ^bb4:  // pred: ^bb1
    %8 = llvm.load %0 : !llvm.ptr -> f32
    %9 = arith.negf %8 : f32
    cf.br ^bb5(%9 : f32)
  ^bb5(%10: f32):  // 2 preds: ^bb3, ^bb4
    cf.br ^bb2(%10 : f32)
  }
  func.func public @f32.no_fold_ge_if_to_abs(%arg0: !llvm.ptr, %arg1: f32) -> f32 attributes {llvm.emit_c_interface} {
    %c1_i64 = arith.constant 1 : i64
    %0 = llvm.alloca %c1_i64 x f32 : (i64) -> !llvm.ptr
    llvm.store %arg1, %0 : f32, !llvm.ptr
    cf.br ^bb1
  ^bb1:  // pred: ^bb0
    %1 = llvm.load %0 : !llvm.ptr -> f32
    %c0_i32 = arith.constant 0 : i32
    %2 = arith.bitcast %c0_i32 : i32 to f32
    %3 = arith.cmpf oge, %1, %2 : f32
    %4 = arith.extui %3 : i1 to i32
    %c0_i32_0 = arith.constant 0 : i32
    %5 = arith.cmpi ne, %4, %c0_i32_0 : i32
    cf.cond_br %5, ^bb3, ^bb4
  ^bb2(%6: f32):  // pred: ^bb5
    return %6 : f32
  ^bb3:  // pred: ^bb1
    %7 = llvm.load %0 : !llvm.ptr -> f32
    cf.br ^bb5(%7 : f32)
  ^bb4:  // pred: ^bb1
    %8 = llvm.load %0 : !llvm.ptr -> f32
    %9 = arith.negf %8 : f32
    cf.br ^bb5(%9 : f32)
  ^bb5(%10: f32):  // 2 preds: ^bb3, ^bb4
    cf.br ^bb2(%10 : f32)
  }
  func.func public @f64.no_fold_lt_if_to_abs(%arg0: !llvm.ptr, %arg1: f64) -> f64 attributes {llvm.emit_c_interface} {
    %c1_i64 = arith.constant 1 : i64
    %0 = llvm.alloca %c1_i64 x f64 : (i64) -> !llvm.ptr
    llvm.store %arg1, %0 : f64, !llvm.ptr
    cf.br ^bb1
  ^bb1:  // pred: ^bb0
    %1 = llvm.load %0 : !llvm.ptr -> f64
    %c0_i64 = arith.constant 0 : i64
    %2 = arith.bitcast %c0_i64 : i64 to f64
    %3 = arith.cmpf olt, %1, %2 : f64
    %4 = arith.extui %3 : i1 to i32
    %c0_i32 = arith.constant 0 : i32
    %5 = arith.cmpi ne, %4, %c0_i32 : i32
    cf.cond_br %5, ^bb3, ^bb4
  ^bb2(%6: f64):  // pred: ^bb5
    return %6 : f64
  ^bb3:  // pred: ^bb1
    %7 = llvm.load %0 : !llvm.ptr -> f64
    %8 = arith.negf %7 : f64
    cf.br ^bb5(%8 : f64)
  ^bb4:  // pred: ^bb1
    %9 = llvm.load %0 : !llvm.ptr -> f64
    cf.br ^bb5(%9 : f64)
  ^bb5(%10: f64):  // 2 preds: ^bb3, ^bb4
    cf.br ^bb2(%10 : f64)
  }
  func.func public @f64.no_fold_le_if_to_abs(%arg0: !llvm.ptr, %arg1: f64) -> f64 attributes {llvm.emit_c_interface} {
    %c1_i64 = arith.constant 1 : i64
    %0 = llvm.alloca %c1_i64 x f64 : (i64) -> !llvm.ptr
    llvm.store %arg1, %0 : f64, !llvm.ptr
    cf.br ^bb1
  ^bb1:  // pred: ^bb0
    %1 = llvm.load %0 : !llvm.ptr -> f64
    %c-9223372036854775808_i64 = arith.constant -9223372036854775808 : i64
    %2 = arith.bitcast %c-9223372036854775808_i64 : i64 to f64
    %3 = arith.cmpf ole, %1, %2 : f64
    %4 = arith.extui %3 : i1 to i32
    %c0_i32 = arith.constant 0 : i32
    %5 = arith.cmpi ne, %4, %c0_i32 : i32
    cf.cond_br %5, ^bb3, ^bb4
  ^bb2(%6: f64):  // pred: ^bb5
    return %6 : f64
  ^bb3:  // pred: ^bb1
    %7 = llvm.load %0 : !llvm.ptr -> f64
    %8 = arith.negf %7 : f64
    cf.br ^bb5(%8 : f64)
  ^bb4:  // pred: ^bb1
    %9 = llvm.load %0 : !llvm.ptr -> f64
    cf.br ^bb5(%9 : f64)
  ^bb5(%10: f64):  // 2 preds: ^bb3, ^bb4
    cf.br ^bb2(%10 : f64)
  }
  func.func public @f64.no_fold_gt_if_to_abs(%arg0: !llvm.ptr, %arg1: f64) -> f64 attributes {llvm.emit_c_interface} {
    %c1_i64 = arith.constant 1 : i64
    %0 = llvm.alloca %c1_i64 x f64 : (i64) -> !llvm.ptr
    llvm.store %arg1, %0 : f64, !llvm.ptr
    cf.br ^bb1
  ^bb1:  // pred: ^bb0
    %1 = llvm.load %0 : !llvm.ptr -> f64
    %c-9223372036854775808_i64 = arith.constant -9223372036854775808 : i64
    %2 = arith.bitcast %c-9223372036854775808_i64 : i64 to f64
    %3 = arith.cmpf ogt, %1, %2 : f64
    %4 = arith.extui %3 : i1 to i32
    %c0_i32 = arith.constant 0 : i32
    %5 = arith.cmpi ne, %4, %c0_i32 : i32
    cf.cond_br %5, ^bb3, ^bb4
  ^bb2(%6: f64):  // pred: ^bb5
    return %6 : f64
  ^bb3:  // pred: ^bb1
    %7 = llvm.load %0 : !llvm.ptr -> f64
    cf.br ^bb5(%7 : f64)
  ^bb4:  // pred: ^bb1
    %8 = llvm.load %0 : !llvm.ptr -> f64
    %9 = arith.negf %8 : f64
    cf.br ^bb5(%9 : f64)
  ^bb5(%10: f64):  // 2 preds: ^bb3, ^bb4
    cf.br ^bb2(%10 : f64)
  }
  func.func public @f64.no_fold_ge_if_to_abs(%arg0: !llvm.ptr, %arg1: f64) -> f64 attributes {llvm.emit_c_interface} {
    %c1_i64 = arith.constant 1 : i64
    %0 = llvm.alloca %c1_i64 x f64 : (i64) -> !llvm.ptr
    llvm.store %arg1, %0 : f64, !llvm.ptr
    cf.br ^bb1
  ^bb1:  // pred: ^bb0
    %1 = llvm.load %0 : !llvm.ptr -> f64
    %c0_i64 = arith.constant 0 : i64
    %2 = arith.bitcast %c0_i64 : i64 to f64
    %3 = arith.cmpf oge, %1, %2 : f64
    %4 = arith.extui %3 : i1 to i32
    %c0_i32 = arith.constant 0 : i32
    %5 = arith.cmpi ne, %4, %c0_i32 : i32
    cf.cond_br %5, ^bb3, ^bb4
  ^bb2(%6: f64):  // pred: ^bb5
    return %6 : f64
  ^bb3:  // pred: ^bb1
    %7 = llvm.load %0 : !llvm.ptr -> f64
    cf.br ^bb5(%7 : f64)
  ^bb4:  // pred: ^bb1
    %8 = llvm.load %0 : !llvm.ptr -> f64
    %9 = arith.negf %8 : f64
    cf.br ^bb5(%9 : f64)
  ^bb5(%10: f64):  // 2 preds: ^bb3, ^bb4
    cf.br ^bb2(%10 : f64)
  }
  func.func public @f32.incorrect_correction(%arg0: !llvm.ptr) -> f32 attributes {llvm.emit_c_interface} {
    cf.br ^bb1
  ^bb1:  // pred: ^bb0
    %c1068146622_i32 = arith.constant 1068146622 : i32
    %0 = arith.bitcast %c1068146622_i32 : i32 to f32
    %c1067240653_i32 = arith.constant 1067240653 : i32
    %1 = arith.bitcast %c1067240653_i32 : i32 to f32
    %2 = arith.addf %0, %1 : f32
    %c1068146622_i32_0 = arith.constant 1068146622 : i32
    %3 = arith.bitcast %c1068146622_i32_0 : i32 to f32
    %4 = arith.subf %2, %3 : f32
    %c1067240653_i32_1 = arith.constant 1067240653 : i32
    %5 = arith.bitcast %c1067240653_i32_1 : i32 to f32
    %6 = arith.subf %4, %5 : f32
    cf.br ^bb2(%6 : f32)
  ^bb2(%7: f32):  // pred: ^bb1
    return %7 : f32
  }
  func.func public @f64.incorrect_correction(%arg0: !llvm.ptr) -> f64 attributes {llvm.emit_c_interface} {
    cf.br ^bb1
  ^bb1:  // pred: ^bb0
    %c4608682117475931783_i64 = arith.constant 4608682117475931783 : i64
    %0 = arith.bitcast %c4608682117475931783_i64 : i64 to f64
    %c4608195728716175770_i64 = arith.constant 4608195728716175770 : i64
    %1 = arith.bitcast %c4608195728716175770_i64 : i64 to f64
    %2 = arith.addf %0, %1 : f64
    %c4608682117475931783_i64_0 = arith.constant 4608682117475931783 : i64
    %3 = arith.bitcast %c4608682117475931783_i64_0 : i64 to f64
    %4 = arith.subf %2, %3 : f64
    %c4608195728716175770_i64_1 = arith.constant 4608195728716175770 : i64
    %5 = arith.bitcast %c4608195728716175770_i64_1 : i64 to f64
    %6 = arith.subf %4, %5 : f64
    cf.br ^bb2(%6 : f64)
  ^bb2(%7: f64):  // pred: ^bb1
    return %7 : f64
  }
  func.func public @init(%arg0: !llvm.ptr, %arg1: i32, %arg2: f32) attributes {llvm.emit_c_interface} {
    %c1_i64 = arith.constant 1 : i64
    %0 = llvm.alloca %c1_i64 x i32 : (i64) -> !llvm.ptr
    llvm.store %arg1, %0 : i32, !llvm.ptr
    %c1_i64_0 = arith.constant 1 : i64
    %1 = llvm.alloca %c1_i64_0 x f32 : (i64) -> !llvm.ptr
    llvm.store %arg2, %1 : f32, !llvm.ptr
    %2 = llvm.getelementptr %arg0[104] : (!llvm.ptr) -> !llvm.ptr, i8
    %3 = llvm.getelementptr %2[0] : (!llvm.ptr) -> !llvm.ptr, i8
    %4 = llvm.load %3 : !llvm.ptr -> !llvm.ptr
    cf.br ^bb1
  ^bb1:  // pred: ^bb0
    %5 = llvm.load %0 : !llvm.ptr -> i32
    %6 = llvm.load %1 : !llvm.ptr -> f32
    %c0_i64 = arith.constant 0 : i64
    %7 = arith.extui %5 : i32 to i64
    %8 = arith.addi %7, %c0_i64 : i64
    %9 = llvm.getelementptr %4[%8] : (!llvm.ptr, i64) -> !llvm.ptr, i8
    llvm.store volatile %6, %9 {alignment = 1 : i64} : f32, !llvm.ptr
    cf.br ^bb2
  ^bb2:  // pred: ^bb1
    return
  }
  func.func public @run(%arg0: !llvm.ptr, %arg1: i32, %arg2: f32) attributes {llvm.emit_c_interface} {
    %c1_i64 = arith.constant 1 : i64
    %0 = llvm.alloca %c1_i64 x i32 : (i64) -> !llvm.ptr
    llvm.store %arg1, %0 : i32, !llvm.ptr
    %c1_i64_0 = arith.constant 1 : i64
    %1 = llvm.alloca %c1_i64_0 x f32 : (i64) -> !llvm.ptr
    llvm.store %arg2, %1 : f32, !llvm.ptr
    %c0_i32 = arith.constant 0 : i32
    %c1_i64_1 = arith.constant 1 : i64
    %2 = llvm.alloca %c1_i64_1 x i32 : (i64) -> !llvm.ptr
    llvm.store %c0_i32, %2 : i32, !llvm.ptr
    %3 = llvm.getelementptr %arg0[104] : (!llvm.ptr) -> !llvm.ptr, i8
    %4 = llvm.getelementptr %3[0] : (!llvm.ptr) -> !llvm.ptr, i8
    %5 = llvm.load %4 : !llvm.ptr -> !llvm.ptr
    cf.br ^bb1
  ^bb1:  // pred: ^bb0
    cf.br ^bb5
  ^bb2:  // pred: ^bb3
    return
  ^bb3:  // pred: ^bb4
    cf.br ^bb2
  ^bb4:  // pred: ^bb6
    cf.br ^bb3
  ^bb5:  // 2 preds: ^bb1, ^bb5
    %6 = llvm.load %2 : !llvm.ptr -> i32
    %7 = llvm.load %2 : !llvm.ptr -> i32
    %c0_i64 = arith.constant 0 : i64
    %8 = arith.extui %7 : i32 to i64
    %9 = arith.addi %8, %c0_i64 : i64
    %10 = llvm.getelementptr %5[%9] : (!llvm.ptr, i64) -> !llvm.ptr, i8
    %11 = llvm.load volatile %10 {alignment = 1 : i64} : !llvm.ptr -> f32
    %12 = llvm.load %1 : !llvm.ptr -> f32
    %cst = arith.constant 0.000000e+00 : f32
    %13 = arith.cmpf oeq, %12, %cst : f32
    %14 = scf.if %13 -> (f32) {
      scf.yield %cst : f32
    } else {
      %25 = arith.divf %11, %12 : f32
      scf.yield %25 : f32
    }
    %c0_i64_2 = arith.constant 0 : i64
    %15 = arith.extui %6 : i32 to i64
    %16 = arith.addi %15, %c0_i64_2 : i64
    %17 = llvm.getelementptr %5[%16] : (!llvm.ptr, i64) -> !llvm.ptr, i8
    llvm.store volatile %14, %17 {alignment = 1 : i64} : f32, !llvm.ptr
    %18 = llvm.load %2 : !llvm.ptr -> i32
    %c4_i32 = arith.constant 4 : i32
    %19 = arith.addi %18, %c4_i32 : i32
    llvm.store %19, %2 : i32, !llvm.ptr
    %20 = llvm.load %2 : !llvm.ptr -> i32
    %21 = llvm.load %0 : !llvm.ptr -> i32
    %22 = arith.cmpi ult, %20, %21 : i32
    %23 = arith.extui %22 : i1 to i32
    %c0_i32_3 = arith.constant 0 : i32
    %24 = arith.cmpi ne, %23, %c0_i32_3 : i32
    cf.cond_br %24, ^bb5, ^bb6
  ^bb6:  // pred: ^bb5
    cf.br ^bb4
  }
  func.func public @check(%arg0: !llvm.ptr, %arg1: i32) -> f32 attributes {llvm.emit_c_interface} {
    %c1_i64 = arith.constant 1 : i64
    %0 = llvm.alloca %c1_i64 x i32 : (i64) -> !llvm.ptr
    llvm.store %arg1, %0 : i32, !llvm.ptr
    %1 = llvm.getelementptr %arg0[104] : (!llvm.ptr) -> !llvm.ptr, i8
    %2 = llvm.getelementptr %1[0] : (!llvm.ptr) -> !llvm.ptr, i8
    %3 = llvm.load %2 : !llvm.ptr -> !llvm.ptr
    cf.br ^bb1
  ^bb1:  // pred: ^bb0
    %4 = llvm.load %0 : !llvm.ptr -> i32
    %c0_i64 = arith.constant 0 : i64
    %5 = arith.extui %4 : i32 to i64
    %6 = arith.addi %5, %c0_i64 : i64
    %7 = llvm.getelementptr %3[%6] : (!llvm.ptr, i64) -> !llvm.ptr, i8
    %8 = llvm.load volatile %7 {alignment = 1 : i64} : !llvm.ptr -> f32
    cf.br ^bb2(%8 : f32)
  ^bb2(%9: f32):  // pred: ^bb1
    return %9 : f32
  }
  func.func public @calculate(%arg0: !llvm.ptr) -> f32 attributes {llvm.emit_c_interface} {
    %cst = arith.constant 0.000000e+00 : f32
    %c1_i64 = arith.constant 1 : i64
    %0 = llvm.alloca %c1_i64 x f32 : (i64) -> !llvm.ptr
    llvm.store %cst, %0 : f32, !llvm.ptr
    %c1_i64_0 = arith.constant 1 : i64
    %1 = llvm.alloca %c1_i64_0 x f32 : (i64) -> !llvm.ptr
    llvm.store %cst, %1 : f32, !llvm.ptr
    %c1_i64_1 = arith.constant 1 : i64
    %2 = llvm.alloca %c1_i64_1 x f32 : (i64) -> !llvm.ptr
    llvm.store %cst, %2 : f32, !llvm.ptr
    %c1_i64_2 = arith.constant 1 : i64
    %3 = llvm.alloca %c1_i64_2 x f32 : (i64) -> !llvm.ptr
    llvm.store %cst, %3 : f32, !llvm.ptr
    %c1_i64_3 = arith.constant 1 : i64
    %4 = llvm.alloca %c1_i64_3 x f32 : (i64) -> !llvm.ptr
    llvm.store %cst, %4 : f32, !llvm.ptr
    cf.br ^bb1
  ^bb1:  // pred: ^bb0
    %c1125924864_i32 = arith.constant 1125924864 : i32
    %5 = arith.bitcast %c1125924864_i32 : i32 to f32
    llvm.store %5, %0 : f32, !llvm.ptr
    %c1129338197_i32 = arith.constant 1129338197 : i32
    %6 = arith.bitcast %c1129338197_i32 : i32 to f32
    llvm.store %6, %1 : f32, !llvm.ptr
    %c1071892245_i32 = arith.constant 1071892245 : i32
    %7 = arith.bitcast %c1071892245_i32 : i32 to f32
    llvm.store %7, %2 : f32, !llvm.ptr
    %8 = llvm.load %1 : !llvm.ptr -> f32
    %9 = arith.negf %8 : f32
    %10 = llvm.load %0 : !llvm.ptr -> f32
    %11 = arith.mulf %9, %10 : f32
    %12 = llvm.load %0 : !llvm.ptr -> f32
    %13 = llvm.load %2 : !llvm.ptr -> f32
    %14 = arith.mulf %12, %13 : f32
    %15 = llvm.load %1 : !llvm.ptr -> f32
    %16 = arith.subf %14, %15 : f32
    %cst_4 = arith.constant 0.000000e+00 : f32
    %17 = arith.cmpf oeq, %16, %cst_4 : f32
    %18 = scf.if %17 -> (f32) {
      scf.yield %cst_4 : f32
    } else {
      %37 = arith.divf %11, %16 : f32
      scf.yield %37 : f32
    }
    llvm.store %18, %3 : f32, !llvm.ptr
    %19 = llvm.load %1 : !llvm.ptr -> f32
    %20 = arith.negf %19 : f32
    %21 = llvm.load %0 : !llvm.ptr -> f32
    %22 = arith.mulf %20, %21 : f32
    %23 = llvm.load %0 : !llvm.ptr -> f32
    %24 = llvm.load %2 : !llvm.ptr -> f32
    %25 = arith.mulf %23, %24 : f32
    %26 = llvm.load %1 : !llvm.ptr -> f32
    %27 = arith.subf %25, %26 : f32
    %cst_5 = arith.constant 0.000000e+00 : f32
    %28 = arith.cmpf oeq, %27, %cst_5 : f32
    %29 = scf.if %28 -> (f32) {
      scf.yield %cst_5 : f32
    } else {
      %37 = arith.divf %22, %27 : f32
      scf.yield %37 : f32
    }
    llvm.store %29, %4 : f32, !llvm.ptr
    %30 = llvm.load %3 : !llvm.ptr -> f32
    %31 = llvm.load %4 : !llvm.ptr -> f32
    %32 = arith.cmpf oeq, %30, %31 : f32
    %33 = arith.extui %32 : i1 to i32
    %c0_i32 = arith.constant 0 : i32
    %34 = arith.cmpi ne, %33, %c0_i32 : i32
    cf.cond_br %34, ^bb3, ^bb4
  ^bb2(%35: f32):  // pred: ^bb3
    return %35 : f32
  ^bb3:  // pred: ^bb1
    %36 = llvm.load %4 : !llvm.ptr -> f32
    cf.br ^bb2(%36 : f32)
  ^bb4:  // pred: ^bb1
    llvm.unreachable
  }
  func.func public @thepast0(%arg0: !llvm.ptr, %arg1: f64, %arg2: f64, %arg3: f64, %arg4: f64) -> f64 attributes {llvm.emit_c_interface} {
    %c1_i64 = arith.constant 1 : i64
    %0 = llvm.alloca %c1_i64 x f64 : (i64) -> !llvm.ptr
    llvm.store %arg1, %0 : f64, !llvm.ptr
    %c1_i64_0 = arith.constant 1 : i64
    %1 = llvm.alloca %c1_i64_0 x f64 : (i64) -> !llvm.ptr
    llvm.store %arg2, %1 : f64, !llvm.ptr
    %c1_i64_1 = arith.constant 1 : i64
    %2 = llvm.alloca %c1_i64_1 x f64 : (i64) -> !llvm.ptr
    llvm.store %arg3, %2 : f64, !llvm.ptr
    %c1_i64_2 = arith.constant 1 : i64
    %3 = llvm.alloca %c1_i64_2 x f64 : (i64) -> !llvm.ptr
    llvm.store %arg4, %3 : f64, !llvm.ptr
    cf.br ^bb1
  ^bb1:  // pred: ^bb0
    %4 = llvm.load %0 : !llvm.ptr -> f64
    %5 = llvm.load %1 : !llvm.ptr -> f64
    %6 = arith.mulf %4, %5 : f64
    %7 = llvm.load %2 : !llvm.ptr -> f64
    %8 = llvm.load %3 : !llvm.ptr -> f64
    %9 = arith.mulf %7, %8 : f64
    %cst = arith.constant 0.000000e+00 : f64
    %10 = arith.cmpf oeq, %9, %cst : f64
    %11 = scf.if %10 -> (f64) {
      scf.yield %cst : f64
    } else {
      %13 = arith.divf %6, %9 : f64
      scf.yield %13 : f64
    }
    cf.br ^bb2(%11 : f64)
  ^bb2(%12: f64):  // pred: ^bb1
    return %12 : f64
  }
  func.func public @thepast1(%arg0: !llvm.ptr, %arg1: f64, %arg2: f64, %arg3: f64) -> f64 attributes {llvm.emit_c_interface} {
    %c1_i64 = arith.constant 1 : i64
    %0 = llvm.alloca %c1_i64 x f64 : (i64) -> !llvm.ptr
    llvm.store %arg1, %0 : f64, !llvm.ptr
    %c1_i64_0 = arith.constant 1 : i64
    %1 = llvm.alloca %c1_i64_0 x f64 : (i64) -> !llvm.ptr
    llvm.store %arg2, %1 : f64, !llvm.ptr
    %c1_i64_1 = arith.constant 1 : i64
    %2 = llvm.alloca %c1_i64_1 x f64 : (i64) -> !llvm.ptr
    llvm.store %arg3, %2 : f64, !llvm.ptr
    cf.br ^bb1
  ^bb1:  // pred: ^bb0
    %3 = llvm.load %0 : !llvm.ptr -> f64
    %4 = llvm.load %1 : !llvm.ptr -> f64
    %5 = arith.mulf %3, %4 : f64
    %6 = llvm.load %2 : !llvm.ptr -> f64
    %7 = arith.subf %5, %6 : f64
    cf.br ^bb2(%7 : f64)
  ^bb2(%8: f64):  // pred: ^bb1
    return %8 : f64
  }
  func.func public @thepast2(%arg0: !llvm.ptr, %arg1: f32, %arg2: f32, %arg3: f32) -> f32 attributes {llvm.emit_c_interface} {
    %c1_i64 = arith.constant 1 : i64
    %0 = llvm.alloca %c1_i64 x f32 : (i64) -> !llvm.ptr
    llvm.store %arg1, %0 : f32, !llvm.ptr
    %c1_i64_0 = arith.constant 1 : i64
    %1 = llvm.alloca %c1_i64_0 x f32 : (i64) -> !llvm.ptr
    llvm.store %arg2, %1 : f32, !llvm.ptr
    %c1_i64_1 = arith.constant 1 : i64
    %2 = llvm.alloca %c1_i64_1 x f32 : (i64) -> !llvm.ptr
    llvm.store %arg3, %2 : f32, !llvm.ptr
    cf.br ^bb1
  ^bb1:  // pred: ^bb0
    %3 = llvm.load %0 : !llvm.ptr -> f32
    %4 = llvm.load %1 : !llvm.ptr -> f32
    %5 = arith.mulf %3, %4 : f32
    %6 = llvm.load %2 : !llvm.ptr -> f32
    %7 = arith.mulf %5, %6 : f32
    cf.br ^bb2(%7 : f32)
  ^bb2(%8: f32):  // pred: ^bb1
    return %8 : f32
  }
  func.func public @inverse(%arg0: !llvm.ptr, %arg1: f32) -> f32 attributes {llvm.emit_c_interface} {
    %c1_i64 = arith.constant 1 : i64
    %0 = llvm.alloca %c1_i64 x f32 : (i64) -> !llvm.ptr
    llvm.store %arg1, %0 : f32, !llvm.ptr
    cf.br ^bb1
  ^bb1:  // pred: ^bb0
    %c1065353216_i32 = arith.constant 1065353216 : i32
    %1 = arith.bitcast %c1065353216_i32 : i32 to f32
    %2 = llvm.load %0 : !llvm.ptr -> f32
    %cst = arith.constant 0.000000e+00 : f32
    %3 = arith.cmpf oeq, %2, %cst : f32
    %4 = scf.if %3 -> (f32) {
      scf.yield %cst : f32
    } else {
      %6 = arith.divf %1, %2 : f32
      scf.yield %6 : f32
    }
    cf.br ^bb2(%4 : f32)
  ^bb2(%5: f32):  // pred: ^bb1
    return %5 : f32
  }
  func.func public @f32_sqrt_minus_2(%arg0: !llvm.ptr, %arg1: f32) -> f32 attributes {llvm.emit_c_interface} {
    %c1_i64 = arith.constant 1 : i64
    %0 = llvm.alloca %c1_i64 x f32 : (i64) -> !llvm.ptr
    llvm.store %arg1, %0 : f32, !llvm.ptr
    cf.br ^bb1
  ^bb1:  // pred: ^bb0
    %1 = llvm.load %0 : !llvm.ptr -> f32
    %2 = math.sqrt %1 : f32
    %c1073741824_i32 = arith.constant 1073741824 : i32
    %3 = arith.bitcast %c1073741824_i32 : i32 to f32
    %4 = arith.subf %2, %3 : f32
    cf.br ^bb2(%4 : f32)
  ^bb2(%5: f32):  // pred: ^bb1
    return %5 : f32
  }
  func.func public @f64_sqrt_minus_2(%arg0: !llvm.ptr, %arg1: f64) -> f64 attributes {llvm.emit_c_interface} {
    %c1_i64 = arith.constant 1 : i64
    %0 = llvm.alloca %c1_i64 x f64 : (i64) -> !llvm.ptr
    llvm.store %arg1, %0 : f64, !llvm.ptr
    cf.br ^bb1
  ^bb1:  // pred: ^bb0
    %1 = llvm.load %0 : !llvm.ptr -> f64
    %2 = math.sqrt %1 : f64
    %c4611686018427387904_i64 = arith.constant 4611686018427387904 : i64
    %3 = arith.bitcast %c4611686018427387904_i64 : i64 to f64
    %4 = arith.subf %2, %3 : f64
    cf.br ^bb2(%4 : f64)
  ^bb2(%5: f64):  // pred: ^bb1
    return %5 : f64
  }
  func.func public @f32.no_fold_recip_recip(%arg0: !llvm.ptr, %arg1: f32) -> f32 attributes {llvm.emit_c_interface} {
    %c1_i64 = arith.constant 1 : i64
    %0 = llvm.alloca %c1_i64 x f32 : (i64) -> !llvm.ptr
    llvm.store %arg1, %0 : f32, !llvm.ptr
    cf.br ^bb1
  ^bb1:  // pred: ^bb0
    %c1065353216_i32 = arith.constant 1065353216 : i32
    %1 = arith.bitcast %c1065353216_i32 : i32 to f32
    %c1065353216_i32_0 = arith.constant 1065353216 : i32
    %2 = arith.bitcast %c1065353216_i32_0 : i32 to f32
    %3 = llvm.load %0 : !llvm.ptr -> f32
    %cst = arith.constant 0.000000e+00 : f32
    %4 = arith.cmpf oeq, %3, %cst : f32
    %5 = scf.if %4 -> (f32) {
      scf.yield %cst : f32
    } else {
      %9 = arith.divf %2, %3 : f32
      scf.yield %9 : f32
    }
    %cst_1 = arith.constant 0.000000e+00 : f32
    %6 = arith.cmpf oeq, %5, %cst_1 : f32
    %7 = scf.if %6 -> (f32) {
      scf.yield %cst_1 : f32
    } else {
      %9 = arith.divf %1, %5 : f32
      scf.yield %9 : f32
    }
    cf.br ^bb2(%7 : f32)
  ^bb2(%8: f32):  // pred: ^bb1
    return %8 : f32
  }
  func.func public @f64.no_fold_recip_recip(%arg0: !llvm.ptr, %arg1: f64) -> f64 attributes {llvm.emit_c_interface} {
    %c1_i64 = arith.constant 1 : i64
    %0 = llvm.alloca %c1_i64 x f64 : (i64) -> !llvm.ptr
    llvm.store %arg1, %0 : f64, !llvm.ptr
    cf.br ^bb1
  ^bb1:  // pred: ^bb0
    %c4607182418800017408_i64 = arith.constant 4607182418800017408 : i64
    %1 = arith.bitcast %c4607182418800017408_i64 : i64 to f64
    %c4607182418800017408_i64_0 = arith.constant 4607182418800017408 : i64
    %2 = arith.bitcast %c4607182418800017408_i64_0 : i64 to f64
    %3 = llvm.load %0 : !llvm.ptr -> f64
    %cst = arith.constant 0.000000e+00 : f64
    %4 = arith.cmpf oeq, %3, %cst : f64
    %5 = scf.if %4 -> (f64) {
      scf.yield %cst : f64
    } else {
      %9 = arith.divf %2, %3 : f64
      scf.yield %9 : f64
    }
    %cst_1 = arith.constant 0.000000e+00 : f64
    %6 = arith.cmpf oeq, %5, %cst_1 : f64
    %7 = scf.if %6 -> (f64) {
      scf.yield %cst_1 : f64
    } else {
      %9 = arith.divf %1, %5 : f64
      scf.yield %9 : f64
    }
    cf.br ^bb2(%7 : f64)
  ^bb2(%8: f64):  // pred: ^bb1
    return %8 : f64
  }
  func.func @f148(%arg0: !llvm.ptr, %arg1: f32, %arg2: f32) -> f32 {
    %c1_i64 = arith.constant 1 : i64
    %0 = llvm.alloca %c1_i64 x f32 : (i64) -> !llvm.ptr
    llvm.store %arg1, %0 : f32, !llvm.ptr
    %c1_i64_0 = arith.constant 1 : i64
    %1 = llvm.alloca %c1_i64_0 x f32 : (i64) -> !llvm.ptr
    llvm.store %arg2, %1 : f32, !llvm.ptr
    cf.br ^bb1
  ^bb1:  // pred: ^bb0
    %2 = llvm.load %0 : !llvm.ptr -> f32
    %3 = llvm.load %1 : !llvm.ptr -> f32
    %4 = arith.addf %2, %3 : f32
    %5 = llvm.load %0 : !llvm.ptr -> f32
    %6 = llvm.load %1 : !llvm.ptr -> f32
    %7 = arith.subf %5, %6 : f32
    %8 = arith.mulf %4, %7 : f32
    cf.br ^bb2(%8 : f32)
  ^bb2(%9: f32):  // pred: ^bb1
    return %9 : f32
  }
  func.func @f149(%arg0: !llvm.ptr, %arg1: f64, %arg2: f64) -> f64 {
    %c1_i64 = arith.constant 1 : i64
    %0 = llvm.alloca %c1_i64 x f64 : (i64) -> !llvm.ptr
    llvm.store %arg1, %0 : f64, !llvm.ptr
    %c1_i64_0 = arith.constant 1 : i64
    %1 = llvm.alloca %c1_i64_0 x f64 : (i64) -> !llvm.ptr
    llvm.store %arg2, %1 : f64, !llvm.ptr
    cf.br ^bb1
  ^bb1:  // pred: ^bb0
    %2 = llvm.load %0 : !llvm.ptr -> f64
    %3 = llvm.load %1 : !llvm.ptr -> f64
    %4 = arith.addf %2, %3 : f64
    %5 = llvm.load %0 : !llvm.ptr -> f64
    %6 = llvm.load %1 : !llvm.ptr -> f64
    %7 = arith.subf %5, %6 : f64
    %8 = arith.mulf %4, %7 : f64
    cf.br ^bb2(%8 : f64)
  ^bb2(%9: f64):  // pred: ^bb1
    return %9 : f64
  }
  func.func public @f32.no_algebraic_factoring(%arg0: !llvm.ptr, %arg1: f32, %arg2: f32) -> f32 attributes {llvm.emit_c_interface} {
    %c1_i64 = arith.constant 1 : i64
    %0 = llvm.alloca %c1_i64 x f32 : (i64) -> !llvm.ptr
    llvm.store %arg1, %0 : f32, !llvm.ptr
    %c1_i64_0 = arith.constant 1 : i64
    %1 = llvm.alloca %c1_i64_0 x f32 : (i64) -> !llvm.ptr
    llvm.store %arg2, %1 : f32, !llvm.ptr
    cf.br ^bb1
  ^bb1:  // pred: ^bb0
    %2 = llvm.load %0 : !llvm.ptr -> f32
    %3 = llvm.load %0 : !llvm.ptr -> f32
    %4 = arith.mulf %2, %3 : f32
    %5 = llvm.load %1 : !llvm.ptr -> f32
    %6 = llvm.load %1 : !llvm.ptr -> f32
    %7 = arith.mulf %5, %6 : f32
    %8 = arith.subf %4, %7 : f32
    cf.br ^bb2(%8 : f32)
  ^bb2(%9: f32):  // pred: ^bb1
    return %9 : f32
  }
  func.func public @f64.no_algebraic_factoring(%arg0: !llvm.ptr, %arg1: f64, %arg2: f64) -> f64 attributes {llvm.emit_c_interface} {
    %c1_i64 = arith.constant 1 : i64
    %0 = llvm.alloca %c1_i64 x f64 : (i64) -> !llvm.ptr
    llvm.store %arg1, %0 : f64, !llvm.ptr
    %c1_i64_0 = arith.constant 1 : i64
    %1 = llvm.alloca %c1_i64_0 x f64 : (i64) -> !llvm.ptr
    llvm.store %arg2, %1 : f64, !llvm.ptr
    cf.br ^bb1
  ^bb1:  // pred: ^bb0
    %2 = llvm.load %0 : !llvm.ptr -> f64
    %3 = llvm.load %0 : !llvm.ptr -> f64
    %4 = arith.mulf %2, %3 : f64
    %5 = llvm.load %1 : !llvm.ptr -> f64
    %6 = llvm.load %1 : !llvm.ptr -> f64
    %7 = arith.mulf %5, %6 : f64
    %8 = arith.subf %4, %7 : f64
    cf.br ^bb2(%8 : f64)
  ^bb2(%9: f64):  // pred: ^bb1
    return %9 : f64
  }
  func.func public @f32.no_fold_neg_add(%arg0: !llvm.ptr, %arg1: f32, %arg2: f32) -> f32 attributes {llvm.emit_c_interface} {
    %c1_i64 = arith.constant 1 : i64
    %0 = llvm.alloca %c1_i64 x f32 : (i64) -> !llvm.ptr
    llvm.store %arg1, %0 : f32, !llvm.ptr
    %c1_i64_0 = arith.constant 1 : i64
    %1 = llvm.alloca %c1_i64_0 x f32 : (i64) -> !llvm.ptr
    llvm.store %arg2, %1 : f32, !llvm.ptr
    cf.br ^bb1
  ^bb1:  // pred: ^bb0
    %2 = llvm.load %0 : !llvm.ptr -> f32
    %3 = llvm.load %1 : !llvm.ptr -> f32
    %4 = arith.addf %2, %3 : f32
    %5 = arith.negf %4 : f32
    cf.br ^bb2(%5 : f32)
  ^bb2(%6: f32):  // pred: ^bb1
    return %6 : f32
  }
  func.func public @f64.no_fold_neg_add(%arg0: !llvm.ptr, %arg1: f64, %arg2: f64) -> f64 attributes {llvm.emit_c_interface} {
    %c1_i64 = arith.constant 1 : i64
    %0 = llvm.alloca %c1_i64 x f64 : (i64) -> !llvm.ptr
    llvm.store %arg1, %0 : f64, !llvm.ptr
    %c1_i64_0 = arith.constant 1 : i64
    %1 = llvm.alloca %c1_i64_0 x f64 : (i64) -> !llvm.ptr
    llvm.store %arg2, %1 : f64, !llvm.ptr
    cf.br ^bb1
  ^bb1:  // pred: ^bb0
    %2 = llvm.load %0 : !llvm.ptr -> f64
    %3 = llvm.load %1 : !llvm.ptr -> f64
    %4 = arith.addf %2, %3 : f64
    %5 = arith.negf %4 : f64
    cf.br ^bb2(%5 : f64)
  ^bb2(%6: f64):  // pred: ^bb1
    return %6 : f64
  }
  func.func public @f32.no_fold_add_neg(%arg0: !llvm.ptr, %arg1: f32) -> f32 attributes {llvm.emit_c_interface} {
    %c1_i64 = arith.constant 1 : i64
    %0 = llvm.alloca %c1_i64 x f32 : (i64) -> !llvm.ptr
    llvm.store %arg1, %0 : f32, !llvm.ptr
    cf.br ^bb1
  ^bb1:  // pred: ^bb0
    %1 = llvm.load %0 : !llvm.ptr -> f32
    %2 = arith.negf %1 : f32
    %3 = llvm.load %0 : !llvm.ptr -> f32
    %4 = arith.addf %2, %3 : f32
    cf.br ^bb2(%4 : f32)
  ^bb2(%5: f32):  // pred: ^bb1
    return %5 : f32
  }
  func.func public @f64.no_fold_add_neg(%arg0: !llvm.ptr, %arg1: f64) -> f64 attributes {llvm.emit_c_interface} {
    %c1_i64 = arith.constant 1 : i64
    %0 = llvm.alloca %c1_i64 x f64 : (i64) -> !llvm.ptr
    llvm.store %arg1, %0 : f64, !llvm.ptr
    cf.br ^bb1
  ^bb1:  // pred: ^bb0
    %1 = llvm.load %0 : !llvm.ptr -> f64
    %2 = arith.negf %1 : f64
    %3 = llvm.load %0 : !llvm.ptr -> f64
    %4 = arith.addf %2, %3 : f64
    cf.br ^bb2(%4 : f64)
  ^bb2(%5: f64):  // pred: ^bb1
    return %5 : f64
  }
  func.func public @f32.no_fold_6x_via_add(%arg0: !llvm.ptr, %arg1: f32) -> f32 attributes {llvm.emit_c_interface} {
    %c1_i64 = arith.constant 1 : i64
    %0 = llvm.alloca %c1_i64 x f32 : (i64) -> !llvm.ptr
    llvm.store %arg1, %0 : f32, !llvm.ptr
    cf.br ^bb1
  ^bb1:  // pred: ^bb0
    %1 = llvm.load %0 : !llvm.ptr -> f32
    %2 = llvm.load %0 : !llvm.ptr -> f32
    %3 = arith.addf %1, %2 : f32
    %4 = llvm.load %0 : !llvm.ptr -> f32
    %5 = arith.addf %3, %4 : f32
    %6 = llvm.load %0 : !llvm.ptr -> f32
    %7 = arith.addf %5, %6 : f32
    %8 = llvm.load %0 : !llvm.ptr -> f32
    %9 = arith.addf %7, %8 : f32
    %10 = llvm.load %0 : !llvm.ptr -> f32
    %11 = arith.addf %9, %10 : f32
    cf.br ^bb2(%11 : f32)
  ^bb2(%12: f32):  // pred: ^bb1
    return %12 : f32
  }
  func.func public @f64.no_fold_6x_via_add(%arg0: !llvm.ptr, %arg1: f64) -> f64 attributes {llvm.emit_c_interface} {
    %c1_i64 = arith.constant 1 : i64
    %0 = llvm.alloca %c1_i64 x f64 : (i64) -> !llvm.ptr
    llvm.store %arg1, %0 : f64, !llvm.ptr
    cf.br ^bb1
  ^bb1:  // pred: ^bb0
    %1 = llvm.load %0 : !llvm.ptr -> f64
    %2 = llvm.load %0 : !llvm.ptr -> f64
    %3 = arith.addf %1, %2 : f64
    %4 = llvm.load %0 : !llvm.ptr -> f64
    %5 = arith.addf %3, %4 : f64
    %6 = llvm.load %0 : !llvm.ptr -> f64
    %7 = arith.addf %5, %6 : f64
    %8 = llvm.load %0 : !llvm.ptr -> f64
    %9 = arith.addf %7, %8 : f64
    %10 = llvm.load %0 : !llvm.ptr -> f64
    %11 = arith.addf %9, %10 : f64
    cf.br ^bb2(%11 : f64)
  ^bb2(%12: f64):  // pred: ^bb1
    return %12 : f64
  }
  func.func public @f32.no_fold_div_div(%arg0: !llvm.ptr, %arg1: f32, %arg2: f32, %arg3: f32) -> f32 attributes {llvm.emit_c_interface} {
    %c1_i64 = arith.constant 1 : i64
    %0 = llvm.alloca %c1_i64 x f32 : (i64) -> !llvm.ptr
    llvm.store %arg1, %0 : f32, !llvm.ptr
    %c1_i64_0 = arith.constant 1 : i64
    %1 = llvm.alloca %c1_i64_0 x f32 : (i64) -> !llvm.ptr
    llvm.store %arg2, %1 : f32, !llvm.ptr
    %c1_i64_1 = arith.constant 1 : i64
    %2 = llvm.alloca %c1_i64_1 x f32 : (i64) -> !llvm.ptr
    llvm.store %arg3, %2 : f32, !llvm.ptr
    cf.br ^bb1
  ^bb1:  // pred: ^bb0
    %3 = llvm.load %0 : !llvm.ptr -> f32
    %4 = llvm.load %1 : !llvm.ptr -> f32
    %cst = arith.constant 0.000000e+00 : f32
    %5 = arith.cmpf oeq, %4, %cst : f32
    %6 = scf.if %5 -> (f32) {
      scf.yield %cst : f32
    } else {
      %11 = arith.divf %3, %4 : f32
      scf.yield %11 : f32
    }
    %7 = llvm.load %2 : !llvm.ptr -> f32
    %cst_2 = arith.constant 0.000000e+00 : f32
    %8 = arith.cmpf oeq, %7, %cst_2 : f32
    %9 = scf.if %8 -> (f32) {
      scf.yield %cst_2 : f32
    } else {
      %11 = arith.divf %6, %7 : f32
      scf.yield %11 : f32
    }
    cf.br ^bb2(%9 : f32)
  ^bb2(%10: f32):  // pred: ^bb1
    return %10 : f32
  }
  func.func public @f64.no_fold_div_div(%arg0: !llvm.ptr, %arg1: f64, %arg2: f64, %arg3: f64) -> f64 attributes {llvm.emit_c_interface} {
    %c1_i64 = arith.constant 1 : i64
    %0 = llvm.alloca %c1_i64 x f64 : (i64) -> !llvm.ptr
    llvm.store %arg1, %0 : f64, !llvm.ptr
    %c1_i64_0 = arith.constant 1 : i64
    %1 = llvm.alloca %c1_i64_0 x f64 : (i64) -> !llvm.ptr
    llvm.store %arg2, %1 : f64, !llvm.ptr
    %c1_i64_1 = arith.constant 1 : i64
    %2 = llvm.alloca %c1_i64_1 x f64 : (i64) -> !llvm.ptr
    llvm.store %arg3, %2 : f64, !llvm.ptr
    cf.br ^bb1
  ^bb1:  // pred: ^bb0
    %3 = llvm.load %0 : !llvm.ptr -> f64
    %4 = llvm.load %1 : !llvm.ptr -> f64
    %cst = arith.constant 0.000000e+00 : f64
    %5 = arith.cmpf oeq, %4, %cst : f64
    %6 = scf.if %5 -> (f64) {
      scf.yield %cst : f64
    } else {
      %11 = arith.divf %3, %4 : f64
      scf.yield %11 : f64
    }
    %7 = llvm.load %2 : !llvm.ptr -> f64
    %cst_2 = arith.constant 0.000000e+00 : f64
    %8 = arith.cmpf oeq, %7, %cst_2 : f64
    %9 = scf.if %8 -> (f64) {
      scf.yield %cst_2 : f64
    } else {
      %11 = arith.divf %6, %7 : f64
      scf.yield %11 : f64
    }
    cf.br ^bb2(%9 : f64)
  ^bb2(%10: f64):  // pred: ^bb1
    return %10 : f64
  }
  func.func public @f32.no_fold_mul_divs(%arg0: !llvm.ptr, %arg1: f32, %arg2: f32, %arg3: f32, %arg4: f32) -> f32 attributes {llvm.emit_c_interface} {
    %c1_i64 = arith.constant 1 : i64
    %0 = llvm.alloca %c1_i64 x f32 : (i64) -> !llvm.ptr
    llvm.store %arg1, %0 : f32, !llvm.ptr
    %c1_i64_0 = arith.constant 1 : i64
    %1 = llvm.alloca %c1_i64_0 x f32 : (i64) -> !llvm.ptr
    llvm.store %arg2, %1 : f32, !llvm.ptr
    %c1_i64_1 = arith.constant 1 : i64
    %2 = llvm.alloca %c1_i64_1 x f32 : (i64) -> !llvm.ptr
    llvm.store %arg3, %2 : f32, !llvm.ptr
    %c1_i64_2 = arith.constant 1 : i64
    %3 = llvm.alloca %c1_i64_2 x f32 : (i64) -> !llvm.ptr
    llvm.store %arg4, %3 : f32, !llvm.ptr
    cf.br ^bb1
  ^bb1:  // pred: ^bb0
    %4 = llvm.load %0 : !llvm.ptr -> f32
    %5 = llvm.load %1 : !llvm.ptr -> f32
    %cst = arith.constant 0.000000e+00 : f32
    %6 = arith.cmpf oeq, %5, %cst : f32
    %7 = scf.if %6 -> (f32) {
      scf.yield %cst : f32
    } else {
      %14 = arith.divf %4, %5 : f32
      scf.yield %14 : f32
    }
    %8 = llvm.load %2 : !llvm.ptr -> f32
    %9 = llvm.load %3 : !llvm.ptr -> f32
    %cst_3 = arith.constant 0.000000e+00 : f32
    %10 = arith.cmpf oeq, %9, %cst_3 : f32
    %11 = scf.if %10 -> (f32) {
      scf.yield %cst_3 : f32
    } else {
      %14 = arith.divf %8, %9 : f32
      scf.yield %14 : f32
    }
    %12 = arith.mulf %7, %11 : f32
    cf.br ^bb2(%12 : f32)
  ^bb2(%13: f32):  // pred: ^bb1
    return %13 : f32
  }
  func.func public @f64.no_fold_mul_divs(%arg0: !llvm.ptr, %arg1: f64, %arg2: f64, %arg3: f64, %arg4: f64) -> f64 attributes {llvm.emit_c_interface} {
    %c1_i64 = arith.constant 1 : i64
    %0 = llvm.alloca %c1_i64 x f64 : (i64) -> !llvm.ptr
    llvm.store %arg1, %0 : f64, !llvm.ptr
    %c1_i64_0 = arith.constant 1 : i64
    %1 = llvm.alloca %c1_i64_0 x f64 : (i64) -> !llvm.ptr
    llvm.store %arg2, %1 : f64, !llvm.ptr
    %c1_i64_1 = arith.constant 1 : i64
    %2 = llvm.alloca %c1_i64_1 x f64 : (i64) -> !llvm.ptr
    llvm.store %arg3, %2 : f64, !llvm.ptr
    %c1_i64_2 = arith.constant 1 : i64
    %3 = llvm.alloca %c1_i64_2 x f64 : (i64) -> !llvm.ptr
    llvm.store %arg4, %3 : f64, !llvm.ptr
    cf.br ^bb1
  ^bb1:  // pred: ^bb0
    %4 = llvm.load %0 : !llvm.ptr -> f64
    %5 = llvm.load %1 : !llvm.ptr -> f64
    %cst = arith.constant 0.000000e+00 : f64
    %6 = arith.cmpf oeq, %5, %cst : f64
    %7 = scf.if %6 -> (f64) {
      scf.yield %cst : f64
    } else {
      %14 = arith.divf %4, %5 : f64
      scf.yield %14 : f64
    }
    %8 = llvm.load %2 : !llvm.ptr -> f64
    %9 = llvm.load %3 : !llvm.ptr -> f64
    %cst_3 = arith.constant 0.000000e+00 : f64
    %10 = arith.cmpf oeq, %9, %cst_3 : f64
    %11 = scf.if %10 -> (f64) {
      scf.yield %cst_3 : f64
    } else {
      %14 = arith.divf %8, %9 : f64
      scf.yield %14 : f64
    }
    %12 = arith.mulf %7, %11 : f64
    cf.br ^bb2(%12 : f64)
  ^bb2(%13: f64):  // pred: ^bb1
    return %13 : f64
  }
  func.func public @f32.no_fold_add_divs(%arg0: !llvm.ptr, %arg1: f32, %arg2: f32, %arg3: f32) -> f32 attributes {llvm.emit_c_interface} {
    %c1_i64 = arith.constant 1 : i64
    %0 = llvm.alloca %c1_i64 x f32 : (i64) -> !llvm.ptr
    llvm.store %arg1, %0 : f32, !llvm.ptr
    %c1_i64_0 = arith.constant 1 : i64
    %1 = llvm.alloca %c1_i64_0 x f32 : (i64) -> !llvm.ptr
    llvm.store %arg2, %1 : f32, !llvm.ptr
    %c1_i64_1 = arith.constant 1 : i64
    %2 = llvm.alloca %c1_i64_1 x f32 : (i64) -> !llvm.ptr
    llvm.store %arg3, %2 : f32, !llvm.ptr
    cf.br ^bb1
  ^bb1:  // pred: ^bb0
    %3 = llvm.load %0 : !llvm.ptr -> f32
    %4 = llvm.load %2 : !llvm.ptr -> f32
    %cst = arith.constant 0.000000e+00 : f32
    %5 = arith.cmpf oeq, %4, %cst : f32
    %6 = scf.if %5 -> (f32) {
      scf.yield %cst : f32
    } else {
      %13 = arith.divf %3, %4 : f32
      scf.yield %13 : f32
    }
    %7 = llvm.load %1 : !llvm.ptr -> f32
    %8 = llvm.load %2 : !llvm.ptr -> f32
    %cst_2 = arith.constant 0.000000e+00 : f32
    %9 = arith.cmpf oeq, %8, %cst_2 : f32
    %10 = scf.if %9 -> (f32) {
      scf.yield %cst_2 : f32
    } else {
      %13 = arith.divf %7, %8 : f32
      scf.yield %13 : f32
    }
    %11 = arith.addf %6, %10 : f32
    cf.br ^bb2(%11 : f32)
  ^bb2(%12: f32):  // pred: ^bb1
    return %12 : f32
  }
  func.func public @f64.no_fold_add_divs(%arg0: !llvm.ptr, %arg1: f64, %arg2: f64, %arg3: f64) -> f64 attributes {llvm.emit_c_interface} {
    %c1_i64 = arith.constant 1 : i64
    %0 = llvm.alloca %c1_i64 x f64 : (i64) -> !llvm.ptr
    llvm.store %arg1, %0 : f64, !llvm.ptr
    %c1_i64_0 = arith.constant 1 : i64
    %1 = llvm.alloca %c1_i64_0 x f64 : (i64) -> !llvm.ptr
    llvm.store %arg2, %1 : f64, !llvm.ptr
    %c1_i64_1 = arith.constant 1 : i64
    %2 = llvm.alloca %c1_i64_1 x f64 : (i64) -> !llvm.ptr
    llvm.store %arg3, %2 : f64, !llvm.ptr
    cf.br ^bb1
  ^bb1:  // pred: ^bb0
    %3 = llvm.load %0 : !llvm.ptr -> f64
    %4 = llvm.load %2 : !llvm.ptr -> f64
    %cst = arith.constant 0.000000e+00 : f64
    %5 = arith.cmpf oeq, %4, %cst : f64
    %6 = scf.if %5 -> (f64) {
      scf.yield %cst : f64
    } else {
      %13 = arith.divf %3, %4 : f64
      scf.yield %13 : f64
    }
    %7 = llvm.load %1 : !llvm.ptr -> f64
    %8 = llvm.load %2 : !llvm.ptr -> f64
    %cst_2 = arith.constant 0.000000e+00 : f64
    %9 = arith.cmpf oeq, %8, %cst_2 : f64
    %10 = scf.if %9 -> (f64) {
      scf.yield %cst_2 : f64
    } else {
      %13 = arith.divf %7, %8 : f64
      scf.yield %13 : f64
    }
    %11 = arith.addf %6, %10 : f64
    cf.br ^bb2(%11 : f64)
  ^bb2(%12: f64):  // pred: ^bb1
    return %12 : f64
  }
  func.func public @f32.no_fold_sqrt_square(%arg0: !llvm.ptr, %arg1: f32) -> f32 attributes {llvm.emit_c_interface} {
    %c1_i64 = arith.constant 1 : i64
    %0 = llvm.alloca %c1_i64 x f32 : (i64) -> !llvm.ptr
    llvm.store %arg1, %0 : f32, !llvm.ptr
    cf.br ^bb1
  ^bb1:  // pred: ^bb0
    %1 = llvm.load %0 : !llvm.ptr -> f32
    %2 = llvm.load %0 : !llvm.ptr -> f32
    %3 = arith.mulf %1, %2 : f32
    %4 = math.sqrt %3 : f32
    cf.br ^bb2(%4 : f32)
  ^bb2(%5: f32):  // pred: ^bb1
    return %5 : f32
  }
  func.func public @f64.no_fold_sqrt_square(%arg0: !llvm.ptr, %arg1: f64) -> f64 attributes {llvm.emit_c_interface} {
    %c1_i64 = arith.constant 1 : i64
    %0 = llvm.alloca %c1_i64 x f64 : (i64) -> !llvm.ptr
    llvm.store %arg1, %0 : f64, !llvm.ptr
    cf.br ^bb1
  ^bb1:  // pred: ^bb0
    %1 = llvm.load %0 : !llvm.ptr -> f64
    %2 = llvm.load %0 : !llvm.ptr -> f64
    %3 = arith.mulf %1, %2 : f64
    %4 = math.sqrt %3 : f64
    cf.br ^bb2(%4 : f64)
  ^bb2(%5: f64):  // pred: ^bb1
    return %5 : f64
  }
  func.func public @f32.no_fold_mul_sqrts(%arg0: !llvm.ptr, %arg1: f32, %arg2: f32) -> f32 attributes {llvm.emit_c_interface} {
    %c1_i64 = arith.constant 1 : i64
    %0 = llvm.alloca %c1_i64 x f32 : (i64) -> !llvm.ptr
    llvm.store %arg1, %0 : f32, !llvm.ptr
    %c1_i64_0 = arith.constant 1 : i64
    %1 = llvm.alloca %c1_i64_0 x f32 : (i64) -> !llvm.ptr
    llvm.store %arg2, %1 : f32, !llvm.ptr
    cf.br ^bb1
  ^bb1:  // pred: ^bb0
    %2 = llvm.load %0 : !llvm.ptr -> f32
    %3 = math.sqrt %2 : f32
    %4 = llvm.load %1 : !llvm.ptr -> f32
    %5 = math.sqrt %4 : f32
    %6 = arith.mulf %3, %5 : f32
    cf.br ^bb2(%6 : f32)
  ^bb2(%7: f32):  // pred: ^bb1
    return %7 : f32
  }
  func.func public @f64.no_fold_mul_sqrts(%arg0: !llvm.ptr, %arg1: f64, %arg2: f64) -> f64 attributes {llvm.emit_c_interface} {
    %c1_i64 = arith.constant 1 : i64
    %0 = llvm.alloca %c1_i64 x f64 : (i64) -> !llvm.ptr
    llvm.store %arg1, %0 : f64, !llvm.ptr
    %c1_i64_0 = arith.constant 1 : i64
    %1 = llvm.alloca %c1_i64_0 x f64 : (i64) -> !llvm.ptr
    llvm.store %arg2, %1 : f64, !llvm.ptr
    cf.br ^bb1
  ^bb1:  // pred: ^bb0
    %2 = llvm.load %0 : !llvm.ptr -> f64
    %3 = math.sqrt %2 : f64
    %4 = llvm.load %1 : !llvm.ptr -> f64
    %5 = math.sqrt %4 : f64
    %6 = arith.mulf %3, %5 : f64
    cf.br ^bb2(%6 : f64)
  ^bb2(%7: f64):  // pred: ^bb1
    return %7 : f64
  }
  func.func public @f32.no_fold_div_sqrts(%arg0: !llvm.ptr, %arg1: f32, %arg2: f32) -> f32 attributes {llvm.emit_c_interface} {
    %c1_i64 = arith.constant 1 : i64
    %0 = llvm.alloca %c1_i64 x f32 : (i64) -> !llvm.ptr
    llvm.store %arg1, %0 : f32, !llvm.ptr
    %c1_i64_0 = arith.constant 1 : i64
    %1 = llvm.alloca %c1_i64_0 x f32 : (i64) -> !llvm.ptr
    llvm.store %arg2, %1 : f32, !llvm.ptr
    cf.br ^bb1
  ^bb1:  // pred: ^bb0
    %2 = llvm.load %0 : !llvm.ptr -> f32
    %3 = math.sqrt %2 : f32
    %4 = llvm.load %1 : !llvm.ptr -> f32
    %5 = math.sqrt %4 : f32
    %cst = arith.constant 0.000000e+00 : f32
    %6 = arith.cmpf oeq, %5, %cst : f32
    %7 = scf.if %6 -> (f32) {
      scf.yield %cst : f32
    } else {
      %9 = arith.divf %3, %5 : f32
      scf.yield %9 : f32
    }
    cf.br ^bb2(%7 : f32)
  ^bb2(%8: f32):  // pred: ^bb1
    return %8 : f32
  }
  func.func public @f64.no_fold_div_sqrts(%arg0: !llvm.ptr, %arg1: f64, %arg2: f64) -> f64 attributes {llvm.emit_c_interface} {
    %c1_i64 = arith.constant 1 : i64
    %0 = llvm.alloca %c1_i64 x f64 : (i64) -> !llvm.ptr
    llvm.store %arg1, %0 : f64, !llvm.ptr
    %c1_i64_0 = arith.constant 1 : i64
    %1 = llvm.alloca %c1_i64_0 x f64 : (i64) -> !llvm.ptr
    llvm.store %arg2, %1 : f64, !llvm.ptr
    cf.br ^bb1
  ^bb1:  // pred: ^bb0
    %2 = llvm.load %0 : !llvm.ptr -> f64
    %3 = math.sqrt %2 : f64
    %4 = llvm.load %1 : !llvm.ptr -> f64
    %5 = math.sqrt %4 : f64
    %cst = arith.constant 0.000000e+00 : f64
    %6 = arith.cmpf oeq, %5, %cst : f64
    %7 = scf.if %6 -> (f64) {
      scf.yield %cst : f64
    } else {
      %9 = arith.divf %3, %5 : f64
      scf.yield %9 : f64
    }
    cf.br ^bb2(%7 : f64)
  ^bb2(%8: f64):  // pred: ^bb1
    return %8 : f64
  }
  func.func public @f32.no_fold_mul_sqrt_div(%arg0: !llvm.ptr, %arg1: f32, %arg2: f32) -> f32 attributes {llvm.emit_c_interface} {
    %c1_i64 = arith.constant 1 : i64
    %0 = llvm.alloca %c1_i64 x f32 : (i64) -> !llvm.ptr
    llvm.store %arg1, %0 : f32, !llvm.ptr
    %c1_i64_0 = arith.constant 1 : i64
    %1 = llvm.alloca %c1_i64_0 x f32 : (i64) -> !llvm.ptr
    llvm.store %arg2, %1 : f32, !llvm.ptr
    cf.br ^bb1
  ^bb1:  // pred: ^bb0
    %2 = llvm.load %0 : !llvm.ptr -> f32
    %3 = llvm.load %1 : !llvm.ptr -> f32
    %4 = math.sqrt %3 : f32
    %5 = arith.mulf %2, %4 : f32
    %6 = llvm.load %1 : !llvm.ptr -> f32
    %cst = arith.constant 0.000000e+00 : f32
    %7 = arith.cmpf oeq, %6, %cst : f32
    %8 = scf.if %7 -> (f32) {
      scf.yield %cst : f32
    } else {
      %10 = arith.divf %5, %6 : f32
      scf.yield %10 : f32
    }
    cf.br ^bb2(%8 : f32)
  ^bb2(%9: f32):  // pred: ^bb1
    return %9 : f32
  }
  func.func public @f64.no_fold_mul_sqrt_div(%arg0: !llvm.ptr, %arg1: f64, %arg2: f64) -> f64 attributes {llvm.emit_c_interface} {
    %c1_i64 = arith.constant 1 : i64
    %0 = llvm.alloca %c1_i64 x f64 : (i64) -> !llvm.ptr
    llvm.store %arg1, %0 : f64, !llvm.ptr
    %c1_i64_0 = arith.constant 1 : i64
    %1 = llvm.alloca %c1_i64_0 x f64 : (i64) -> !llvm.ptr
    llvm.store %arg2, %1 : f64, !llvm.ptr
    cf.br ^bb1
  ^bb1:  // pred: ^bb0
    %2 = llvm.load %0 : !llvm.ptr -> f64
    %3 = llvm.load %1 : !llvm.ptr -> f64
    %4 = math.sqrt %3 : f64
    %5 = arith.mulf %2, %4 : f64
    %6 = llvm.load %1 : !llvm.ptr -> f64
    %cst = arith.constant 0.000000e+00 : f64
    %7 = arith.cmpf oeq, %6, %cst : f64
    %8 = scf.if %7 -> (f64) {
      scf.yield %cst : f64
    } else {
      %10 = arith.divf %5, %6 : f64
      scf.yield %10 : f64
    }
    cf.br ^bb2(%8 : f64)
  ^bb2(%9: f64):  // pred: ^bb1
    return %9 : f64
  }
  func.func public @f32.no_flush_intermediate_subnormal(%arg0: !llvm.ptr, %arg1: f32, %arg2: f32, %arg3: f32) -> f32 attributes {llvm.emit_c_interface} {
    %c1_i64 = arith.constant 1 : i64
    %0 = llvm.alloca %c1_i64 x f32 : (i64) -> !llvm.ptr
    llvm.store %arg1, %0 : f32, !llvm.ptr
    %c1_i64_0 = arith.constant 1 : i64
    %1 = llvm.alloca %c1_i64_0 x f32 : (i64) -> !llvm.ptr
    llvm.store %arg2, %1 : f32, !llvm.ptr
    %c1_i64_1 = arith.constant 1 : i64
    %2 = llvm.alloca %c1_i64_1 x f32 : (i64) -> !llvm.ptr
    llvm.store %arg3, %2 : f32, !llvm.ptr
    cf.br ^bb1
  ^bb1:  // pred: ^bb0
    %3 = llvm.load %0 : !llvm.ptr -> f32
    %4 = llvm.load %1 : !llvm.ptr -> f32
    %5 = arith.mulf %3, %4 : f32
    %6 = llvm.load %2 : !llvm.ptr -> f32
    %7 = arith.mulf %5, %6 : f32
    cf.br ^bb2(%7 : f32)
  ^bb2(%8: f32):  // pred: ^bb1
    return %8 : f32
  }
  func.func public @f64.no_flush_intermediate_subnormal(%arg0: !llvm.ptr, %arg1: f64, %arg2: f64, %arg3: f64) -> f64 attributes {llvm.emit_c_interface} {
    %c1_i64 = arith.constant 1 : i64
    %0 = llvm.alloca %c1_i64 x f64 : (i64) -> !llvm.ptr
    llvm.store %arg1, %0 : f64, !llvm.ptr
    %c1_i64_0 = arith.constant 1 : i64
    %1 = llvm.alloca %c1_i64_0 x f64 : (i64) -> !llvm.ptr
    llvm.store %arg2, %1 : f64, !llvm.ptr
    %c1_i64_1 = arith.constant 1 : i64
    %2 = llvm.alloca %c1_i64_1 x f64 : (i64) -> !llvm.ptr
    llvm.store %arg3, %2 : f64, !llvm.ptr
    cf.br ^bb1
  ^bb1:  // pred: ^bb0
    %3 = llvm.load %0 : !llvm.ptr -> f64
    %4 = llvm.load %1 : !llvm.ptr -> f64
    %5 = arith.mulf %3, %4 : f64
    %6 = llvm.load %2 : !llvm.ptr -> f64
    %7 = arith.mulf %5, %6 : f64
    cf.br ^bb2(%7 : f64)
  ^bb2(%8: f64):  // pred: ^bb1
    return %8 : f64
  }
  func.func public @f32.recoding_eq(%arg0: !llvm.ptr, %arg1: f32, %arg2: f32) -> i32 attributes {llvm.emit_c_interface} {
    %c1_i64 = arith.constant 1 : i64
    %0 = llvm.alloca %c1_i64 x f32 : (i64) -> !llvm.ptr
    llvm.store %arg1, %0 : f32, !llvm.ptr
    %c1_i64_0 = arith.constant 1 : i64
    %1 = llvm.alloca %c1_i64_0 x f32 : (i64) -> !llvm.ptr
    llvm.store %arg2, %1 : f32, !llvm.ptr
    cf.br ^bb1
  ^bb1:  // pred: ^bb0
    %2 = llvm.load %0 : !llvm.ptr -> f32
    %3 = llvm.load %1 : !llvm.ptr -> f32
    %4 = arith.mulf %2, %3 : f32
    %5 = llvm.load %0 : !llvm.ptr -> f32
    %6 = arith.cmpf oeq, %4, %5 : f32
    %7 = arith.extui %6 : i1 to i32
    cf.br ^bb2(%7 : i32)
  ^bb2(%8: i32):  // pred: ^bb1
    return %8 : i32
  }
  func.func public @f32.recoding_le(%arg0: !llvm.ptr, %arg1: f32, %arg2: f32) -> i32 attributes {llvm.emit_c_interface} {
    %c1_i64 = arith.constant 1 : i64
    %0 = llvm.alloca %c1_i64 x f32 : (i64) -> !llvm.ptr
    llvm.store %arg1, %0 : f32, !llvm.ptr
    %c1_i64_0 = arith.constant 1 : i64
    %1 = llvm.alloca %c1_i64_0 x f32 : (i64) -> !llvm.ptr
    llvm.store %arg2, %1 : f32, !llvm.ptr
    cf.br ^bb1
  ^bb1:  // pred: ^bb0
    %2 = llvm.load %0 : !llvm.ptr -> f32
    %3 = llvm.load %1 : !llvm.ptr -> f32
    %4 = arith.mulf %2, %3 : f32
    %5 = llvm.load %0 : !llvm.ptr -> f32
    %6 = arith.cmpf ole, %4, %5 : f32
    %7 = arith.extui %6 : i1 to i32
    cf.br ^bb2(%7 : i32)
  ^bb2(%8: i32):  // pred: ^bb1
    return %8 : i32
  }
  func.func public @f32.recoding_lt(%arg0: !llvm.ptr, %arg1: f32, %arg2: f32) -> i32 attributes {llvm.emit_c_interface} {
    %c1_i64 = arith.constant 1 : i64
    %0 = llvm.alloca %c1_i64 x f32 : (i64) -> !llvm.ptr
    llvm.store %arg1, %0 : f32, !llvm.ptr
    %c1_i64_0 = arith.constant 1 : i64
    %1 = llvm.alloca %c1_i64_0 x f32 : (i64) -> !llvm.ptr
    llvm.store %arg2, %1 : f32, !llvm.ptr
    cf.br ^bb1
  ^bb1:  // pred: ^bb0
    %2 = llvm.load %0 : !llvm.ptr -> f32
    %3 = llvm.load %1 : !llvm.ptr -> f32
    %4 = arith.mulf %2, %3 : f32
    %5 = llvm.load %0 : !llvm.ptr -> f32
    %6 = arith.cmpf olt, %4, %5 : f32
    %7 = arith.extui %6 : i1 to i32
    cf.br ^bb2(%7 : i32)
  ^bb2(%8: i32):  // pred: ^bb1
    return %8 : i32
  }
  func.func public @f64.recoding_eq(%arg0: !llvm.ptr, %arg1: f64, %arg2: f64) -> i32 attributes {llvm.emit_c_interface} {
    %c1_i64 = arith.constant 1 : i64
    %0 = llvm.alloca %c1_i64 x f64 : (i64) -> !llvm.ptr
    llvm.store %arg1, %0 : f64, !llvm.ptr
    %c1_i64_0 = arith.constant 1 : i64
    %1 = llvm.alloca %c1_i64_0 x f64 : (i64) -> !llvm.ptr
    llvm.store %arg2, %1 : f64, !llvm.ptr
    cf.br ^bb1
  ^bb1:  // pred: ^bb0
    %2 = llvm.load %0 : !llvm.ptr -> f64
    %3 = llvm.load %1 : !llvm.ptr -> f64
    %4 = arith.mulf %2, %3 : f64
    %5 = llvm.load %0 : !llvm.ptr -> f64
    %6 = arith.cmpf oeq, %4, %5 : f64
    %7 = arith.extui %6 : i1 to i32
    cf.br ^bb2(%7 : i32)
  ^bb2(%8: i32):  // pred: ^bb1
    return %8 : i32
  }
  func.func public @f64.recoding_le(%arg0: !llvm.ptr, %arg1: f64, %arg2: f64) -> i32 attributes {llvm.emit_c_interface} {
    %c1_i64 = arith.constant 1 : i64
    %0 = llvm.alloca %c1_i64 x f64 : (i64) -> !llvm.ptr
    llvm.store %arg1, %0 : f64, !llvm.ptr
    %c1_i64_0 = arith.constant 1 : i64
    %1 = llvm.alloca %c1_i64_0 x f64 : (i64) -> !llvm.ptr
    llvm.store %arg2, %1 : f64, !llvm.ptr
    cf.br ^bb1
  ^bb1:  // pred: ^bb0
    %2 = llvm.load %0 : !llvm.ptr -> f64
    %3 = llvm.load %1 : !llvm.ptr -> f64
    %4 = arith.mulf %2, %3 : f64
    %5 = llvm.load %0 : !llvm.ptr -> f64
    %6 = arith.cmpf ole, %4, %5 : f64
    %7 = arith.extui %6 : i1 to i32
    cf.br ^bb2(%7 : i32)
  ^bb2(%8: i32):  // pred: ^bb1
    return %8 : i32
  }
  func.func public @f64.recoding_lt(%arg0: !llvm.ptr, %arg1: f64, %arg2: f64) -> i32 attributes {llvm.emit_c_interface} {
    %c1_i64 = arith.constant 1 : i64
    %0 = llvm.alloca %c1_i64 x f64 : (i64) -> !llvm.ptr
    llvm.store %arg1, %0 : f64, !llvm.ptr
    %c1_i64_0 = arith.constant 1 : i64
    %1 = llvm.alloca %c1_i64_0 x f64 : (i64) -> !llvm.ptr
    llvm.store %arg2, %1 : f64, !llvm.ptr
    cf.br ^bb1
  ^bb1:  // pred: ^bb0
    %2 = llvm.load %0 : !llvm.ptr -> f64
    %3 = llvm.load %1 : !llvm.ptr -> f64
    %4 = arith.mulf %2, %3 : f64
    %5 = llvm.load %0 : !llvm.ptr -> f64
    %6 = arith.cmpf olt, %4, %5 : f64
    %7 = arith.extui %6 : i1 to i32
    cf.br ^bb2(%7 : i32)
  ^bb2(%8: i32):  // pred: ^bb1
    return %8 : i32
  }
  func.func public @recoding_demote(%arg0: !llvm.ptr, %arg1: f64, %arg2: f32) -> f32 attributes {llvm.emit_c_interface} {
    %c1_i64 = arith.constant 1 : i64
    %0 = llvm.alloca %c1_i64 x f64 : (i64) -> !llvm.ptr
    llvm.store %arg1, %0 : f64, !llvm.ptr
    %c1_i64_0 = arith.constant 1 : i64
    %1 = llvm.alloca %c1_i64_0 x f32 : (i64) -> !llvm.ptr
    llvm.store %arg2, %1 : f32, !llvm.ptr
    cf.br ^bb1
  ^bb1:  // pred: ^bb0
    %2 = llvm.load %0 : !llvm.ptr -> f64
    %3 = arith.truncf %2 : f64 to f32
    %4 = llvm.load %1 : !llvm.ptr -> f32
    %5 = arith.mulf %3, %4 : f32
    cf.br ^bb2(%5 : f32)
  ^bb2(%6: f32):  // pred: ^bb1
    return %6 : f32
  }
  func.func public @f32.no_extended_precision_div(%arg0: !llvm.ptr, %arg1: f32, %arg2: f32, %arg3: f32) -> i32 attributes {llvm.emit_c_interface} {
    %c1_i64 = arith.constant 1 : i64
    %0 = llvm.alloca %c1_i64 x f32 : (i64) -> !llvm.ptr
    llvm.store %arg1, %0 : f32, !llvm.ptr
    %c1_i64_0 = arith.constant 1 : i64
    %1 = llvm.alloca %c1_i64_0 x f32 : (i64) -> !llvm.ptr
    llvm.store %arg2, %1 : f32, !llvm.ptr
    %c1_i64_1 = arith.constant 1 : i64
    %2 = llvm.alloca %c1_i64_1 x f32 : (i64) -> !llvm.ptr
    llvm.store %arg3, %2 : f32, !llvm.ptr
    cf.br ^bb1
  ^bb1:  // pred: ^bb0
    %3 = llvm.load %0 : !llvm.ptr -> f32
    %4 = llvm.load %1 : !llvm.ptr -> f32
    %cst = arith.constant 0.000000e+00 : f32
    %5 = arith.cmpf oeq, %4, %cst : f32
    %6 = scf.if %5 -> (f32) {
      scf.yield %cst : f32
    } else {
      %11 = arith.divf %3, %4 : f32
      scf.yield %11 : f32
    }
    %7 = llvm.load %2 : !llvm.ptr -> f32
    %8 = arith.cmpf oeq, %6, %7 : f32
    %9 = arith.extui %8 : i1 to i32
    cf.br ^bb2(%9 : i32)
  ^bb2(%10: i32):  // pred: ^bb1
    return %10 : i32
  }
  func.func public @f64.no_extended_precision_div(%arg0: !llvm.ptr, %arg1: f64, %arg2: f64, %arg3: f64) -> i32 attributes {llvm.emit_c_interface} {
    %c1_i64 = arith.constant 1 : i64
    %0 = llvm.alloca %c1_i64 x f64 : (i64) -> !llvm.ptr
    llvm.store %arg1, %0 : f64, !llvm.ptr
    %c1_i64_0 = arith.constant 1 : i64
    %1 = llvm.alloca %c1_i64_0 x f64 : (i64) -> !llvm.ptr
    llvm.store %arg2, %1 : f64, !llvm.ptr
    %c1_i64_1 = arith.constant 1 : i64
    %2 = llvm.alloca %c1_i64_1 x f64 : (i64) -> !llvm.ptr
    llvm.store %arg3, %2 : f64, !llvm.ptr
    cf.br ^bb1
  ^bb1:  // pred: ^bb0
    %3 = llvm.load %0 : !llvm.ptr -> f64
    %4 = llvm.load %1 : !llvm.ptr -> f64
    %cst = arith.constant 0.000000e+00 : f64
    %5 = arith.cmpf oeq, %4, %cst : f64
    %6 = scf.if %5 -> (f64) {
      scf.yield %cst : f64
    } else {
      %11 = arith.divf %3, %4 : f64
      scf.yield %11 : f64
    }
    %7 = llvm.load %2 : !llvm.ptr -> f64
    %8 = arith.cmpf oeq, %6, %7 : f64
    %9 = arith.extui %8 : i1 to i32
    cf.br ^bb2(%9 : i32)
  ^bb2(%10: i32):  // pred: ^bb1
    return %10 : i32
  }
  func.func public @f32.no_distribute_exact(%arg0: !llvm.ptr, %arg1: f32) -> f32 attributes {llvm.emit_c_interface} {
    %c1_i64 = arith.constant 1 : i64
    %0 = llvm.alloca %c1_i64 x f32 : (i64) -> !llvm.ptr
    llvm.store %arg1, %0 : f32, !llvm.ptr
    cf.br ^bb1
  ^bb1:  // pred: ^bb0
    %c-1056964608_i32 = arith.constant -1056964608 : i32
    %1 = arith.bitcast %c-1056964608_i32 : i32 to f32
    %2 = llvm.load %0 : !llvm.ptr -> f32
    %3 = arith.mulf %1, %2 : f32
    %c1090519040_i32 = arith.constant 1090519040 : i32
    %4 = arith.bitcast %c1090519040_i32 : i32 to f32
    %5 = llvm.load %0 : !llvm.ptr -> f32
    %6 = arith.mulf %4, %5 : f32
    %7 = arith.addf %3, %6 : f32
    cf.br ^bb2(%7 : f32)
  ^bb2(%8: f32):  // pred: ^bb1
    return %8 : f32
  }
  func.func public @f64.no_distribute_exact(%arg0: !llvm.ptr, %arg1: f64) -> f64 attributes {llvm.emit_c_interface} {
    %c1_i64 = arith.constant 1 : i64
    %0 = llvm.alloca %c1_i64 x f64 : (i64) -> !llvm.ptr
    llvm.store %arg1, %0 : f64, !llvm.ptr
    cf.br ^bb1
  ^bb1:  // pred: ^bb0
    %c-4602678819172646912_i64 = arith.constant -4602678819172646912 : i64
    %1 = arith.bitcast %c-4602678819172646912_i64 : i64 to f64
    %2 = llvm.load %0 : !llvm.ptr -> f64
    %3 = arith.mulf %1, %2 : f64
    %c4620693217682128896_i64 = arith.constant 4620693217682128896 : i64
    %4 = arith.bitcast %c4620693217682128896_i64 : i64 to f64
    %5 = llvm.load %0 : !llvm.ptr -> f64
    %6 = arith.mulf %4, %5 : f64
    %7 = arith.addf %3, %6 : f64
    cf.br ^bb2(%7 : f64)
  ^bb2(%8: f64):  // pred: ^bb1
    return %8 : f64
  }
  func.func public @f32.sqrt(%arg0: !llvm.ptr, %arg1: f32) -> f32 attributes {llvm.emit_c_interface} {
    %c1_i64 = arith.constant 1 : i64
    %0 = llvm.alloca %c1_i64 x f32 : (i64) -> !llvm.ptr
    llvm.store %arg1, %0 : f32, !llvm.ptr
    cf.br ^bb1
  ^bb1:  // pred: ^bb0
    %1 = llvm.load %0 : !llvm.ptr -> f32
    %2 = math.sqrt %1 : f32
    cf.br ^bb2(%2 : f32)
  ^bb2(%3: f32):  // pred: ^bb1
    return %3 : f32
  }
  func.func public @f32.xkcd_sqrt_2(%arg0: !llvm.ptr, %arg1: f32, %arg2: f32, %arg3: f32, %arg4: f32) -> f32 attributes {llvm.emit_c_interface} {
    %c1_i64 = arith.constant 1 : i64
    %0 = llvm.alloca %c1_i64 x f32 : (i64) -> !llvm.ptr
    llvm.store %arg1, %0 : f32, !llvm.ptr
    %c1_i64_0 = arith.constant 1 : i64
    %1 = llvm.alloca %c1_i64_0 x f32 : (i64) -> !llvm.ptr
    llvm.store %arg2, %1 : f32, !llvm.ptr
    %c1_i64_1 = arith.constant 1 : i64
    %2 = llvm.alloca %c1_i64_1 x f32 : (i64) -> !llvm.ptr
    llvm.store %arg3, %2 : f32, !llvm.ptr
    %c1_i64_2 = arith.constant 1 : i64
    %3 = llvm.alloca %c1_i64_2 x f32 : (i64) -> !llvm.ptr
    llvm.store %arg4, %3 : f32, !llvm.ptr
    cf.br ^bb1
  ^bb1:  // pred: ^bb0
    %4 = llvm.load %0 : !llvm.ptr -> f32
    %5 = llvm.load %1 : !llvm.ptr -> f32
    %cst = arith.constant 0.000000e+00 : f32
    %6 = arith.cmpf oeq, %5, %cst : f32
    %7 = scf.if %6 -> (f32) {
      scf.yield %cst : f32
    } else {
      %16 = arith.divf %4, %5 : f32
      scf.yield %16 : f32
    }
    %8 = llvm.load %2 : !llvm.ptr -> f32
    %9 = llvm.load %3 : !llvm.ptr -> f32
    %10 = llvm.load %2 : !llvm.ptr -> f32
    %11 = arith.subf %9, %10 : f32
    %cst_3 = arith.constant 0.000000e+00 : f32
    %12 = arith.cmpf oeq, %11, %cst_3 : f32
    %13 = scf.if %12 -> (f32) {
      scf.yield %cst_3 : f32
    } else {
      %16 = arith.divf %8, %11 : f32
      scf.yield %16 : f32
    }
    %14 = arith.addf %7, %13 : f32
    cf.br ^bb2(%14 : f32)
  ^bb2(%15: f32):  // pred: ^bb1
    return %15 : f32
  }
  func.func public @f32.xkcd_sqrt_3(%arg0: !llvm.ptr, %arg1: f32, %arg2: f32, %arg3: f32) -> f32 attributes {llvm.emit_c_interface} {
    %c1_i64 = arith.constant 1 : i64
    %0 = llvm.alloca %c1_i64 x f32 : (i64) -> !llvm.ptr
    llvm.store %arg1, %0 : f32, !llvm.ptr
    %c1_i64_0 = arith.constant 1 : i64
    %1 = llvm.alloca %c1_i64_0 x f32 : (i64) -> !llvm.ptr
    llvm.store %arg2, %1 : f32, !llvm.ptr
    %c1_i64_1 = arith.constant 1 : i64
    %2 = llvm.alloca %c1_i64_1 x f32 : (i64) -> !llvm.ptr
    llvm.store %arg3, %2 : f32, !llvm.ptr
    cf.br ^bb1
  ^bb1:  // pred: ^bb0
    %3 = llvm.load %0 : !llvm.ptr -> f32
    %4 = llvm.load %1 : !llvm.ptr -> f32
    %5 = arith.mulf %3, %4 : f32
    %6 = llvm.load %2 : !llvm.ptr -> f32
    %cst = arith.constant 0.000000e+00 : f32
    %7 = arith.cmpf oeq, %6, %cst : f32
    %8 = scf.if %7 -> (f32) {
      scf.yield %cst : f32
    } else {
      %10 = arith.divf %5, %6 : f32
      scf.yield %10 : f32
    }
    cf.br ^bb2(%8 : f32)
  ^bb2(%9: f32):  // pred: ^bb1
    return %9 : f32
  }
  func.func public @f32.xkcd_sqrt_5(%arg0: !llvm.ptr, %arg1: f32, %arg2: f32, %arg3: f32) -> f32 attributes {llvm.emit_c_interface} {
    %c1_i64 = arith.constant 1 : i64
    %0 = llvm.alloca %c1_i64 x f32 : (i64) -> !llvm.ptr
    llvm.store %arg1, %0 : f32, !llvm.ptr
    %c1_i64_0 = arith.constant 1 : i64
    %1 = llvm.alloca %c1_i64_0 x f32 : (i64) -> !llvm.ptr
    llvm.store %arg2, %1 : f32, !llvm.ptr
    %c1_i64_1 = arith.constant 1 : i64
    %2 = llvm.alloca %c1_i64_1 x f32 : (i64) -> !llvm.ptr
    llvm.store %arg3, %2 : f32, !llvm.ptr
    cf.br ^bb1
  ^bb1:  // pred: ^bb0
    %3 = llvm.load %0 : !llvm.ptr -> f32
    %4 = llvm.load %1 : !llvm.ptr -> f32
    %cst = arith.constant 0.000000e+00 : f32
    %5 = arith.cmpf oeq, %4, %cst : f32
    %6 = scf.if %5 -> (f32) {
      scf.yield %cst : f32
    } else {
      %13 = arith.divf %3, %4 : f32
      scf.yield %13 : f32
    }
    %7 = llvm.load %2 : !llvm.ptr -> f32
    %8 = llvm.load %0 : !llvm.ptr -> f32
    %cst_2 = arith.constant 0.000000e+00 : f32
    %9 = arith.cmpf oeq, %8, %cst_2 : f32
    %10 = scf.if %9 -> (f32) {
      scf.yield %cst_2 : f32
    } else {
      %13 = arith.divf %7, %8 : f32
      scf.yield %13 : f32
    }
    %11 = arith.addf %6, %10 : f32
    cf.br ^bb2(%11 : f32)
  ^bb2(%12: f32):  // pred: ^bb1
    return %12 : f32
  }
  func.func public @f32.xkcd_better_sqrt_5(%arg0: !llvm.ptr, %arg1: f32, %arg2: f32, %arg3: f32, %arg4: f32) -> f32 attributes {llvm.emit_c_interface} {
    %c1_i64 = arith.constant 1 : i64
    %0 = llvm.alloca %c1_i64 x f32 : (i64) -> !llvm.ptr
    llvm.store %arg1, %0 : f32, !llvm.ptr
    %c1_i64_0 = arith.constant 1 : i64
    %1 = llvm.alloca %c1_i64_0 x f32 : (i64) -> !llvm.ptr
    llvm.store %arg2, %1 : f32, !llvm.ptr
    %c1_i64_1 = arith.constant 1 : i64
    %2 = llvm.alloca %c1_i64_1 x f32 : (i64) -> !llvm.ptr
    llvm.store %arg3, %2 : f32, !llvm.ptr
    %c1_i64_2 = arith.constant 1 : i64
    %3 = llvm.alloca %c1_i64_2 x f32 : (i64) -> !llvm.ptr
    llvm.store %arg4, %3 : f32, !llvm.ptr
    cf.br ^bb1
  ^bb1:  // pred: ^bb0
    %4 = llvm.load %0 : !llvm.ptr -> f32
    %5 = llvm.load %1 : !llvm.ptr -> f32
    %6 = llvm.load %2 : !llvm.ptr -> f32
    %7 = arith.mulf %5, %6 : f32
    %8 = arith.addf %4, %7 : f32
    %9 = llvm.load %3 : !llvm.ptr -> f32
    %10 = llvm.load %1 : !llvm.ptr -> f32
    %11 = llvm.load %2 : !llvm.ptr -> f32
    %12 = arith.mulf %10, %11 : f32
    %13 = arith.subf %9, %12 : f32
    %cst = arith.constant 0.000000e+00 : f32
    %14 = arith.cmpf oeq, %13, %cst : f32
    %15 = scf.if %14 -> (f32) {
      scf.yield %cst : f32
    } else {
      %17 = arith.divf %8, %13 : f32
      scf.yield %17 : f32
    }
    cf.br ^bb2(%15 : f32)
  ^bb2(%16: f32):  // pred: ^bb1
    return %16 : f32
  }
  func.func public @f64.sqrt(%arg0: !llvm.ptr, %arg1: f64) -> f64 attributes {llvm.emit_c_interface} {
    %c1_i64 = arith.constant 1 : i64
    %0 = llvm.alloca %c1_i64 x f64 : (i64) -> !llvm.ptr
    llvm.store %arg1, %0 : f64, !llvm.ptr
    cf.br ^bb1
  ^bb1:  // pred: ^bb0
    %1 = llvm.load %0 : !llvm.ptr -> f64
    %2 = math.sqrt %1 : f64
    cf.br ^bb2(%2 : f64)
  ^bb2(%3: f64):  // pred: ^bb1
    return %3 : f64
  }
  func.func public @f64.xkcd_sqrt_2(%arg0: !llvm.ptr, %arg1: f64, %arg2: f64, %arg3: f64, %arg4: f64) -> f64 attributes {llvm.emit_c_interface} {
    %c1_i64 = arith.constant 1 : i64
    %0 = llvm.alloca %c1_i64 x f64 : (i64) -> !llvm.ptr
    llvm.store %arg1, %0 : f64, !llvm.ptr
    %c1_i64_0 = arith.constant 1 : i64
    %1 = llvm.alloca %c1_i64_0 x f64 : (i64) -> !llvm.ptr
    llvm.store %arg2, %1 : f64, !llvm.ptr
    %c1_i64_1 = arith.constant 1 : i64
    %2 = llvm.alloca %c1_i64_1 x f64 : (i64) -> !llvm.ptr
    llvm.store %arg3, %2 : f64, !llvm.ptr
    %c1_i64_2 = arith.constant 1 : i64
    %3 = llvm.alloca %c1_i64_2 x f64 : (i64) -> !llvm.ptr
    llvm.store %arg4, %3 : f64, !llvm.ptr
    cf.br ^bb1
  ^bb1:  // pred: ^bb0
    %4 = llvm.load %0 : !llvm.ptr -> f64
    %5 = llvm.load %1 : !llvm.ptr -> f64
    %cst = arith.constant 0.000000e+00 : f64
    %6 = arith.cmpf oeq, %5, %cst : f64
    %7 = scf.if %6 -> (f64) {
      scf.yield %cst : f64
    } else {
      %16 = arith.divf %4, %5 : f64
      scf.yield %16 : f64
    }
    %8 = llvm.load %2 : !llvm.ptr -> f64
    %9 = llvm.load %3 : !llvm.ptr -> f64
    %10 = llvm.load %2 : !llvm.ptr -> f64
    %11 = arith.subf %9, %10 : f64
    %cst_3 = arith.constant 0.000000e+00 : f64
    %12 = arith.cmpf oeq, %11, %cst_3 : f64
    %13 = scf.if %12 -> (f64) {
      scf.yield %cst_3 : f64
    } else {
      %16 = arith.divf %8, %11 : f64
      scf.yield %16 : f64
    }
    %14 = arith.addf %7, %13 : f64
    cf.br ^bb2(%14 : f64)
  ^bb2(%15: f64):  // pred: ^bb1
    return %15 : f64
  }
  func.func public @f64.xkcd_sqrt_3(%arg0: !llvm.ptr, %arg1: f64, %arg2: f64, %arg3: f64) -> f64 attributes {llvm.emit_c_interface} {
    %c1_i64 = arith.constant 1 : i64
    %0 = llvm.alloca %c1_i64 x f64 : (i64) -> !llvm.ptr
    llvm.store %arg1, %0 : f64, !llvm.ptr
    %c1_i64_0 = arith.constant 1 : i64
    %1 = llvm.alloca %c1_i64_0 x f64 : (i64) -> !llvm.ptr
    llvm.store %arg2, %1 : f64, !llvm.ptr
    %c1_i64_1 = arith.constant 1 : i64
    %2 = llvm.alloca %c1_i64_1 x f64 : (i64) -> !llvm.ptr
    llvm.store %arg3, %2 : f64, !llvm.ptr
    cf.br ^bb1
  ^bb1:  // pred: ^bb0
    %3 = llvm.load %0 : !llvm.ptr -> f64
    %4 = llvm.load %1 : !llvm.ptr -> f64
    %5 = arith.mulf %3, %4 : f64
    %6 = llvm.load %2 : !llvm.ptr -> f64
    %cst = arith.constant 0.000000e+00 : f64
    %7 = arith.cmpf oeq, %6, %cst : f64
    %8 = scf.if %7 -> (f64) {
      scf.yield %cst : f64
    } else {
      %10 = arith.divf %5, %6 : f64
      scf.yield %10 : f64
    }
    cf.br ^bb2(%8 : f64)
  ^bb2(%9: f64):  // pred: ^bb1
    return %9 : f64
  }
  func.func public @f64.xkcd_sqrt_5(%arg0: !llvm.ptr, %arg1: f64, %arg2: f64, %arg3: f64) -> f64 attributes {llvm.emit_c_interface} {
    %c1_i64 = arith.constant 1 : i64
    %0 = llvm.alloca %c1_i64 x f64 : (i64) -> !llvm.ptr
    llvm.store %arg1, %0 : f64, !llvm.ptr
    %c1_i64_0 = arith.constant 1 : i64
    %1 = llvm.alloca %c1_i64_0 x f64 : (i64) -> !llvm.ptr
    llvm.store %arg2, %1 : f64, !llvm.ptr
    %c1_i64_1 = arith.constant 1 : i64
    %2 = llvm.alloca %c1_i64_1 x f64 : (i64) -> !llvm.ptr
    llvm.store %arg3, %2 : f64, !llvm.ptr
    cf.br ^bb1
  ^bb1:  // pred: ^bb0
    %3 = llvm.load %0 : !llvm.ptr -> f64
    %4 = llvm.load %1 : !llvm.ptr -> f64
    %cst = arith.constant 0.000000e+00 : f64
    %5 = arith.cmpf oeq, %4, %cst : f64
    %6 = scf.if %5 -> (f64) {
      scf.yield %cst : f64
    } else {
      %13 = arith.divf %3, %4 : f64
      scf.yield %13 : f64
    }
    %7 = llvm.load %2 : !llvm.ptr -> f64
    %8 = llvm.load %0 : !llvm.ptr -> f64
    %cst_2 = arith.constant 0.000000e+00 : f64
    %9 = arith.cmpf oeq, %8, %cst_2 : f64
    %10 = scf.if %9 -> (f64) {
      scf.yield %cst_2 : f64
    } else {
      %13 = arith.divf %7, %8 : f64
      scf.yield %13 : f64
    }
    %11 = arith.addf %6, %10 : f64
    cf.br ^bb2(%11 : f64)
  ^bb2(%12: f64):  // pred: ^bb1
    return %12 : f64
  }
  func.func public @f64.xkcd_better_sqrt_5(%arg0: !llvm.ptr, %arg1: f64, %arg2: f64, %arg3: f64, %arg4: f64) -> f64 attributes {llvm.emit_c_interface} {
    %c1_i64 = arith.constant 1 : i64
    %0 = llvm.alloca %c1_i64 x f64 : (i64) -> !llvm.ptr
    llvm.store %arg1, %0 : f64, !llvm.ptr
    %c1_i64_0 = arith.constant 1 : i64
    %1 = llvm.alloca %c1_i64_0 x f64 : (i64) -> !llvm.ptr
    llvm.store %arg2, %1 : f64, !llvm.ptr
    %c1_i64_1 = arith.constant 1 : i64
    %2 = llvm.alloca %c1_i64_1 x f64 : (i64) -> !llvm.ptr
    llvm.store %arg3, %2 : f64, !llvm.ptr
    %c1_i64_2 = arith.constant 1 : i64
    %3 = llvm.alloca %c1_i64_2 x f64 : (i64) -> !llvm.ptr
    llvm.store %arg4, %3 : f64, !llvm.ptr
    cf.br ^bb1
  ^bb1:  // pred: ^bb0
    %4 = llvm.load %0 : !llvm.ptr -> f64
    %5 = llvm.load %1 : !llvm.ptr -> f64
    %6 = llvm.load %2 : !llvm.ptr -> f64
    %7 = arith.mulf %5, %6 : f64
    %8 = arith.addf %4, %7 : f64
    %9 = llvm.load %3 : !llvm.ptr -> f64
    %10 = llvm.load %1 : !llvm.ptr -> f64
    %11 = llvm.load %2 : !llvm.ptr -> f64
    %12 = arith.mulf %10, %11 : f64
    %13 = arith.subf %9, %12 : f64
    %cst = arith.constant 0.000000e+00 : f64
    %14 = arith.cmpf oeq, %13, %cst : f64
    %15 = scf.if %14 -> (f64) {
      scf.yield %cst : f64
    } else {
      %17 = arith.divf %8, %13 : f64
      scf.yield %17 : f64
    }
    cf.br ^bb2(%15 : f64)
  ^bb2(%16: f64):  // pred: ^bb1
    return %16 : f64
  }
  func.func public @f32.compute_radix(%arg0: !llvm.ptr, %arg1: f32, %arg2: f32) -> f32 attributes {llvm.emit_c_interface} {
    %c1_i64 = arith.constant 1 : i64
    %0 = llvm.alloca %c1_i64 x f32 : (i64) -> !llvm.ptr
    llvm.store %arg1, %0 : f32, !llvm.ptr
    %c1_i64_0 = arith.constant 1 : i64
    %1 = llvm.alloca %c1_i64_0 x f32 : (i64) -> !llvm.ptr
    llvm.store %arg2, %1 : f32, !llvm.ptr
    cf.br ^bb1
  ^bb1:  // pred: ^bb0
    cf.br ^bb4
  ^bb2(%2: f32):  // pred: ^bb6
    return %2 : f32
  ^bb3:  // pred: ^bb5
    cf.br ^bb7
  ^bb4:  // 2 preds: ^bb1, ^bb4
    %3 = llvm.load %0 : !llvm.ptr -> f32
    %4 = llvm.load %0 : !llvm.ptr -> f32
    %5 = arith.addf %3, %4 : f32
    llvm.store %5, %0 : f32, !llvm.ptr
    %c1065353216_i32 = arith.constant 1065353216 : i32
    %6 = arith.bitcast %c1065353216_i32 : i32 to f32
    %7 = arith.addf %5, %6 : f32
    %8 = llvm.load %0 : !llvm.ptr -> f32
    %9 = arith.subf %7, %8 : f32
    %c-1082130432_i32 = arith.constant -1082130432 : i32
    %10 = arith.bitcast %c-1082130432_i32 : i32 to f32
    %11 = arith.addf %9, %10 : f32
    %c0_i32 = arith.constant 0 : i32
    %12 = arith.bitcast %c0_i32 : i32 to f32
    %13 = arith.cmpf oeq, %11, %12 : f32
    %14 = arith.extui %13 : i1 to i32
    %c0_i32_1 = arith.constant 0 : i32
    %15 = arith.cmpi ne, %14, %c0_i32_1 : i32
    cf.cond_br %15, ^bb4, ^bb5
  ^bb5:  // pred: ^bb4
    cf.br ^bb3
  ^bb6:  // pred: ^bb8
    %16 = llvm.load %1 : !llvm.ptr -> f32
    cf.br ^bb2(%16 : f32)
  ^bb7:  // 2 preds: ^bb3, ^bb7
    %17 = llvm.load %0 : !llvm.ptr -> f32
    %18 = llvm.load %1 : !llvm.ptr -> f32
    %c1065353216_i32_2 = arith.constant 1065353216 : i32
    %19 = arith.bitcast %c1065353216_i32_2 : i32 to f32
    %20 = arith.addf %18, %19 : f32
    llvm.store %20, %1 : f32, !llvm.ptr
    %21 = arith.addf %17, %20 : f32
    %22 = llvm.load %0 : !llvm.ptr -> f32
    %23 = arith.subf %21, %22 : f32
    %24 = llvm.load %1 : !llvm.ptr -> f32
    %25 = arith.subf %23, %24 : f32
    %c0_i32_3 = arith.constant 0 : i32
    %26 = arith.bitcast %c0_i32_3 : i32 to f32
    %27 = arith.cmpf oeq, %25, %26 : f32
    %28 = arith.extui %27 : i1 to i32
    %c0_i32_4 = arith.constant 0 : i32
    %29 = arith.cmpi eq, %28, %c0_i32_4 : i32
    %30 = arith.extui %29 : i1 to i32
    %c0_i32_5 = arith.constant 0 : i32
    %31 = arith.cmpi ne, %30, %c0_i32_5 : i32
    cf.cond_br %31, ^bb7, ^bb8
  ^bb8:  // pred: ^bb7
    cf.br ^bb6
  }
  func.func public @f64.compute_radix(%arg0: !llvm.ptr, %arg1: f64, %arg2: f64) -> f64 attributes {llvm.emit_c_interface} {
    %c1_i64 = arith.constant 1 : i64
    %0 = llvm.alloca %c1_i64 x f64 : (i64) -> !llvm.ptr
    llvm.store %arg1, %0 : f64, !llvm.ptr
    %c1_i64_0 = arith.constant 1 : i64
    %1 = llvm.alloca %c1_i64_0 x f64 : (i64) -> !llvm.ptr
    llvm.store %arg2, %1 : f64, !llvm.ptr
    cf.br ^bb1
  ^bb1:  // pred: ^bb0
    cf.br ^bb4
  ^bb2(%2: f64):  // pred: ^bb6
    return %2 : f64
  ^bb3:  // pred: ^bb5
    cf.br ^bb7
  ^bb4:  // 2 preds: ^bb1, ^bb4
    %3 = llvm.load %0 : !llvm.ptr -> f64
    %4 = llvm.load %0 : !llvm.ptr -> f64
    %5 = arith.addf %3, %4 : f64
    llvm.store %5, %0 : f64, !llvm.ptr
    %c4607182418800017408_i64 = arith.constant 4607182418800017408 : i64
    %6 = arith.bitcast %c4607182418800017408_i64 : i64 to f64
    %7 = arith.addf %5, %6 : f64
    %8 = llvm.load %0 : !llvm.ptr -> f64
    %9 = arith.subf %7, %8 : f64
    %c-4616189618054758400_i64 = arith.constant -4616189618054758400 : i64
    %10 = arith.bitcast %c-4616189618054758400_i64 : i64 to f64
    %11 = arith.addf %9, %10 : f64
    %c0_i64 = arith.constant 0 : i64
    %12 = arith.bitcast %c0_i64 : i64 to f64
    %13 = arith.cmpf oeq, %11, %12 : f64
    %14 = arith.extui %13 : i1 to i32
    %c0_i32 = arith.constant 0 : i32
    %15 = arith.cmpi ne, %14, %c0_i32 : i32
    cf.cond_br %15, ^bb4, ^bb5
  ^bb5:  // pred: ^bb4
    cf.br ^bb3
  ^bb6:  // pred: ^bb8
    %16 = llvm.load %1 : !llvm.ptr -> f64
    cf.br ^bb2(%16 : f64)
  ^bb7:  // 2 preds: ^bb3, ^bb7
    %17 = llvm.load %0 : !llvm.ptr -> f64
    %18 = llvm.load %1 : !llvm.ptr -> f64
    %c4607182418800017408_i64_1 = arith.constant 4607182418800017408 : i64
    %19 = arith.bitcast %c4607182418800017408_i64_1 : i64 to f64
    %20 = arith.addf %18, %19 : f64
    llvm.store %20, %1 : f64, !llvm.ptr
    %21 = arith.addf %17, %20 : f64
    %22 = llvm.load %0 : !llvm.ptr -> f64
    %23 = arith.subf %21, %22 : f64
    %24 = llvm.load %1 : !llvm.ptr -> f64
    %25 = arith.subf %23, %24 : f64
    %c0_i64_2 = arith.constant 0 : i64
    %26 = arith.bitcast %c0_i64_2 : i64 to f64
    %27 = arith.cmpf oeq, %25, %26 : f64
    %28 = arith.extui %27 : i1 to i32
    %c0_i32_3 = arith.constant 0 : i32
    %29 = arith.cmpi eq, %28, %c0_i32_3 : i32
    %30 = arith.extui %29 : i1 to i32
    %c0_i32_4 = arith.constant 0 : i32
    %31 = arith.cmpi ne, %30, %c0_i32_4 : i32
    cf.cond_br %31, ^bb7, ^bb8
  ^bb8:  // pred: ^bb7
    cf.br ^bb6
  }
  func.func public @f32.no_fold_sub1_mul_add(%arg0: !llvm.ptr, %arg1: f32, %arg2: f32) -> f32 attributes {llvm.emit_c_interface} {
    %c1_i64 = arith.constant 1 : i64
    %0 = llvm.alloca %c1_i64 x f32 : (i64) -> !llvm.ptr
    llvm.store %arg1, %0 : f32, !llvm.ptr
    %c1_i64_0 = arith.constant 1 : i64
    %1 = llvm.alloca %c1_i64_0 x f32 : (i64) -> !llvm.ptr
    llvm.store %arg2, %1 : f32, !llvm.ptr
    cf.br ^bb1
  ^bb1:  // pred: ^bb0
    %2 = llvm.load %0 : !llvm.ptr -> f32
    %c1065353216_i32 = arith.constant 1065353216 : i32
    %3 = arith.bitcast %c1065353216_i32 : i32 to f32
    %4 = arith.subf %2, %3 : f32
    %5 = llvm.load %1 : !llvm.ptr -> f32
    %6 = arith.mulf %4, %5 : f32
    %7 = llvm.load %1 : !llvm.ptr -> f32
    %8 = arith.addf %6, %7 : f32
    cf.br ^bb2(%8 : f32)
  ^bb2(%9: f32):  // pred: ^bb1
    return %9 : f32
  }
  func.func public @f64.no_fold_sub1_mul_add(%arg0: !llvm.ptr, %arg1: f64, %arg2: f64) -> f64 attributes {llvm.emit_c_interface} {
    %c1_i64 = arith.constant 1 : i64
    %0 = llvm.alloca %c1_i64 x f64 : (i64) -> !llvm.ptr
    llvm.store %arg1, %0 : f64, !llvm.ptr
    %c1_i64_0 = arith.constant 1 : i64
    %1 = llvm.alloca %c1_i64_0 x f64 : (i64) -> !llvm.ptr
    llvm.store %arg2, %1 : f64, !llvm.ptr
    cf.br ^bb1
  ^bb1:  // pred: ^bb0
    %2 = llvm.load %0 : !llvm.ptr -> f64
    %c4607182418800017408_i64 = arith.constant 4607182418800017408 : i64
    %3 = arith.bitcast %c4607182418800017408_i64 : i64 to f64
    %4 = arith.subf %2, %3 : f64
    %5 = llvm.load %1 : !llvm.ptr -> f64
    %6 = arith.mulf %4, %5 : f64
    %7 = llvm.load %1 : !llvm.ptr -> f64
    %8 = arith.addf %6, %7 : f64
    cf.br ^bb2(%8 : f64)
  ^bb2(%9: f64):  // pred: ^bb1
    return %9 : f64
  }
  func.func public @f32.no_fold_add_le_monotonicity(%arg0: !llvm.ptr, %arg1: f32, %arg2: f32, %arg3: f32) -> i32 attributes {llvm.emit_c_interface} {
    %c1_i64 = arith.constant 1 : i64
    %0 = llvm.alloca %c1_i64 x f32 : (i64) -> !llvm.ptr
    llvm.store %arg1, %0 : f32, !llvm.ptr
    %c1_i64_0 = arith.constant 1 : i64
    %1 = llvm.alloca %c1_i64_0 x f32 : (i64) -> !llvm.ptr
    llvm.store %arg2, %1 : f32, !llvm.ptr
    %c1_i64_1 = arith.constant 1 : i64
    %2 = llvm.alloca %c1_i64_1 x f32 : (i64) -> !llvm.ptr
    llvm.store %arg3, %2 : f32, !llvm.ptr
    cf.br ^bb1
  ^bb1:  // pred: ^bb0
    %3 = llvm.load %0 : !llvm.ptr -> f32
    %4 = llvm.load %2 : !llvm.ptr -> f32
    %5 = arith.addf %3, %4 : f32
    %6 = llvm.load %1 : !llvm.ptr -> f32
    %7 = llvm.load %2 : !llvm.ptr -> f32
    %8 = arith.addf %6, %7 : f32
    %9 = arith.cmpf ole, %5, %8 : f32
    %10 = arith.extui %9 : i1 to i32
    cf.br ^bb2(%10 : i32)
  ^bb2(%11: i32):  // pred: ^bb1
    return %11 : i32
  }
  func.func public @f32.no_fold_add_ge_monotonicity(%arg0: !llvm.ptr, %arg1: f32, %arg2: f32, %arg3: f32) -> i32 attributes {llvm.emit_c_interface} {
    %c1_i64 = arith.constant 1 : i64
    %0 = llvm.alloca %c1_i64 x f32 : (i64) -> !llvm.ptr
    llvm.store %arg1, %0 : f32, !llvm.ptr
    %c1_i64_0 = arith.constant 1 : i64
    %1 = llvm.alloca %c1_i64_0 x f32 : (i64) -> !llvm.ptr
    llvm.store %arg2, %1 : f32, !llvm.ptr
    %c1_i64_1 = arith.constant 1 : i64
    %2 = llvm.alloca %c1_i64_1 x f32 : (i64) -> !llvm.ptr
    llvm.store %arg3, %2 : f32, !llvm.ptr
    cf.br ^bb1
  ^bb1:  // pred: ^bb0
    %3 = llvm.load %0 : !llvm.ptr -> f32
    %4 = llvm.load %2 : !llvm.ptr -> f32
    %5 = arith.addf %3, %4 : f32
    %6 = llvm.load %1 : !llvm.ptr -> f32
    %7 = llvm.load %2 : !llvm.ptr -> f32
    %8 = arith.addf %6, %7 : f32
    %9 = arith.cmpf oge, %5, %8 : f32
    %10 = arith.extui %9 : i1 to i32
    cf.br ^bb2(%10 : i32)
  ^bb2(%11: i32):  // pred: ^bb1
    return %11 : i32
  }
  func.func public @f64.no_fold_add_le_monotonicity(%arg0: !llvm.ptr, %arg1: f64, %arg2: f64, %arg3: f64) -> i32 attributes {llvm.emit_c_interface} {
    %c1_i64 = arith.constant 1 : i64
    %0 = llvm.alloca %c1_i64 x f64 : (i64) -> !llvm.ptr
    llvm.store %arg1, %0 : f64, !llvm.ptr
    %c1_i64_0 = arith.constant 1 : i64
    %1 = llvm.alloca %c1_i64_0 x f64 : (i64) -> !llvm.ptr
    llvm.store %arg2, %1 : f64, !llvm.ptr
    %c1_i64_1 = arith.constant 1 : i64
    %2 = llvm.alloca %c1_i64_1 x f64 : (i64) -> !llvm.ptr
    llvm.store %arg3, %2 : f64, !llvm.ptr
    cf.br ^bb1
  ^bb1:  // pred: ^bb0
    %3 = llvm.load %0 : !llvm.ptr -> f64
    %4 = llvm.load %2 : !llvm.ptr -> f64
    %5 = arith.addf %3, %4 : f64
    %6 = llvm.load %1 : !llvm.ptr -> f64
    %7 = llvm.load %2 : !llvm.ptr -> f64
    %8 = arith.addf %6, %7 : f64
    %9 = arith.cmpf ole, %5, %8 : f64
    %10 = arith.extui %9 : i1 to i32
    cf.br ^bb2(%10 : i32)
  ^bb2(%11: i32):  // pred: ^bb1
    return %11 : i32
  }
  func.func public @f64.no_fold_add_ge_monotonicity(%arg0: !llvm.ptr, %arg1: f64, %arg2: f64, %arg3: f64) -> i32 attributes {llvm.emit_c_interface} {
    %c1_i64 = arith.constant 1 : i64
    %0 = llvm.alloca %c1_i64 x f64 : (i64) -> !llvm.ptr
    llvm.store %arg1, %0 : f64, !llvm.ptr
    %c1_i64_0 = arith.constant 1 : i64
    %1 = llvm.alloca %c1_i64_0 x f64 : (i64) -> !llvm.ptr
    llvm.store %arg2, %1 : f64, !llvm.ptr
    %c1_i64_1 = arith.constant 1 : i64
    %2 = llvm.alloca %c1_i64_1 x f64 : (i64) -> !llvm.ptr
    llvm.store %arg3, %2 : f64, !llvm.ptr
    cf.br ^bb1
  ^bb1:  // pred: ^bb0
    %3 = llvm.load %0 : !llvm.ptr -> f64
    %4 = llvm.load %2 : !llvm.ptr -> f64
    %5 = arith.addf %3, %4 : f64
    %6 = llvm.load %1 : !llvm.ptr -> f64
    %7 = llvm.load %2 : !llvm.ptr -> f64
    %8 = arith.addf %6, %7 : f64
    %9 = arith.cmpf oge, %5, %8 : f64
    %10 = arith.extui %9 : i1 to i32
    cf.br ^bb2(%10 : i32)
  ^bb2(%11: i32):  // pred: ^bb1
    return %11 : i32
  }
  func.func public @f32.not_lt(%arg0: !llvm.ptr, %arg1: f32, %arg2: f32) -> i32 attributes {llvm.emit_c_interface} {
    %c1_i64 = arith.constant 1 : i64
    %0 = llvm.alloca %c1_i64 x f32 : (i64) -> !llvm.ptr
    llvm.store %arg1, %0 : f32, !llvm.ptr
    %c1_i64_0 = arith.constant 1 : i64
    %1 = llvm.alloca %c1_i64_0 x f32 : (i64) -> !llvm.ptr
    llvm.store %arg2, %1 : f32, !llvm.ptr
    cf.br ^bb1
  ^bb1:  // pred: ^bb0
    %2 = llvm.load %0 : !llvm.ptr -> f32
    %3 = llvm.load %1 : !llvm.ptr -> f32
    %4 = arith.cmpf olt, %2, %3 : f32
    %5 = arith.extui %4 : i1 to i32
    %c0_i32 = arith.constant 0 : i32
    %6 = arith.cmpi eq, %5, %c0_i32 : i32
    %7 = arith.extui %6 : i1 to i32
    cf.br ^bb2(%7 : i32)
  ^bb2(%8: i32):  // pred: ^bb1
    return %8 : i32
  }
  func.func public @f32.not_le(%arg0: !llvm.ptr, %arg1: f32, %arg2: f32) -> i32 attributes {llvm.emit_c_interface} {
    %c1_i64 = arith.constant 1 : i64
    %0 = llvm.alloca %c1_i64 x f32 : (i64) -> !llvm.ptr
    llvm.store %arg1, %0 : f32, !llvm.ptr
    %c1_i64_0 = arith.constant 1 : i64
    %1 = llvm.alloca %c1_i64_0 x f32 : (i64) -> !llvm.ptr
    llvm.store %arg2, %1 : f32, !llvm.ptr
    cf.br ^bb1
  ^bb1:  // pred: ^bb0
    %2 = llvm.load %0 : !llvm.ptr -> f32
    %3 = llvm.load %1 : !llvm.ptr -> f32
    %4 = arith.cmpf ole, %2, %3 : f32
    %5 = arith.extui %4 : i1 to i32
    %c0_i32 = arith.constant 0 : i32
    %6 = arith.cmpi eq, %5, %c0_i32 : i32
    %7 = arith.extui %6 : i1 to i32
    cf.br ^bb2(%7 : i32)
  ^bb2(%8: i32):  // pred: ^bb1
    return %8 : i32
  }
  func.func public @f32.not_gt(%arg0: !llvm.ptr, %arg1: f32, %arg2: f32) -> i32 attributes {llvm.emit_c_interface} {
    %c1_i64 = arith.constant 1 : i64
    %0 = llvm.alloca %c1_i64 x f32 : (i64) -> !llvm.ptr
    llvm.store %arg1, %0 : f32, !llvm.ptr
    %c1_i64_0 = arith.constant 1 : i64
    %1 = llvm.alloca %c1_i64_0 x f32 : (i64) -> !llvm.ptr
    llvm.store %arg2, %1 : f32, !llvm.ptr
    cf.br ^bb1
  ^bb1:  // pred: ^bb0
    %2 = llvm.load %0 : !llvm.ptr -> f32
    %3 = llvm.load %1 : !llvm.ptr -> f32
    %4 = arith.cmpf ogt, %2, %3 : f32
    %5 = arith.extui %4 : i1 to i32
    %c0_i32 = arith.constant 0 : i32
    %6 = arith.cmpi eq, %5, %c0_i32 : i32
    %7 = arith.extui %6 : i1 to i32
    cf.br ^bb2(%7 : i32)
  ^bb2(%8: i32):  // pred: ^bb1
    return %8 : i32
  }
  func.func public @f32.not_ge(%arg0: !llvm.ptr, %arg1: f32, %arg2: f32) -> i32 attributes {llvm.emit_c_interface} {
    %c1_i64 = arith.constant 1 : i64
    %0 = llvm.alloca %c1_i64 x f32 : (i64) -> !llvm.ptr
    llvm.store %arg1, %0 : f32, !llvm.ptr
    %c1_i64_0 = arith.constant 1 : i64
    %1 = llvm.alloca %c1_i64_0 x f32 : (i64) -> !llvm.ptr
    llvm.store %arg2, %1 : f32, !llvm.ptr
    cf.br ^bb1
  ^bb1:  // pred: ^bb0
    %2 = llvm.load %0 : !llvm.ptr -> f32
    %3 = llvm.load %1 : !llvm.ptr -> f32
    %4 = arith.cmpf oge, %2, %3 : f32
    %5 = arith.extui %4 : i1 to i32
    %c0_i32 = arith.constant 0 : i32
    %6 = arith.cmpi eq, %5, %c0_i32 : i32
    %7 = arith.extui %6 : i1 to i32
    cf.br ^bb2(%7 : i32)
  ^bb2(%8: i32):  // pred: ^bb1
    return %8 : i32
  }
  func.func public @f64.not_lt(%arg0: !llvm.ptr, %arg1: f64, %arg2: f64) -> i32 attributes {llvm.emit_c_interface} {
    %c1_i64 = arith.constant 1 : i64
    %0 = llvm.alloca %c1_i64 x f64 : (i64) -> !llvm.ptr
    llvm.store %arg1, %0 : f64, !llvm.ptr
    %c1_i64_0 = arith.constant 1 : i64
    %1 = llvm.alloca %c1_i64_0 x f64 : (i64) -> !llvm.ptr
    llvm.store %arg2, %1 : f64, !llvm.ptr
    cf.br ^bb1
  ^bb1:  // pred: ^bb0
    %2 = llvm.load %0 : !llvm.ptr -> f64
    %3 = llvm.load %1 : !llvm.ptr -> f64
    %4 = arith.cmpf olt, %2, %3 : f64
    %5 = arith.extui %4 : i1 to i32
    %c0_i32 = arith.constant 0 : i32
    %6 = arith.cmpi eq, %5, %c0_i32 : i32
    %7 = arith.extui %6 : i1 to i32
    cf.br ^bb2(%7 : i32)
  ^bb2(%8: i32):  // pred: ^bb1
    return %8 : i32
  }
  func.func public @f64.not_le(%arg0: !llvm.ptr, %arg1: f64, %arg2: f64) -> i32 attributes {llvm.emit_c_interface} {
    %c1_i64 = arith.constant 1 : i64
    %0 = llvm.alloca %c1_i64 x f64 : (i64) -> !llvm.ptr
    llvm.store %arg1, %0 : f64, !llvm.ptr
    %c1_i64_0 = arith.constant 1 : i64
    %1 = llvm.alloca %c1_i64_0 x f64 : (i64) -> !llvm.ptr
    llvm.store %arg2, %1 : f64, !llvm.ptr
    cf.br ^bb1
  ^bb1:  // pred: ^bb0
    %2 = llvm.load %0 : !llvm.ptr -> f64
    %3 = llvm.load %1 : !llvm.ptr -> f64
    %4 = arith.cmpf ole, %2, %3 : f64
    %5 = arith.extui %4 : i1 to i32
    %c0_i32 = arith.constant 0 : i32
    %6 = arith.cmpi eq, %5, %c0_i32 : i32
    %7 = arith.extui %6 : i1 to i32
    cf.br ^bb2(%7 : i32)
  ^bb2(%8: i32):  // pred: ^bb1
    return %8 : i32
  }
  func.func public @f64.not_gt(%arg0: !llvm.ptr, %arg1: f64, %arg2: f64) -> i32 attributes {llvm.emit_c_interface} {
    %c1_i64 = arith.constant 1 : i64
    %0 = llvm.alloca %c1_i64 x f64 : (i64) -> !llvm.ptr
    llvm.store %arg1, %0 : f64, !llvm.ptr
    %c1_i64_0 = arith.constant 1 : i64
    %1 = llvm.alloca %c1_i64_0 x f64 : (i64) -> !llvm.ptr
    llvm.store %arg2, %1 : f64, !llvm.ptr
    cf.br ^bb1
  ^bb1:  // pred: ^bb0
    %2 = llvm.load %0 : !llvm.ptr -> f64
    %3 = llvm.load %1 : !llvm.ptr -> f64
    %4 = arith.cmpf ogt, %2, %3 : f64
    %5 = arith.extui %4 : i1 to i32
    %c0_i32 = arith.constant 0 : i32
    %6 = arith.cmpi eq, %5, %c0_i32 : i32
    %7 = arith.extui %6 : i1 to i32
    cf.br ^bb2(%7 : i32)
  ^bb2(%8: i32):  // pred: ^bb1
    return %8 : i32
  }
  func.func public @f64.not_ge(%arg0: !llvm.ptr, %arg1: f64, %arg2: f64) -> i32 attributes {llvm.emit_c_interface} {
    %c1_i64 = arith.constant 1 : i64
    %0 = llvm.alloca %c1_i64 x f64 : (i64) -> !llvm.ptr
    llvm.store %arg1, %0 : f64, !llvm.ptr
    %c1_i64_0 = arith.constant 1 : i64
    %1 = llvm.alloca %c1_i64_0 x f64 : (i64) -> !llvm.ptr
    llvm.store %arg2, %1 : f64, !llvm.ptr
    cf.br ^bb1
  ^bb1:  // pred: ^bb0
    %2 = llvm.load %0 : !llvm.ptr -> f64
    %3 = llvm.load %1 : !llvm.ptr -> f64
    %4 = arith.cmpf oge, %2, %3 : f64
    %5 = arith.extui %4 : i1 to i32
    %c0_i32 = arith.constant 0 : i32
    %6 = arith.cmpi eq, %5, %c0_i32 : i32
    %7 = arith.extui %6 : i1 to i32
    cf.br ^bb2(%7 : i32)
  ^bb2(%8: i32):  // pred: ^bb1
    return %8 : i32
  }
  func.func @f211(%arg0: !llvm.ptr) -> f32 {
    cf.br ^bb1
  ^bb1:  // pred: ^bb0
    %c1065353216_i32 = arith.constant 1065353216 : i32
    %0 = arith.bitcast %c1065353216_i32 : i32 to f32
    %c1077936128_i32 = arith.constant 1077936128 : i32
    %1 = arith.bitcast %c1077936128_i32 : i32 to f32
    %c1082130432_i32 = arith.constant 1082130432 : i32
    %2 = arith.bitcast %c1082130432_i32 : i32 to f32
    %c1077936128_i32_0 = arith.constant 1077936128 : i32
    %3 = arith.bitcast %c1077936128_i32_0 : i32 to f32
    %cst = arith.constant 0.000000e+00 : f32
    %4 = arith.cmpf oeq, %3, %cst : f32
    %5 = scf.if %4 -> (f32) {
      scf.yield %cst : f32
    } else {
      %11 = arith.divf %2, %3 : f32
      scf.yield %11 : f32
    }
    %c1065353216_i32_1 = arith.constant 1065353216 : i32
    %6 = arith.bitcast %c1065353216_i32_1 : i32 to f32
    %7 = arith.subf %5, %6 : f32
    %8 = arith.mulf %1, %7 : f32
    %9 = arith.subf %0, %8 : f32
    cf.br ^bb2(%9 : f32)
  ^bb2(%10: f32):  // pred: ^bb1
    return %10 : f32
  }
  func.func @f212(%arg0: !llvm.ptr) -> f64 {
    cf.br ^bb1
  ^bb1:  // pred: ^bb0
    %c4607182418800017408_i64 = arith.constant 4607182418800017408 : i64
    %0 = arith.bitcast %c4607182418800017408_i64 : i64 to f64
    %c4613937818241073152_i64 = arith.constant 4613937818241073152 : i64
    %1 = arith.bitcast %c4613937818241073152_i64 : i64 to f64
    %c4616189618054758400_i64 = arith.constant 4616189618054758400 : i64
    %2 = arith.bitcast %c4616189618054758400_i64 : i64 to f64
    %c4613937818241073152_i64_0 = arith.constant 4613937818241073152 : i64
    %3 = arith.bitcast %c4613937818241073152_i64_0 : i64 to f64
    %cst = arith.constant 0.000000e+00 : f64
    %4 = arith.cmpf oeq, %3, %cst : f64
    %5 = scf.if %4 -> (f64) {
      scf.yield %cst : f64
    } else {
      %11 = arith.divf %2, %3 : f64
      scf.yield %11 : f64
    }
    %c4607182418800017408_i64_1 = arith.constant 4607182418800017408 : i64
    %6 = arith.bitcast %c4607182418800017408_i64_1 : i64 to f64
    %7 = arith.subf %5, %6 : f64
    %8 = arith.mulf %1, %7 : f64
    %9 = arith.subf %0, %8 : f64
    cf.br ^bb2(%9 : f64)
  ^bb2(%10: f64):  // pred: ^bb1
    return %10 : f64
  }
  func.func public @f32.epsilon(%arg0: !llvm.ptr) -> f32 attributes {llvm.emit_c_interface} {
    %cst = arith.constant 0.000000e+00 : f32
    %c1_i64 = arith.constant 1 : i64
    %0 = llvm.alloca %c1_i64 x f32 : (i64) -> !llvm.ptr
    llvm.store %cst, %0 : f32, !llvm.ptr
    %c1_i64_0 = arith.constant 1 : i64
    %1 = llvm.alloca %c1_i64_0 x f32 : (i64) -> !llvm.ptr
    llvm.store %cst, %1 : f32, !llvm.ptr
    cf.br ^bb1
  ^bb1:  // pred: ^bb0
    %c1065353216_i32 = arith.constant 1065353216 : i32
    %2 = arith.bitcast %c1065353216_i32 : i32 to f32
    llvm.store %2, %0 : f32, !llvm.ptr
    cf.br ^bb4
  ^bb2(%3: f32):  // pred: ^bb3
    return %3 : f32
  ^bb3:  // pred: ^bb5
    %4 = llvm.load %1 : !llvm.ptr -> f32
    cf.br ^bb2(%4 : f32)
  ^bb4:  // 2 preds: ^bb1, ^bb4
    %5 = llvm.load %0 : !llvm.ptr -> f32
    llvm.store %5, %1 : f32, !llvm.ptr
    %c1056964608_i32 = arith.constant 1056964608 : i32
    %6 = arith.bitcast %c1056964608_i32 : i32 to f32
    %7 = arith.mulf %5, %6 : f32
    llvm.store %7, %0 : f32, !llvm.ptr
    %c1065353216_i32_1 = arith.constant 1065353216 : i32
    %8 = arith.bitcast %c1065353216_i32_1 : i32 to f32
    %9 = arith.addf %7, %8 : f32
    %c1065353216_i32_2 = arith.constant 1065353216 : i32
    %10 = arith.bitcast %c1065353216_i32_2 : i32 to f32
    %11 = arith.cmpf ogt, %9, %10 : f32
    %12 = arith.extui %11 : i1 to i32
    %c0_i32 = arith.constant 0 : i32
    %13 = arith.cmpi ne, %12, %c0_i32 : i32
    cf.cond_br %13, ^bb4, ^bb5
  ^bb5:  // pred: ^bb4
    cf.br ^bb3
  }
  func.func public @f64.epsilon(%arg0: !llvm.ptr) -> f64 attributes {llvm.emit_c_interface} {
    %cst = arith.constant 0.000000e+00 : f64
    %c1_i64 = arith.constant 1 : i64
    %0 = llvm.alloca %c1_i64 x f64 : (i64) -> !llvm.ptr
    llvm.store %cst, %0 : f64, !llvm.ptr
    %c1_i64_0 = arith.constant 1 : i64
    %1 = llvm.alloca %c1_i64_0 x f64 : (i64) -> !llvm.ptr
    llvm.store %cst, %1 : f64, !llvm.ptr
    cf.br ^bb1
  ^bb1:  // pred: ^bb0
    %c4607182418800017408_i64 = arith.constant 4607182418800017408 : i64
    %2 = arith.bitcast %c4607182418800017408_i64 : i64 to f64
    llvm.store %2, %0 : f64, !llvm.ptr
    cf.br ^bb4
  ^bb2(%3: f64):  // pred: ^bb3
    return %3 : f64
  ^bb3:  // pred: ^bb5
    %4 = llvm.load %1 : !llvm.ptr -> f64
    cf.br ^bb2(%4 : f64)
  ^bb4:  // 2 preds: ^bb1, ^bb4
    %5 = llvm.load %0 : !llvm.ptr -> f64
    llvm.store %5, %1 : f64, !llvm.ptr
    %c4602678819172646912_i64 = arith.constant 4602678819172646912 : i64
    %6 = arith.bitcast %c4602678819172646912_i64 : i64 to f64
    %7 = arith.mulf %5, %6 : f64
    llvm.store %7, %0 : f64, !llvm.ptr
    %c4607182418800017408_i64_1 = arith.constant 4607182418800017408 : i64
    %8 = arith.bitcast %c4607182418800017408_i64_1 : i64 to f64
    %9 = arith.addf %7, %8 : f64
    %c4607182418800017408_i64_2 = arith.constant 4607182418800017408 : i64
    %10 = arith.bitcast %c4607182418800017408_i64_2 : i64 to f64
    %11 = arith.cmpf ogt, %9, %10 : f64
    %12 = arith.extui %11 : i1 to i32
    %c0_i32 = arith.constant 0 : i32
    %13 = arith.cmpi ne, %12, %c0_i32 : i32
    cf.cond_br %13, ^bb4, ^bb5
  ^bb5:  // pred: ^bb4
    cf.br ^bb3
  }
  func.func public @f32.no_trichotomy_lt(%arg0: !llvm.ptr, %arg1: f32, %arg2: f32) -> i32 attributes {llvm.emit_c_interface} {
    %c1_i64 = arith.constant 1 : i64
    %0 = llvm.alloca %c1_i64 x f32 : (i64) -> !llvm.ptr
    llvm.store %arg1, %0 : f32, !llvm.ptr
    %c1_i64_0 = arith.constant 1 : i64
    %1 = llvm.alloca %c1_i64_0 x f32 : (i64) -> !llvm.ptr
    llvm.store %arg2, %1 : f32, !llvm.ptr
    cf.br ^bb1
  ^bb1:  // pred: ^bb0
    %2 = llvm.load %0 : !llvm.ptr -> f32
    %3 = llvm.load %1 : !llvm.ptr -> f32
    %4 = arith.cmpf olt, %2, %3 : f32
    %5 = arith.extui %4 : i1 to i32
    %6 = llvm.load %0 : !llvm.ptr -> f32
    %7 = llvm.load %1 : !llvm.ptr -> f32
    %8 = arith.cmpf oge, %6, %7 : f32
    %9 = arith.extui %8 : i1 to i32
    %10 = arith.ori %5, %9 : i32
    cf.br ^bb2(%10 : i32)
  ^bb2(%11: i32):  // pred: ^bb1
    return %11 : i32
  }
  func.func public @f32.no_trichotomy_le(%arg0: !llvm.ptr, %arg1: f32, %arg2: f32) -> i32 attributes {llvm.emit_c_interface} {
    %c1_i64 = arith.constant 1 : i64
    %0 = llvm.alloca %c1_i64 x f32 : (i64) -> !llvm.ptr
    llvm.store %arg1, %0 : f32, !llvm.ptr
    %c1_i64_0 = arith.constant 1 : i64
    %1 = llvm.alloca %c1_i64_0 x f32 : (i64) -> !llvm.ptr
    llvm.store %arg2, %1 : f32, !llvm.ptr
    cf.br ^bb1
  ^bb1:  // pred: ^bb0
    %2 = llvm.load %0 : !llvm.ptr -> f32
    %3 = llvm.load %1 : !llvm.ptr -> f32
    %4 = arith.cmpf ole, %2, %3 : f32
    %5 = arith.extui %4 : i1 to i32
    %6 = llvm.load %0 : !llvm.ptr -> f32
    %7 = llvm.load %1 : !llvm.ptr -> f32
    %8 = arith.cmpf ogt, %6, %7 : f32
    %9 = arith.extui %8 : i1 to i32
    %10 = arith.ori %5, %9 : i32
    cf.br ^bb2(%10 : i32)
  ^bb2(%11: i32):  // pred: ^bb1
    return %11 : i32
  }
  func.func public @f32.no_trichotomy_gt(%arg0: !llvm.ptr, %arg1: f32, %arg2: f32) -> i32 attributes {llvm.emit_c_interface} {
    %c1_i64 = arith.constant 1 : i64
    %0 = llvm.alloca %c1_i64 x f32 : (i64) -> !llvm.ptr
    llvm.store %arg1, %0 : f32, !llvm.ptr
    %c1_i64_0 = arith.constant 1 : i64
    %1 = llvm.alloca %c1_i64_0 x f32 : (i64) -> !llvm.ptr
    llvm.store %arg2, %1 : f32, !llvm.ptr
    cf.br ^bb1
  ^bb1:  // pred: ^bb0
    %2 = llvm.load %0 : !llvm.ptr -> f32
    %3 = llvm.load %1 : !llvm.ptr -> f32
    %4 = arith.cmpf ogt, %2, %3 : f32
    %5 = arith.extui %4 : i1 to i32
    %6 = llvm.load %0 : !llvm.ptr -> f32
    %7 = llvm.load %1 : !llvm.ptr -> f32
    %8 = arith.cmpf ole, %6, %7 : f32
    %9 = arith.extui %8 : i1 to i32
    %10 = arith.ori %5, %9 : i32
    cf.br ^bb2(%10 : i32)
  ^bb2(%11: i32):  // pred: ^bb1
    return %11 : i32
  }
  func.func public @f32.no_trichotomy_ge(%arg0: !llvm.ptr, %arg1: f32, %arg2: f32) -> i32 attributes {llvm.emit_c_interface} {
    %c1_i64 = arith.constant 1 : i64
    %0 = llvm.alloca %c1_i64 x f32 : (i64) -> !llvm.ptr
    llvm.store %arg1, %0 : f32, !llvm.ptr
    %c1_i64_0 = arith.constant 1 : i64
    %1 = llvm.alloca %c1_i64_0 x f32 : (i64) -> !llvm.ptr
    llvm.store %arg2, %1 : f32, !llvm.ptr
    cf.br ^bb1
  ^bb1:  // pred: ^bb0
    %2 = llvm.load %0 : !llvm.ptr -> f32
    %3 = llvm.load %1 : !llvm.ptr -> f32
    %4 = arith.cmpf oge, %2, %3 : f32
    %5 = arith.extui %4 : i1 to i32
    %6 = llvm.load %0 : !llvm.ptr -> f32
    %7 = llvm.load %1 : !llvm.ptr -> f32
    %8 = arith.cmpf olt, %6, %7 : f32
    %9 = arith.extui %8 : i1 to i32
    %10 = arith.ori %5, %9 : i32
    cf.br ^bb2(%10 : i32)
  ^bb2(%11: i32):  // pred: ^bb1
    return %11 : i32
  }
  func.func public @f64.no_trichotomy_lt(%arg0: !llvm.ptr, %arg1: f64, %arg2: f64) -> i32 attributes {llvm.emit_c_interface} {
    %c1_i64 = arith.constant 1 : i64
    %0 = llvm.alloca %c1_i64 x f64 : (i64) -> !llvm.ptr
    llvm.store %arg1, %0 : f64, !llvm.ptr
    %c1_i64_0 = arith.constant 1 : i64
    %1 = llvm.alloca %c1_i64_0 x f64 : (i64) -> !llvm.ptr
    llvm.store %arg2, %1 : f64, !llvm.ptr
    cf.br ^bb1
  ^bb1:  // pred: ^bb0
    %2 = llvm.load %0 : !llvm.ptr -> f64
    %3 = llvm.load %1 : !llvm.ptr -> f64
    %4 = arith.cmpf olt, %2, %3 : f64
    %5 = arith.extui %4 : i1 to i32
    %6 = llvm.load %0 : !llvm.ptr -> f64
    %7 = llvm.load %1 : !llvm.ptr -> f64
    %8 = arith.cmpf oge, %6, %7 : f64
    %9 = arith.extui %8 : i1 to i32
    %10 = arith.ori %5, %9 : i32
    cf.br ^bb2(%10 : i32)
  ^bb2(%11: i32):  // pred: ^bb1
    return %11 : i32
  }
  func.func public @f64.no_trichotomy_le(%arg0: !llvm.ptr, %arg1: f64, %arg2: f64) -> i32 attributes {llvm.emit_c_interface} {
    %c1_i64 = arith.constant 1 : i64
    %0 = llvm.alloca %c1_i64 x f64 : (i64) -> !llvm.ptr
    llvm.store %arg1, %0 : f64, !llvm.ptr
    %c1_i64_0 = arith.constant 1 : i64
    %1 = llvm.alloca %c1_i64_0 x f64 : (i64) -> !llvm.ptr
    llvm.store %arg2, %1 : f64, !llvm.ptr
    cf.br ^bb1
  ^bb1:  // pred: ^bb0
    %2 = llvm.load %0 : !llvm.ptr -> f64
    %3 = llvm.load %1 : !llvm.ptr -> f64
    %4 = arith.cmpf ole, %2, %3 : f64
    %5 = arith.extui %4 : i1 to i32
    %6 = llvm.load %0 : !llvm.ptr -> f64
    %7 = llvm.load %1 : !llvm.ptr -> f64
    %8 = arith.cmpf ogt, %6, %7 : f64
    %9 = arith.extui %8 : i1 to i32
    %10 = arith.ori %5, %9 : i32
    cf.br ^bb2(%10 : i32)
  ^bb2(%11: i32):  // pred: ^bb1
    return %11 : i32
  }
  func.func public @f64.no_trichotomy_gt(%arg0: !llvm.ptr, %arg1: f64, %arg2: f64) -> i32 attributes {llvm.emit_c_interface} {
    %c1_i64 = arith.constant 1 : i64
    %0 = llvm.alloca %c1_i64 x f64 : (i64) -> !llvm.ptr
    llvm.store %arg1, %0 : f64, !llvm.ptr
    %c1_i64_0 = arith.constant 1 : i64
    %1 = llvm.alloca %c1_i64_0 x f64 : (i64) -> !llvm.ptr
    llvm.store %arg2, %1 : f64, !llvm.ptr
    cf.br ^bb1
  ^bb1:  // pred: ^bb0
    %2 = llvm.load %0 : !llvm.ptr -> f64
    %3 = llvm.load %1 : !llvm.ptr -> f64
    %4 = arith.cmpf ogt, %2, %3 : f64
    %5 = arith.extui %4 : i1 to i32
    %6 = llvm.load %0 : !llvm.ptr -> f64
    %7 = llvm.load %1 : !llvm.ptr -> f64
    %8 = arith.cmpf ole, %6, %7 : f64
    %9 = arith.extui %8 : i1 to i32
    %10 = arith.ori %5, %9 : i32
    cf.br ^bb2(%10 : i32)
  ^bb2(%11: i32):  // pred: ^bb1
    return %11 : i32
  }
  func.func public @f64.no_trichotomy_ge(%arg0: !llvm.ptr, %arg1: f64, %arg2: f64) -> i32 attributes {llvm.emit_c_interface} {
    %c1_i64 = arith.constant 1 : i64
    %0 = llvm.alloca %c1_i64 x f64 : (i64) -> !llvm.ptr
    llvm.store %arg1, %0 : f64, !llvm.ptr
    %c1_i64_0 = arith.constant 1 : i64
    %1 = llvm.alloca %c1_i64_0 x f64 : (i64) -> !llvm.ptr
    llvm.store %arg2, %1 : f64, !llvm.ptr
    cf.br ^bb1
  ^bb1:  // pred: ^bb0
    %2 = llvm.load %0 : !llvm.ptr -> f64
    %3 = llvm.load %1 : !llvm.ptr -> f64
    %4 = arith.cmpf oge, %2, %3 : f64
    %5 = arith.extui %4 : i1 to i32
    %6 = llvm.load %0 : !llvm.ptr -> f64
    %7 = llvm.load %1 : !llvm.ptr -> f64
    %8 = arith.cmpf olt, %6, %7 : f64
    %9 = arith.extui %8 : i1 to i32
    %10 = arith.ori %5, %9 : i32
    cf.br ^bb2(%10 : i32)
  ^bb2(%11: i32):  // pred: ^bb1
    return %11 : i32
  }
  func.func public @f32.arithmetic_nan_bitpattern(%arg0: !llvm.ptr, %arg1: i32, %arg2: i32) -> i32 attributes {llvm.emit_c_interface} {
    %c1_i64 = arith.constant 1 : i64
    %0 = llvm.alloca %c1_i64 x i32 : (i64) -> !llvm.ptr
    llvm.store %arg1, %0 : i32, !llvm.ptr
    %c1_i64_0 = arith.constant 1 : i64
    %1 = llvm.alloca %c1_i64_0 x i32 : (i64) -> !llvm.ptr
    llvm.store %arg2, %1 : i32, !llvm.ptr
    cf.br ^bb1
  ^bb1:  // pred: ^bb0
    %2 = llvm.load %0 : !llvm.ptr -> i32
    %3 = arith.bitcast %2 : i32 to f32
    %4 = llvm.load %1 : !llvm.ptr -> i32
    %5 = arith.bitcast %4 : i32 to f32
    %cst = arith.constant 0.000000e+00 : f32
    %6 = arith.cmpf oeq, %5, %cst : f32
    %7 = scf.if %6 -> (f32) {
      scf.yield %cst : f32
    } else {
      %11 = arith.divf %3, %5 : f32
      scf.yield %11 : f32
    }
    %8 = arith.bitcast %7 : f32 to i32
    %c2143289344_i32 = arith.constant 2143289344 : i32
    %9 = arith.andi %8, %c2143289344_i32 : i32
    cf.br ^bb2(%9 : i32)
  ^bb2(%10: i32):  // pred: ^bb1
    return %10 : i32
  }
  func.func public @f32.canonical_nan_bitpattern(%arg0: !llvm.ptr, %arg1: i32, %arg2: i32) -> i32 attributes {llvm.emit_c_interface} {
    %c1_i64 = arith.constant 1 : i64
    %0 = llvm.alloca %c1_i64 x i32 : (i64) -> !llvm.ptr
    llvm.store %arg1, %0 : i32, !llvm.ptr
    %c1_i64_0 = arith.constant 1 : i64
    %1 = llvm.alloca %c1_i64_0 x i32 : (i64) -> !llvm.ptr
    llvm.store %arg2, %1 : i32, !llvm.ptr
    cf.br ^bb1
  ^bb1:  // pred: ^bb0
    %2 = llvm.load %0 : !llvm.ptr -> i32
    %3 = arith.bitcast %2 : i32 to f32
    %4 = llvm.load %1 : !llvm.ptr -> i32
    %5 = arith.bitcast %4 : i32 to f32
    %cst = arith.constant 0.000000e+00 : f32
    %6 = arith.cmpf oeq, %5, %cst : f32
    %7 = scf.if %6 -> (f32) {
      scf.yield %cst : f32
    } else {
      %11 = arith.divf %3, %5 : f32
      scf.yield %11 : f32
    }
    %8 = arith.bitcast %7 : f32 to i32
    %c2147483647_i32 = arith.constant 2147483647 : i32
    %9 = arith.andi %8, %c2147483647_i32 : i32
    cf.br ^bb2(%9 : i32)
  ^bb2(%10: i32):  // pred: ^bb1
    return %10 : i32
  }
  func.func public @f32.nonarithmetic_nan_bitpattern(%arg0: !llvm.ptr, %arg1: i32) -> i32 attributes {llvm.emit_c_interface} {
    %c1_i64 = arith.constant 1 : i64
    %0 = llvm.alloca %c1_i64 x i32 : (i64) -> !llvm.ptr
    llvm.store %arg1, %0 : i32, !llvm.ptr
    cf.br ^bb1
  ^bb1:  // pred: ^bb0
    %1 = llvm.load %0 : !llvm.ptr -> i32
    %2 = arith.bitcast %1 : i32 to f32
    %3 = arith.negf %2 : f32
    %4 = arith.bitcast %3 : f32 to i32
    cf.br ^bb2(%4 : i32)
  ^bb2(%5: i32):  // pred: ^bb1
    return %5 : i32
  }
  func.func public @f64.arithmetic_nan_bitpattern(%arg0: !llvm.ptr, %arg1: i64, %arg2: i64) -> i64 attributes {llvm.emit_c_interface} {
    %c1_i64 = arith.constant 1 : i64
    %0 = llvm.alloca %c1_i64 x i64 : (i64) -> !llvm.ptr
    llvm.store %arg1, %0 : i64, !llvm.ptr
    %c1_i64_0 = arith.constant 1 : i64
    %1 = llvm.alloca %c1_i64_0 x i64 : (i64) -> !llvm.ptr
    llvm.store %arg2, %1 : i64, !llvm.ptr
    cf.br ^bb1
  ^bb1:  // pred: ^bb0
    %2 = llvm.load %0 : !llvm.ptr -> i64
    %3 = arith.bitcast %2 : i64 to f64
    %4 = llvm.load %1 : !llvm.ptr -> i64
    %5 = arith.bitcast %4 : i64 to f64
    %cst = arith.constant 0.000000e+00 : f64
    %6 = arith.cmpf oeq, %5, %cst : f64
    %7 = scf.if %6 -> (f64) {
      scf.yield %cst : f64
    } else {
      %11 = arith.divf %3, %5 : f64
      scf.yield %11 : f64
    }
    %8 = arith.bitcast %7 : f64 to i64
    %c9221120237041090560_i64 = arith.constant 9221120237041090560 : i64
    %9 = arith.andi %8, %c9221120237041090560_i64 : i64
    cf.br ^bb2(%9 : i64)
  ^bb2(%10: i64):  // pred: ^bb1
    return %10 : i64
  }
  func.func public @f64.canonical_nan_bitpattern(%arg0: !llvm.ptr, %arg1: i64, %arg2: i64) -> i64 attributes {llvm.emit_c_interface} {
    %c1_i64 = arith.constant 1 : i64
    %0 = llvm.alloca %c1_i64 x i64 : (i64) -> !llvm.ptr
    llvm.store %arg1, %0 : i64, !llvm.ptr
    %c1_i64_0 = arith.constant 1 : i64
    %1 = llvm.alloca %c1_i64_0 x i64 : (i64) -> !llvm.ptr
    llvm.store %arg2, %1 : i64, !llvm.ptr
    cf.br ^bb1
  ^bb1:  // pred: ^bb0
    %2 = llvm.load %0 : !llvm.ptr -> i64
    %3 = arith.bitcast %2 : i64 to f64
    %4 = llvm.load %1 : !llvm.ptr -> i64
    %5 = arith.bitcast %4 : i64 to f64
    %cst = arith.constant 0.000000e+00 : f64
    %6 = arith.cmpf oeq, %5, %cst : f64
    %7 = scf.if %6 -> (f64) {
      scf.yield %cst : f64
    } else {
      %11 = arith.divf %3, %5 : f64
      scf.yield %11 : f64
    }
    %8 = arith.bitcast %7 : f64 to i64
    %c9223372036854775807_i64 = arith.constant 9223372036854775807 : i64
    %9 = arith.andi %8, %c9223372036854775807_i64 : i64
    cf.br ^bb2(%9 : i64)
  ^bb2(%10: i64):  // pred: ^bb1
    return %10 : i64
  }
  func.func public @f64.nonarithmetic_nan_bitpattern(%arg0: !llvm.ptr, %arg1: i64) -> i64 attributes {llvm.emit_c_interface} {
    %c1_i64 = arith.constant 1 : i64
    %0 = llvm.alloca %c1_i64 x i64 : (i64) -> !llvm.ptr
    llvm.store %arg1, %0 : i64, !llvm.ptr
    cf.br ^bb1
  ^bb1:  // pred: ^bb0
    %1 = llvm.load %0 : !llvm.ptr -> i64
    %2 = arith.bitcast %1 : i64 to f64
    %3 = arith.negf %2 : f64
    %4 = arith.bitcast %3 : f64 to i64
    cf.br ^bb2(%4 : i64)
  ^bb2(%5: i64):  // pred: ^bb1
    return %5 : i64
  }
  func.func public @f32.no_fold_sub_zero(%arg0: !llvm.ptr, %arg1: i32) -> i32 attributes {llvm.emit_c_interface} {
    %c1_i64 = arith.constant 1 : i64
    %0 = llvm.alloca %c1_i64 x i32 : (i64) -> !llvm.ptr
    llvm.store %arg1, %0 : i32, !llvm.ptr
    cf.br ^bb1
  ^bb1:  // pred: ^bb0
    %1 = llvm.load %0 : !llvm.ptr -> i32
    %2 = arith.bitcast %1 : i32 to f32
    %c0_i32 = arith.constant 0 : i32
    %3 = arith.bitcast %c0_i32 : i32 to f32
    %4 = arith.subf %2, %3 : f32
    %5 = arith.bitcast %4 : f32 to i32
    %c2143289344_i32 = arith.constant 2143289344 : i32
    %6 = arith.andi %5, %c2143289344_i32 : i32
    cf.br ^bb2(%6 : i32)
  ^bb2(%7: i32):  // pred: ^bb1
    return %7 : i32
  }
  func.func public @f32.no_fold_neg0_sub(%arg0: !llvm.ptr, %arg1: i32) -> i32 attributes {llvm.emit_c_interface} {
    %c1_i64 = arith.constant 1 : i64
    %0 = llvm.alloca %c1_i64 x i32 : (i64) -> !llvm.ptr
    llvm.store %arg1, %0 : i32, !llvm.ptr
    cf.br ^bb1
  ^bb1:  // pred: ^bb0
    %c-2147483648_i32 = arith.constant -2147483648 : i32
    %1 = arith.bitcast %c-2147483648_i32 : i32 to f32
    %2 = llvm.load %0 : !llvm.ptr -> i32
    %3 = arith.bitcast %2 : i32 to f32
    %4 = arith.subf %1, %3 : f32
    %5 = arith.bitcast %4 : f32 to i32
    %c2143289344_i32 = arith.constant 2143289344 : i32
    %6 = arith.andi %5, %c2143289344_i32 : i32
    cf.br ^bb2(%6 : i32)
  ^bb2(%7: i32):  // pred: ^bb1
    return %7 : i32
  }
  func.func public @f32.no_fold_mul_one(%arg0: !llvm.ptr, %arg1: i32) -> i32 attributes {llvm.emit_c_interface} {
    %c1_i64 = arith.constant 1 : i64
    %0 = llvm.alloca %c1_i64 x i32 : (i64) -> !llvm.ptr
    llvm.store %arg1, %0 : i32, !llvm.ptr
    cf.br ^bb1
  ^bb1:  // pred: ^bb0
    %1 = llvm.load %0 : !llvm.ptr -> i32
    %2 = arith.bitcast %1 : i32 to f32
    %c1065353216_i32 = arith.constant 1065353216 : i32
    %3 = arith.bitcast %c1065353216_i32 : i32 to f32
    %4 = arith.mulf %2, %3 : f32
    %5 = arith.bitcast %4 : f32 to i32
    %c2143289344_i32 = arith.constant 2143289344 : i32
    %6 = arith.andi %5, %c2143289344_i32 : i32
    cf.br ^bb2(%6 : i32)
  ^bb2(%7: i32):  // pred: ^bb1
    return %7 : i32
  }
  func.func public @f32.no_fold_neg1_mul(%arg0: !llvm.ptr, %arg1: i32) -> i32 attributes {llvm.emit_c_interface} {
    %c1_i64 = arith.constant 1 : i64
    %0 = llvm.alloca %c1_i64 x i32 : (i64) -> !llvm.ptr
    llvm.store %arg1, %0 : i32, !llvm.ptr
    cf.br ^bb1
  ^bb1:  // pred: ^bb0
    %c-1082130432_i32 = arith.constant -1082130432 : i32
    %1 = arith.bitcast %c-1082130432_i32 : i32 to f32
    %2 = llvm.load %0 : !llvm.ptr -> i32
    %3 = arith.bitcast %2 : i32 to f32
    %4 = arith.mulf %1, %3 : f32
    %5 = arith.bitcast %4 : f32 to i32
    %c2143289344_i32 = arith.constant 2143289344 : i32
    %6 = arith.andi %5, %c2143289344_i32 : i32
    cf.br ^bb2(%6 : i32)
  ^bb2(%7: i32):  // pred: ^bb1
    return %7 : i32
  }
  func.func public @f32.no_fold_div_one(%arg0: !llvm.ptr, %arg1: i32) -> i32 attributes {llvm.emit_c_interface} {
    %c1_i64 = arith.constant 1 : i64
    %0 = llvm.alloca %c1_i64 x i32 : (i64) -> !llvm.ptr
    llvm.store %arg1, %0 : i32, !llvm.ptr
    cf.br ^bb1
  ^bb1:  // pred: ^bb0
    %1 = llvm.load %0 : !llvm.ptr -> i32
    %2 = arith.bitcast %1 : i32 to f32
    %c1065353216_i32 = arith.constant 1065353216 : i32
    %3 = arith.bitcast %c1065353216_i32 : i32 to f32
    %cst = arith.constant 0.000000e+00 : f32
    %4 = arith.cmpf oeq, %3, %cst : f32
    %5 = scf.if %4 -> (f32) {
      scf.yield %cst : f32
    } else {
      %9 = arith.divf %2, %3 : f32
      scf.yield %9 : f32
    }
    %6 = arith.bitcast %5 : f32 to i32
    %c2143289344_i32 = arith.constant 2143289344 : i32
    %7 = arith.andi %6, %c2143289344_i32 : i32
    cf.br ^bb2(%7 : i32)
  ^bb2(%8: i32):  // pred: ^bb1
    return %8 : i32
  }
  func.func public @f32.no_fold_div_neg1(%arg0: !llvm.ptr, %arg1: i32) -> i32 attributes {llvm.emit_c_interface} {
    %c1_i64 = arith.constant 1 : i64
    %0 = llvm.alloca %c1_i64 x i32 : (i64) -> !llvm.ptr
    llvm.store %arg1, %0 : i32, !llvm.ptr
    cf.br ^bb1
  ^bb1:  // pred: ^bb0
    %1 = llvm.load %0 : !llvm.ptr -> i32
    %2 = arith.bitcast %1 : i32 to f32
    %c-1082130432_i32 = arith.constant -1082130432 : i32
    %3 = arith.bitcast %c-1082130432_i32 : i32 to f32
    %cst = arith.constant 0.000000e+00 : f32
    %4 = arith.cmpf oeq, %3, %cst : f32
    %5 = scf.if %4 -> (f32) {
      scf.yield %cst : f32
    } else {
      %9 = arith.divf %2, %3 : f32
      scf.yield %9 : f32
    }
    %6 = arith.bitcast %5 : f32 to i32
    %c2143289344_i32 = arith.constant 2143289344 : i32
    %7 = arith.andi %6, %c2143289344_i32 : i32
    cf.br ^bb2(%7 : i32)
  ^bb2(%8: i32):  // pred: ^bb1
    return %8 : i32
  }
  func.func public @f64.no_fold_sub_zero(%arg0: !llvm.ptr, %arg1: i64) -> i64 attributes {llvm.emit_c_interface} {
    %c1_i64 = arith.constant 1 : i64
    %0 = llvm.alloca %c1_i64 x i64 : (i64) -> !llvm.ptr
    llvm.store %arg1, %0 : i64, !llvm.ptr
    cf.br ^bb1
  ^bb1:  // pred: ^bb0
    %1 = llvm.load %0 : !llvm.ptr -> i64
    %2 = arith.bitcast %1 : i64 to f64
    %c0_i64 = arith.constant 0 : i64
    %3 = arith.bitcast %c0_i64 : i64 to f64
    %4 = arith.subf %2, %3 : f64
    %5 = arith.bitcast %4 : f64 to i64
    %c9221120237041090560_i64 = arith.constant 9221120237041090560 : i64
    %6 = arith.andi %5, %c9221120237041090560_i64 : i64
    cf.br ^bb2(%6 : i64)
  ^bb2(%7: i64):  // pred: ^bb1
    return %7 : i64
  }
  func.func public @f64.no_fold_neg0_sub(%arg0: !llvm.ptr, %arg1: i64) -> i64 attributes {llvm.emit_c_interface} {
    %c1_i64 = arith.constant 1 : i64
    %0 = llvm.alloca %c1_i64 x i64 : (i64) -> !llvm.ptr
    llvm.store %arg1, %0 : i64, !llvm.ptr
    cf.br ^bb1
  ^bb1:  // pred: ^bb0
    %c-9223372036854775808_i64 = arith.constant -9223372036854775808 : i64
    %1 = arith.bitcast %c-9223372036854775808_i64 : i64 to f64
    %2 = llvm.load %0 : !llvm.ptr -> i64
    %3 = arith.bitcast %2 : i64 to f64
    %4 = arith.subf %1, %3 : f64
    %5 = arith.bitcast %4 : f64 to i64
    %c9221120237041090560_i64 = arith.constant 9221120237041090560 : i64
    %6 = arith.andi %5, %c9221120237041090560_i64 : i64
    cf.br ^bb2(%6 : i64)
  ^bb2(%7: i64):  // pred: ^bb1
    return %7 : i64
  }
  func.func public @f64.no_fold_mul_one(%arg0: !llvm.ptr, %arg1: i64) -> i64 attributes {llvm.emit_c_interface} {
    %c1_i64 = arith.constant 1 : i64
    %0 = llvm.alloca %c1_i64 x i64 : (i64) -> !llvm.ptr
    llvm.store %arg1, %0 : i64, !llvm.ptr
    cf.br ^bb1
  ^bb1:  // pred: ^bb0
    %1 = llvm.load %0 : !llvm.ptr -> i64
    %2 = arith.bitcast %1 : i64 to f64
    %c4607182418800017408_i64 = arith.constant 4607182418800017408 : i64
    %3 = arith.bitcast %c4607182418800017408_i64 : i64 to f64
    %4 = arith.mulf %2, %3 : f64
    %5 = arith.bitcast %4 : f64 to i64
    %c9221120237041090560_i64 = arith.constant 9221120237041090560 : i64
    %6 = arith.andi %5, %c9221120237041090560_i64 : i64
    cf.br ^bb2(%6 : i64)
  ^bb2(%7: i64):  // pred: ^bb1
    return %7 : i64
  }
  func.func public @f64.no_fold_neg1_mul(%arg0: !llvm.ptr, %arg1: i64) -> i64 attributes {llvm.emit_c_interface} {
    %c1_i64 = arith.constant 1 : i64
    %0 = llvm.alloca %c1_i64 x i64 : (i64) -> !llvm.ptr
    llvm.store %arg1, %0 : i64, !llvm.ptr
    cf.br ^bb1
  ^bb1:  // pred: ^bb0
    %c-4616189618054758400_i64 = arith.constant -4616189618054758400 : i64
    %1 = arith.bitcast %c-4616189618054758400_i64 : i64 to f64
    %2 = llvm.load %0 : !llvm.ptr -> i64
    %3 = arith.bitcast %2 : i64 to f64
    %4 = arith.mulf %1, %3 : f64
    %5 = arith.bitcast %4 : f64 to i64
    %c9221120237041090560_i64 = arith.constant 9221120237041090560 : i64
    %6 = arith.andi %5, %c9221120237041090560_i64 : i64
    cf.br ^bb2(%6 : i64)
  ^bb2(%7: i64):  // pred: ^bb1
    return %7 : i64
  }
  func.func public @f64.no_fold_div_one(%arg0: !llvm.ptr, %arg1: i64) -> i64 attributes {llvm.emit_c_interface} {
    %c1_i64 = arith.constant 1 : i64
    %0 = llvm.alloca %c1_i64 x i64 : (i64) -> !llvm.ptr
    llvm.store %arg1, %0 : i64, !llvm.ptr
    cf.br ^bb1
  ^bb1:  // pred: ^bb0
    %1 = llvm.load %0 : !llvm.ptr -> i64
    %2 = arith.bitcast %1 : i64 to f64
    %c4607182418800017408_i64 = arith.constant 4607182418800017408 : i64
    %3 = arith.bitcast %c4607182418800017408_i64 : i64 to f64
    %cst = arith.constant 0.000000e+00 : f64
    %4 = arith.cmpf oeq, %3, %cst : f64
    %5 = scf.if %4 -> (f64) {
      scf.yield %cst : f64
    } else {
      %9 = arith.divf %2, %3 : f64
      scf.yield %9 : f64
    }
    %6 = arith.bitcast %5 : f64 to i64
    %c9221120237041090560_i64 = arith.constant 9221120237041090560 : i64
    %7 = arith.andi %6, %c9221120237041090560_i64 : i64
    cf.br ^bb2(%7 : i64)
  ^bb2(%8: i64):  // pred: ^bb1
    return %8 : i64
  }
  func.func public @f64.no_fold_div_neg1(%arg0: !llvm.ptr, %arg1: i64) -> i64 attributes {llvm.emit_c_interface} {
    %c1_i64 = arith.constant 1 : i64
    %0 = llvm.alloca %c1_i64 x i64 : (i64) -> !llvm.ptr
    llvm.store %arg1, %0 : i64, !llvm.ptr
    cf.br ^bb1
  ^bb1:  // pred: ^bb0
    %1 = llvm.load %0 : !llvm.ptr -> i64
    %2 = arith.bitcast %1 : i64 to f64
    %c-4616189618054758400_i64 = arith.constant -4616189618054758400 : i64
    %3 = arith.bitcast %c-4616189618054758400_i64 : i64 to f64
    %cst = arith.constant 0.000000e+00 : f64
    %4 = arith.cmpf oeq, %3, %cst : f64
    %5 = scf.if %4 -> (f64) {
      scf.yield %cst : f64
    } else {
      %9 = arith.divf %2, %3 : f64
      scf.yield %9 : f64
    }
    %6 = arith.bitcast %5 : f64 to i64
    %c9221120237041090560_i64 = arith.constant 9221120237041090560 : i64
    %7 = arith.andi %6, %c9221120237041090560_i64 : i64
    cf.br ^bb2(%7 : i64)
  ^bb2(%8: i64):  // pred: ^bb1
    return %8 : i64
  }
  func.func public @no_fold_promote_demote(%arg0: !llvm.ptr, %arg1: i32) -> i32 attributes {llvm.emit_c_interface} {
    %c1_i64 = arith.constant 1 : i64
    %0 = llvm.alloca %c1_i64 x i32 : (i64) -> !llvm.ptr
    llvm.store %arg1, %0 : i32, !llvm.ptr
    cf.br ^bb1
  ^bb1:  // pred: ^bb0
    %1 = llvm.load %0 : !llvm.ptr -> i32
    %2 = arith.bitcast %1 : i32 to f32
    %3 = arith.extf %2 : f32 to f64
    %4 = arith.truncf %3 : f64 to f32
    %5 = arith.bitcast %4 : f32 to i32
    %c2143289344_i32 = arith.constant 2143289344 : i32
    %6 = arith.andi %5, %c2143289344_i32 : i32
    cf.br ^bb2(%6 : i32)
  ^bb2(%7: i32):  // pred: ^bb1
    return %7 : i32
  }
  func.func public @dot_product_example(%arg0: !llvm.ptr, %arg1: f64, %arg2: f64, %arg3: f64, %arg4: f64, %arg5: f64, %arg6: f64, %arg7: f64, %arg8: f64) -> f64 attributes {llvm.emit_c_interface} {
    %c1_i64 = arith.constant 1 : i64
    %0 = llvm.alloca %c1_i64 x f64 : (i64) -> !llvm.ptr
    llvm.store %arg1, %0 : f64, !llvm.ptr
    %c1_i64_0 = arith.constant 1 : i64
    %1 = llvm.alloca %c1_i64_0 x f64 : (i64) -> !llvm.ptr
    llvm.store %arg2, %1 : f64, !llvm.ptr
    %c1_i64_1 = arith.constant 1 : i64
    %2 = llvm.alloca %c1_i64_1 x f64 : (i64) -> !llvm.ptr
    llvm.store %arg3, %2 : f64, !llvm.ptr
    %c1_i64_2 = arith.constant 1 : i64
    %3 = llvm.alloca %c1_i64_2 x f64 : (i64) -> !llvm.ptr
    llvm.store %arg4, %3 : f64, !llvm.ptr
    %c1_i64_3 = arith.constant 1 : i64
    %4 = llvm.alloca %c1_i64_3 x f64 : (i64) -> !llvm.ptr
    llvm.store %arg5, %4 : f64, !llvm.ptr
    %c1_i64_4 = arith.constant 1 : i64
    %5 = llvm.alloca %c1_i64_4 x f64 : (i64) -> !llvm.ptr
    llvm.store %arg6, %5 : f64, !llvm.ptr
    %c1_i64_5 = arith.constant 1 : i64
    %6 = llvm.alloca %c1_i64_5 x f64 : (i64) -> !llvm.ptr
    llvm.store %arg7, %6 : f64, !llvm.ptr
    %c1_i64_6 = arith.constant 1 : i64
    %7 = llvm.alloca %c1_i64_6 x f64 : (i64) -> !llvm.ptr
    llvm.store %arg8, %7 : f64, !llvm.ptr
    cf.br ^bb1
  ^bb1:  // pred: ^bb0
    %8 = llvm.load %0 : !llvm.ptr -> f64
    %9 = llvm.load %4 : !llvm.ptr -> f64
    %10 = arith.mulf %8, %9 : f64
    %11 = llvm.load %1 : !llvm.ptr -> f64
    %12 = llvm.load %5 : !llvm.ptr -> f64
    %13 = arith.mulf %11, %12 : f64
    %14 = arith.addf %10, %13 : f64
    %15 = llvm.load %2 : !llvm.ptr -> f64
    %16 = llvm.load %6 : !llvm.ptr -> f64
    %17 = arith.mulf %15, %16 : f64
    %18 = arith.addf %14, %17 : f64
    %19 = llvm.load %3 : !llvm.ptr -> f64
    %20 = llvm.load %7 : !llvm.ptr -> f64
    %21 = arith.mulf %19, %20 : f64
    %22 = arith.addf %18, %21 : f64
    cf.br ^bb2(%22 : f64)
  ^bb2(%23: f64):  // pred: ^bb1
    return %23 : f64
  }
  func.func public @with_binary_sum_collapse(%arg0: !llvm.ptr, %arg1: f64, %arg2: f64, %arg3: f64, %arg4: f64, %arg5: f64, %arg6: f64, %arg7: f64, %arg8: f64) -> f64 attributes {llvm.emit_c_interface} {
    %c1_i64 = arith.constant 1 : i64
    %0 = llvm.alloca %c1_i64 x f64 : (i64) -> !llvm.ptr
    llvm.store %arg1, %0 : f64, !llvm.ptr
    %c1_i64_0 = arith.constant 1 : i64
    %1 = llvm.alloca %c1_i64_0 x f64 : (i64) -> !llvm.ptr
    llvm.store %arg2, %1 : f64, !llvm.ptr
    %c1_i64_1 = arith.constant 1 : i64
    %2 = llvm.alloca %c1_i64_1 x f64 : (i64) -> !llvm.ptr
    llvm.store %arg3, %2 : f64, !llvm.ptr
    %c1_i64_2 = arith.constant 1 : i64
    %3 = llvm.alloca %c1_i64_2 x f64 : (i64) -> !llvm.ptr
    llvm.store %arg4, %3 : f64, !llvm.ptr
    %c1_i64_3 = arith.constant 1 : i64
    %4 = llvm.alloca %c1_i64_3 x f64 : (i64) -> !llvm.ptr
    llvm.store %arg5, %4 : f64, !llvm.ptr
    %c1_i64_4 = arith.constant 1 : i64
    %5 = llvm.alloca %c1_i64_4 x f64 : (i64) -> !llvm.ptr
    llvm.store %arg6, %5 : f64, !llvm.ptr
    %c1_i64_5 = arith.constant 1 : i64
    %6 = llvm.alloca %c1_i64_5 x f64 : (i64) -> !llvm.ptr
    llvm.store %arg7, %6 : f64, !llvm.ptr
    %c1_i64_6 = arith.constant 1 : i64
    %7 = llvm.alloca %c1_i64_6 x f64 : (i64) -> !llvm.ptr
    llvm.store %arg8, %7 : f64, !llvm.ptr
    cf.br ^bb1
  ^bb1:  // pred: ^bb0
    %8 = llvm.load %0 : !llvm.ptr -> f64
    %9 = llvm.load %4 : !llvm.ptr -> f64
    %10 = arith.mulf %8, %9 : f64
    %11 = llvm.load %1 : !llvm.ptr -> f64
    %12 = llvm.load %5 : !llvm.ptr -> f64
    %13 = arith.mulf %11, %12 : f64
    %14 = arith.addf %10, %13 : f64
    %15 = llvm.load %2 : !llvm.ptr -> f64
    %16 = llvm.load %6 : !llvm.ptr -> f64
    %17 = arith.mulf %15, %16 : f64
    %18 = llvm.load %3 : !llvm.ptr -> f64
    %19 = llvm.load %7 : !llvm.ptr -> f64
    %20 = arith.mulf %18, %19 : f64
    %21 = arith.addf %17, %20 : f64
    %22 = arith.addf %14, %21 : f64
    cf.br ^bb2(%22 : f64)
  ^bb2(%23: f64):  // pred: ^bb1
    return %23 : f64
  }
  func.func public @f32.contract2fma(%arg0: !llvm.ptr, %arg1: f32, %arg2: f32) -> f32 attributes {llvm.emit_c_interface} {
    %c1_i64 = arith.constant 1 : i64
    %0 = llvm.alloca %c1_i64 x f32 : (i64) -> !llvm.ptr
    llvm.store %arg1, %0 : f32, !llvm.ptr
    %c1_i64_0 = arith.constant 1 : i64
    %1 = llvm.alloca %c1_i64_0 x f32 : (i64) -> !llvm.ptr
    llvm.store %arg2, %1 : f32, !llvm.ptr
    cf.br ^bb1
  ^bb1:  // pred: ^bb0
    %2 = llvm.load %0 : !llvm.ptr -> f32
    %3 = llvm.load %0 : !llvm.ptr -> f32
    %4 = arith.mulf %2, %3 : f32
    %5 = llvm.load %1 : !llvm.ptr -> f32
    %6 = llvm.load %1 : !llvm.ptr -> f32
    %7 = arith.mulf %5, %6 : f32
    %8 = arith.subf %4, %7 : f32
    %9 = math.sqrt %8 : f32
    cf.br ^bb2(%9 : f32)
  ^bb2(%10: f32):  // pred: ^bb1
    return %10 : f32
  }
  func.func public @f64.contract2fma(%arg0: !llvm.ptr, %arg1: f64, %arg2: f64) -> f64 attributes {llvm.emit_c_interface} {
    %c1_i64 = arith.constant 1 : i64
    %0 = llvm.alloca %c1_i64 x f64 : (i64) -> !llvm.ptr
    llvm.store %arg1, %0 : f64, !llvm.ptr
    %c1_i64_0 = arith.constant 1 : i64
    %1 = llvm.alloca %c1_i64_0 x f64 : (i64) -> !llvm.ptr
    llvm.store %arg2, %1 : f64, !llvm.ptr
    cf.br ^bb1
  ^bb1:  // pred: ^bb0
    %2 = llvm.load %0 : !llvm.ptr -> f64
    %3 = llvm.load %0 : !llvm.ptr -> f64
    %4 = arith.mulf %2, %3 : f64
    %5 = llvm.load %1 : !llvm.ptr -> f64
    %6 = llvm.load %1 : !llvm.ptr -> f64
    %7 = arith.mulf %5, %6 : f64
    %8 = arith.subf %4, %7 : f64
    %9 = math.sqrt %8 : f64
    cf.br ^bb2(%9 : f64)
  ^bb2(%10: f64):  // pred: ^bb1
    return %10 : f64
  }
  func.func public @f32.division_by_small_number(%arg0: !llvm.ptr, %arg1: f32, %arg2: f32, %arg3: f32) -> f32 attributes {llvm.emit_c_interface} {
    %c1_i64 = arith.constant 1 : i64
    %0 = llvm.alloca %c1_i64 x f32 : (i64) -> !llvm.ptr
    llvm.store %arg1, %0 : f32, !llvm.ptr
    %c1_i64_0 = arith.constant 1 : i64
    %1 = llvm.alloca %c1_i64_0 x f32 : (i64) -> !llvm.ptr
    llvm.store %arg2, %1 : f32, !llvm.ptr
    %c1_i64_1 = arith.constant 1 : i64
    %2 = llvm.alloca %c1_i64_1 x f32 : (i64) -> !llvm.ptr
    llvm.store %arg3, %2 : f32, !llvm.ptr
    cf.br ^bb1
  ^bb1:  // pred: ^bb0
    %3 = llvm.load %0 : !llvm.ptr -> f32
    %4 = llvm.load %1 : !llvm.ptr -> f32
    %5 = llvm.load %2 : !llvm.ptr -> f32
    %cst = arith.constant 0.000000e+00 : f32
    %6 = arith.cmpf oeq, %5, %cst : f32
    %7 = scf.if %6 -> (f32) {
      scf.yield %cst : f32
    } else {
      %10 = arith.divf %4, %5 : f32
      scf.yield %10 : f32
    }
    %8 = arith.subf %3, %7 : f32
    cf.br ^bb2(%8 : f32)
  ^bb2(%9: f32):  // pred: ^bb1
    return %9 : f32
  }
  func.func public @f64.division_by_small_number(%arg0: !llvm.ptr, %arg1: f64, %arg2: f64, %arg3: f64) -> f64 attributes {llvm.emit_c_interface} {
    %c1_i64 = arith.constant 1 : i64
    %0 = llvm.alloca %c1_i64 x f64 : (i64) -> !llvm.ptr
    llvm.store %arg1, %0 : f64, !llvm.ptr
    %c1_i64_0 = arith.constant 1 : i64
    %1 = llvm.alloca %c1_i64_0 x f64 : (i64) -> !llvm.ptr
    llvm.store %arg2, %1 : f64, !llvm.ptr
    %c1_i64_1 = arith.constant 1 : i64
    %2 = llvm.alloca %c1_i64_1 x f64 : (i64) -> !llvm.ptr
    llvm.store %arg3, %2 : f64, !llvm.ptr
    cf.br ^bb1
  ^bb1:  // pred: ^bb0
    %3 = llvm.load %0 : !llvm.ptr -> f64
    %4 = llvm.load %1 : !llvm.ptr -> f64
    %5 = llvm.load %2 : !llvm.ptr -> f64
    %cst = arith.constant 0.000000e+00 : f64
    %6 = arith.cmpf oeq, %5, %cst : f64
    %7 = scf.if %6 -> (f64) {
      scf.yield %cst : f64
    } else {
      %10 = arith.divf %4, %5 : f64
      scf.yield %10 : f64
    }
    %8 = arith.subf %3, %7 : f64
    cf.br ^bb2(%8 : f64)
  ^bb2(%9: f64):  // pred: ^bb1
    return %9 : f64
  }
  func.func public @f32.golden_ratio(%arg0: !llvm.ptr, %arg1: f32, %arg2: f32, %arg3: f32) -> f32 attributes {llvm.emit_c_interface} {
    %c1_i64 = arith.constant 1 : i64
    %0 = llvm.alloca %c1_i64 x f32 : (i64) -> !llvm.ptr
    llvm.store %arg1, %0 : f32, !llvm.ptr
    %c1_i64_0 = arith.constant 1 : i64
    %1 = llvm.alloca %c1_i64_0 x f32 : (i64) -> !llvm.ptr
    llvm.store %arg2, %1 : f32, !llvm.ptr
    %c1_i64_1 = arith.constant 1 : i64
    %2 = llvm.alloca %c1_i64_1 x f32 : (i64) -> !llvm.ptr
    llvm.store %arg3, %2 : f32, !llvm.ptr
    cf.br ^bb1
  ^bb1:  // pred: ^bb0
    %3 = llvm.load %0 : !llvm.ptr -> f32
    %4 = llvm.load %1 : !llvm.ptr -> f32
    %5 = llvm.load %2 : !llvm.ptr -> f32
    %6 = math.sqrt %5 : f32
    %7 = arith.addf %4, %6 : f32
    %8 = arith.mulf %3, %7 : f32
    cf.br ^bb2(%8 : f32)
  ^bb2(%9: f32):  // pred: ^bb1
    return %9 : f32
  }
  func.func public @f64.golden_ratio(%arg0: !llvm.ptr, %arg1: f64, %arg2: f64, %arg3: f64) -> f64 attributes {llvm.emit_c_interface} {
    %c1_i64 = arith.constant 1 : i64
    %0 = llvm.alloca %c1_i64 x f64 : (i64) -> !llvm.ptr
    llvm.store %arg1, %0 : f64, !llvm.ptr
    %c1_i64_0 = arith.constant 1 : i64
    %1 = llvm.alloca %c1_i64_0 x f64 : (i64) -> !llvm.ptr
    llvm.store %arg2, %1 : f64, !llvm.ptr
    %c1_i64_1 = arith.constant 1 : i64
    %2 = llvm.alloca %c1_i64_1 x f64 : (i64) -> !llvm.ptr
    llvm.store %arg3, %2 : f64, !llvm.ptr
    cf.br ^bb1
  ^bb1:  // pred: ^bb0
    %3 = llvm.load %0 : !llvm.ptr -> f64
    %4 = llvm.load %1 : !llvm.ptr -> f64
    %5 = llvm.load %2 : !llvm.ptr -> f64
    %6 = math.sqrt %5 : f64
    %7 = arith.addf %4, %6 : f64
    %8 = arith.mulf %3, %7 : f64
    cf.br ^bb2(%8 : f64)
  ^bb2(%9: f64):  // pred: ^bb1
    return %9 : f64
  }
  func.func public @f32.silver_means(%arg0: !llvm.ptr, %arg1: f32) -> f32 attributes {llvm.emit_c_interface} {
    %c1_i64 = arith.constant 1 : i64
    %0 = llvm.alloca %c1_i64 x f32 : (i64) -> !llvm.ptr
    llvm.store %arg1, %0 : f32, !llvm.ptr
    cf.br ^bb1
  ^bb1:  // pred: ^bb0
    %c1056964608_i32 = arith.constant 1056964608 : i32
    %1 = arith.bitcast %c1056964608_i32 : i32 to f32
    %2 = llvm.load %0 : !llvm.ptr -> f32
    %3 = llvm.load %0 : !llvm.ptr -> f32
    %4 = llvm.load %0 : !llvm.ptr -> f32
    %5 = arith.mulf %3, %4 : f32
    %c1082130432_i32 = arith.constant 1082130432 : i32
    %6 = arith.bitcast %c1082130432_i32 : i32 to f32
    %7 = arith.addf %5, %6 : f32
    %8 = math.sqrt %7 : f32
    %9 = arith.addf %2, %8 : f32
    %10 = arith.mulf %1, %9 : f32
    cf.br ^bb2(%10 : f32)
  ^bb2(%11: f32):  // pred: ^bb1
    return %11 : f32
  }
  func.func public @f64.silver_means(%arg0: !llvm.ptr, %arg1: f64) -> f64 attributes {llvm.emit_c_interface} {
    %c1_i64 = arith.constant 1 : i64
    %0 = llvm.alloca %c1_i64 x f64 : (i64) -> !llvm.ptr
    llvm.store %arg1, %0 : f64, !llvm.ptr
    cf.br ^bb1
  ^bb1:  // pred: ^bb0
    %c4602678819172646912_i64 = arith.constant 4602678819172646912 : i64
    %1 = arith.bitcast %c4602678819172646912_i64 : i64 to f64
    %2 = llvm.load %0 : !llvm.ptr -> f64
    %3 = llvm.load %0 : !llvm.ptr -> f64
    %4 = llvm.load %0 : !llvm.ptr -> f64
    %5 = arith.mulf %3, %4 : f64
    %c4616189618054758400_i64 = arith.constant 4616189618054758400 : i64
    %6 = arith.bitcast %c4616189618054758400_i64 : i64 to f64
    %7 = arith.addf %5, %6 : f64
    %8 = math.sqrt %7 : f64
    %9 = arith.addf %2, %8 : f64
    %10 = arith.mulf %1, %9 : f64
    cf.br ^bb2(%10 : f64)
  ^bb2(%11: f64):  // pred: ^bb1
    return %11 : f64
  }
  func.func public @point_four(%arg0: !llvm.ptr, %arg1: f64, %arg2: f64) -> i32 attributes {llvm.emit_c_interface} {
    %c1_i64 = arith.constant 1 : i64
    %0 = llvm.alloca %c1_i64 x f64 : (i64) -> !llvm.ptr
    llvm.store %arg1, %0 : f64, !llvm.ptr
    %c1_i64_0 = arith.constant 1 : i64
    %1 = llvm.alloca %c1_i64_0 x f64 : (i64) -> !llvm.ptr
    llvm.store %arg2, %1 : f64, !llvm.ptr
    cf.br ^bb1
  ^bb1:  // pred: ^bb0
    %2 = llvm.load %0 : !llvm.ptr -> f64
    %3 = llvm.load %1 : !llvm.ptr -> f64
    %cst = arith.constant 0.000000e+00 : f64
    %4 = arith.cmpf oeq, %3, %cst : f64
    %5 = scf.if %4 -> (f64) {
      scf.yield %cst : f64
    } else {
      %10 = arith.divf %2, %3 : f64
      scf.yield %10 : f64
    }
    %c4600877379321698714_i64 = arith.constant 4600877379321698714 : i64
    %6 = arith.bitcast %c4600877379321698714_i64 : i64 to f64
    %7 = arith.cmpf olt, %5, %6 : f64
    %8 = arith.extui %7 : i1 to i32
    cf.br ^bb2(%8 : i32)
  ^bb2(%9: i32):  // pred: ^bb1
    return %9 : i32
  }
  func.func public @tau(%arg0: !llvm.ptr, %arg1: i32) -> f64 attributes {llvm.emit_c_interface} {
    %c1_i64 = arith.constant 1 : i64
    %0 = llvm.alloca %c1_i64 x i32 : (i64) -> !llvm.ptr
    llvm.store %arg1, %0 : i32, !llvm.ptr
    %cst = arith.constant 0.000000e+00 : f64
    %c1_i64_0 = arith.constant 1 : i64
    %1 = llvm.alloca %c1_i64_0 x f64 : (i64) -> !llvm.ptr
    llvm.store %cst, %1 : f64, !llvm.ptr
    %c1_i64_1 = arith.constant 1 : i64
    %2 = llvm.alloca %c1_i64_1 x f64 : (i64) -> !llvm.ptr
    llvm.store %cst, %2 : f64, !llvm.ptr
    %c1_i64_2 = arith.constant 1 : i64
    %3 = llvm.alloca %c1_i64_2 x f64 : (i64) -> !llvm.ptr
    llvm.store %cst, %3 : f64, !llvm.ptr
    %c1_i64_3 = arith.constant 1 : i64
    %4 = llvm.alloca %c1_i64_3 x f64 : (i64) -> !llvm.ptr
    llvm.store %cst, %4 : f64, !llvm.ptr
    cf.br ^bb1
  ^bb1:  // pred: ^bb0
    %c0_i64 = arith.constant 0 : i64
    %5 = arith.bitcast %c0_i64 : i64 to f64
    llvm.store %5, %1 : f64, !llvm.ptr
    %6 = llvm.load %0 : !llvm.ptr -> i32
    %c1_i32 = arith.constant 1 : i32
    %7 = arith.cmpi slt, %6, %c1_i32 : i32
    %8 = arith.extui %7 : i1 to i32
    %c0_i32 = arith.constant 0 : i32
    %9 = arith.cmpi ne, %8, %c0_i32 : i32
    cf.cond_br %9, ^bb3, ^bb4
  ^bb2(%10: f64):  // pred: ^bb3
    return %10 : f64
  ^bb3:  // 2 preds: ^bb1, ^bb5
    %11 = llvm.load %1 : !llvm.ptr -> f64
    cf.br ^bb2(%11 : f64)
  ^bb4:  // pred: ^bb1
    %c4607182418800017408_i64 = arith.constant 4607182418800017408 : i64
    %12 = arith.bitcast %c4607182418800017408_i64 : i64 to f64
    llvm.store %12, %2 : f64, !llvm.ptr
    %c0_i64_4 = arith.constant 0 : i64
    %13 = arith.bitcast %c0_i64_4 : i64 to f64
    llvm.store %13, %3 : f64, !llvm.ptr
    cf.br ^bb6
  ^bb5:  // pred: ^bb7
    cf.br ^bb3
  ^bb6:  // 2 preds: ^bb4, ^bb6
    %14 = llvm.load %1 : !llvm.ptr -> f64
    %15 = llvm.load %2 : !llvm.ptr -> f64
    %c4620693217682128896_i64 = arith.constant 4620693217682128896 : i64
    %16 = arith.bitcast %c4620693217682128896_i64 : i64 to f64
    %17 = llvm.load %3 : !llvm.ptr -> f64
    %c4620693217682128896_i64_5 = arith.constant 4620693217682128896 : i64
    %18 = arith.bitcast %c4620693217682128896_i64_5 : i64 to f64
    %19 = arith.mulf %17, %18 : f64
    llvm.store %19, %4 : f64, !llvm.ptr
    %c4607182418800017408_i64_6 = arith.constant 4607182418800017408 : i64
    %20 = arith.bitcast %c4607182418800017408_i64_6 : i64 to f64
    %21 = arith.addf %19, %20 : f64
    %cst_7 = arith.constant 0.000000e+00 : f64
    %22 = arith.cmpf oeq, %21, %cst_7 : f64
    %23 = scf.if %22 -> (f64) {
      scf.yield %cst_7 : f64
    } else {
      %56 = arith.divf %16, %21 : f64
      scf.yield %56 : f64
    }
    %c4616189618054758400_i64 = arith.constant 4616189618054758400 : i64
    %24 = arith.bitcast %c4616189618054758400_i64 : i64 to f64
    %25 = llvm.load %4 : !llvm.ptr -> f64
    %c4616189618054758400_i64_8 = arith.constant 4616189618054758400 : i64
    %26 = arith.bitcast %c4616189618054758400_i64_8 : i64 to f64
    %27 = arith.addf %25, %26 : f64
    %cst_9 = arith.constant 0.000000e+00 : f64
    %28 = arith.cmpf oeq, %27, %cst_9 : f64
    %29 = scf.if %28 -> (f64) {
      scf.yield %cst_9 : f64
    } else {
      %56 = arith.divf %24, %27 : f64
      scf.yield %56 : f64
    }
    %30 = arith.subf %23, %29 : f64
    %c4611686018427387904_i64 = arith.constant 4611686018427387904 : i64
    %31 = arith.bitcast %c4611686018427387904_i64 : i64 to f64
    %32 = llvm.load %4 : !llvm.ptr -> f64
    %c4617315517961601024_i64 = arith.constant 4617315517961601024 : i64
    %33 = arith.bitcast %c4617315517961601024_i64 : i64 to f64
    %34 = arith.addf %32, %33 : f64
    %cst_10 = arith.constant 0.000000e+00 : f64
    %35 = arith.cmpf oeq, %34, %cst_10 : f64
    %36 = scf.if %35 -> (f64) {
      scf.yield %cst_10 : f64
    } else {
      %56 = arith.divf %31, %34 : f64
      scf.yield %56 : f64
    }
    %37 = arith.subf %30, %36 : f64
    %c4611686018427387904_i64_11 = arith.constant 4611686018427387904 : i64
    %38 = arith.bitcast %c4611686018427387904_i64_11 : i64 to f64
    %39 = llvm.load %4 : !llvm.ptr -> f64
    %c4618441417868443648_i64 = arith.constant 4618441417868443648 : i64
    %40 = arith.bitcast %c4618441417868443648_i64 : i64 to f64
    %41 = arith.addf %39, %40 : f64
    %cst_12 = arith.constant 0.000000e+00 : f64
    %42 = arith.cmpf oeq, %41, %cst_12 : f64
    %43 = scf.if %42 -> (f64) {
      scf.yield %cst_12 : f64
    } else {
      %56 = arith.divf %38, %41 : f64
      scf.yield %56 : f64
    }
    %44 = arith.subf %37, %43 : f64
    %45 = arith.mulf %15, %44 : f64
    %46 = arith.addf %14, %45 : f64
    llvm.store %46, %1 : f64, !llvm.ptr
    %47 = llvm.load %3 : !llvm.ptr -> f64
    %c4607182418800017408_i64_13 = arith.constant 4607182418800017408 : i64
    %48 = arith.bitcast %c4607182418800017408_i64_13 : i64 to f64
    %49 = arith.addf %47, %48 : f64
    llvm.store %49, %3 : f64, !llvm.ptr
    %50 = llvm.load %2 : !llvm.ptr -> f64
    %c4589168020290535424_i64 = arith.constant 4589168020290535424 : i64
    %51 = arith.bitcast %c4589168020290535424_i64 : i64 to f64
    %52 = arith.mulf %50, %51 : f64
    llvm.store %52, %2 : f64, !llvm.ptr
    %53 = llvm.load %0 : !llvm.ptr -> i32
    %c-1_i32 = arith.constant -1 : i32
    %54 = arith.addi %53, %c-1_i32 : i32
    llvm.store %54, %0 : i32, !llvm.ptr
    %c0_i32_14 = arith.constant 0 : i32
    %55 = arith.cmpi ne, %54, %c0_i32_14 : i32
    cf.cond_br %55, ^bb6, ^bb7
  ^bb7:  // pred: ^bb6
    cf.br ^bb5
  }
  func.func public @f32.no_fold_conditional_inc(%arg0: !llvm.ptr, %arg1: f32, %arg2: f32) -> f32 attributes {llvm.emit_c_interface} {
    %c1_i64 = arith.constant 1 : i64
    %0 = llvm.alloca %c1_i64 x f32 : (i64) -> !llvm.ptr
    llvm.store %arg1, %0 : f32, !llvm.ptr
    %c1_i64_0 = arith.constant 1 : i64
    %1 = llvm.alloca %c1_i64_0 x f32 : (i64) -> !llvm.ptr
    llvm.store %arg2, %1 : f32, !llvm.ptr
    cf.br ^bb1
  ^bb1:  // pred: ^bb0
    %2 = llvm.load %0 : !llvm.ptr -> f32
    %3 = llvm.load %0 : !llvm.ptr -> f32
    %c1065353216_i32 = arith.constant 1065353216 : i32
    %4 = arith.bitcast %c1065353216_i32 : i32 to f32
    %5 = arith.addf %3, %4 : f32
    %6 = llvm.load %1 : !llvm.ptr -> f32
    %c0_i32 = arith.constant 0 : i32
    %7 = arith.bitcast %c0_i32 : i32 to f32
    %8 = arith.cmpf olt, %6, %7 : f32
    %9 = arith.extui %8 : i1 to i32
    %c0_i32_1 = arith.constant 0 : i32
    %10 = arith.cmpi ne, %9, %c0_i32_1 : i32
    %11 = arith.select %10, %2, %5 : f32
    cf.br ^bb2(%11 : f32)
  ^bb2(%12: f32):  // pred: ^bb1
    return %12 : f32
  }
  func.func public @f64.no_fold_conditional_inc(%arg0: !llvm.ptr, %arg1: f64, %arg2: f64) -> f64 attributes {llvm.emit_c_interface} {
    %c1_i64 = arith.constant 1 : i64
    %0 = llvm.alloca %c1_i64 x f64 : (i64) -> !llvm.ptr
    llvm.store %arg1, %0 : f64, !llvm.ptr
    %c1_i64_0 = arith.constant 1 : i64
    %1 = llvm.alloca %c1_i64_0 x f64 : (i64) -> !llvm.ptr
    llvm.store %arg2, %1 : f64, !llvm.ptr
    cf.br ^bb1
  ^bb1:  // pred: ^bb0
    %2 = llvm.load %0 : !llvm.ptr -> f64
    %3 = llvm.load %0 : !llvm.ptr -> f64
    %c4607182418800017408_i64 = arith.constant 4607182418800017408 : i64
    %4 = arith.bitcast %c4607182418800017408_i64 : i64 to f64
    %5 = arith.addf %3, %4 : f64
    %6 = llvm.load %1 : !llvm.ptr -> f64
    %c0_i64 = arith.constant 0 : i64
    %7 = arith.bitcast %c0_i64 : i64 to f64
    %8 = arith.cmpf olt, %6, %7 : f64
    %9 = arith.extui %8 : i1 to i32
    %c0_i32 = arith.constant 0 : i32
    %10 = arith.cmpi ne, %9, %c0_i32 : i32
    %11 = arith.select %10, %2, %5 : f64
    cf.br ^bb2(%11 : f64)
  ^bb2(%12: f64):  // pred: ^bb1
    return %12 : f64
  }
  func.func private @dora_fn_wasm_table_init(!llvm.ptr, i32, i32, i32, i32, i32)
  func.func private @dora_fn_wasm_table_copy(!llvm.ptr, i32, i32, i32, i32, i32)
  func.func private @dora_fn_wasm_table_fill(!llvm.ptr, i32, i32, !llvm.ptr, i32)
  func.func private @dora_fn_wasm_table_size(!llvm.ptr, i32) -> i32
  func.func private @dora_fn_wasm_table_get(!llvm.ptr, i32, i32) -> !llvm.ptr
  func.func private @dora_fn_wasm_table_set(!llvm.ptr, i32, i32, !llvm.ptr)
  func.func private @dora_fn_wasm_table_grow(!llvm.ptr, !llvm.ptr, i32, i32) -> i32
  func.func private @dora_fn_wasm_imported_table_size(!llvm.ptr, i32) -> i32
  func.func private @dora_fn_wasm_imported_table_get(!llvm.ptr, i32, i32) -> !llvm.ptr
  func.func private @dora_fn_wasm_imported_table_grow(!llvm.ptr, !llvm.ptr, i32, i32) -> i32
  func.func private @dora_fn_wasm_memory_init(!llvm.ptr, i32, i32, i32, i32, i32)
  func.func private @dora_fn_wasm_memory_size(!llvm.ptr, i32) -> i32
  func.func private @dora_fn_wasm_memory_grow(!llvm.ptr, i32, i32) -> i32
  func.func private @dora_fn_wasm_memory_copy(!llvm.ptr, i32, i32, i32, i32)
  func.func private @dora_fn_wasm_memory_fill(!llvm.ptr, i32, i32, i32, i32)
  func.func private @dora_fn_wasm_memory_notify(!llvm.ptr, i32, i32, i32) -> i32
  func.func private @dora_fn_wasm_memory_wait32(!llvm.ptr, i32, i32, i32, i64) -> i32
  func.func private @dora_fn_wasm_memory_wait64(!llvm.ptr, i32, i32, i64, i64) -> i32
  func.func private @dora_fn_wasm_imported_memory_size(!llvm.ptr, i32) -> i32
  func.func private @dora_fn_wasm_imported_memory_grow(!llvm.ptr, i32, i32) -> i32
  func.func private @dora_fn_wasm_imported_memory_copy(!llvm.ptr, i32, i32, i32, i32)
  func.func private @dora_fn_wasm_imported_memory_fill(!llvm.ptr, i32, i32, i32, i32)
  func.func private @dora_fn_wasm_imported_memory_notify(!llvm.ptr, i32, i32, i32) -> i32
  func.func private @dora_fn_wasm_imported_memory_wait32(!llvm.ptr, i32, i32, i32, i64) -> i32
  func.func private @dora_fn_wasm_imported_memory_wait64(!llvm.ptr, i32, i32, i64, i64) -> i32
  func.func private @dora_fn_wasm_func_ref(!llvm.ptr, i32) -> !llvm.ptr
  func.func private @dora_fn_wasm_data_drop(!llvm.ptr, i32)
  func.func private @dora_fn_wasm_elem_drop(!llvm.ptr, i32)
  func.func private @dora_fn_wasm_raise_trap(i32)
}
